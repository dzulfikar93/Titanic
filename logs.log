2024-12-24 13:57:52,855:INFO:PyCaret RegressionExperiment
2024-12-24 13:57:52,855:INFO:Logging name: reg-default-name
2024-12-24 13:57:52,855:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-24 13:57:52,855:INFO:version 3.3.1
2024-12-24 13:57:52,855:INFO:Initializing setup()
2024-12-24 13:57:52,855:INFO:self.USI: 92af
2024-12-24 13:57:52,855:INFO:self._variable_keys: {'_available_plots', 'data', 'y_test', 'html_param', 'pipeline', 'X_test', '_ml_usecase', 'idx', 'target_param', 'fold_generator', 'seed', 'X_train', 'X', 'fold_groups_param', 'transform_target_param', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'y_train', 'fold_shuffle_param', 'y', 'USI', 'gpu_param', 'logging_param', 'exp_name_log', 'memory', 'log_plots_param'}
2024-12-24 13:57:52,855:INFO:Checking environment
2024-12-24 13:57:52,855:INFO:python_version: 3.10.15
2024-12-24 13:57:52,855:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-24 13:57:52,855:INFO:machine: AMD64
2024-12-24 13:57:52,856:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-24 13:57:52,856:INFO:Memory: svmem(total=16312721408, available=4033761280, percent=75.3, used=12278960128, free=4033761280)
2024-12-24 13:57:52,856:INFO:Physical Core: 6
2024-12-24 13:57:52,856:INFO:Logical Core: 12
2024-12-24 13:57:52,856:INFO:Checking libraries
2024-12-24 13:57:52,856:INFO:System:
2024-12-24 13:57:52,856:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-24 13:57:52,856:INFO:executable: D:\Anaconda\python.exe
2024-12-24 13:57:52,856:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-24 13:57:52,856:INFO:PyCaret required dependencies:
2024-12-24 13:57:52,980:INFO:                 pip: 24.2
2024-12-24 13:57:52,980:INFO:          setuptools: 75.1.0
2024-12-24 13:57:52,980:INFO:             pycaret: 3.3.1
2024-12-24 13:57:52,980:INFO:             IPython: 8.27.0
2024-12-24 13:57:52,980:INFO:          ipywidgets: 8.1.2
2024-12-24 13:57:52,981:INFO:                tqdm: 4.66.5
2024-12-24 13:57:52,981:INFO:               numpy: 1.26.4
2024-12-24 13:57:52,981:INFO:              pandas: 2.1.4
2024-12-24 13:57:52,981:INFO:              jinja2: 3.1.4
2024-12-24 13:57:52,981:INFO:               scipy: 1.11.4
2024-12-24 13:57:52,981:INFO:              joblib: 1.2.0
2024-12-24 13:57:52,981:INFO:             sklearn: 1.4.2
2024-12-24 13:57:52,981:INFO:                pyod: 2.0.2
2024-12-24 13:57:52,981:INFO:            imblearn: 0.12.3
2024-12-24 13:57:52,981:INFO:   category_encoders: 2.6.3
2024-12-24 13:57:52,981:INFO:            lightgbm: 4.5.0
2024-12-24 13:57:52,981:INFO:               numba: 0.60.0
2024-12-24 13:57:52,981:INFO:            requests: 2.32.3
2024-12-24 13:57:52,981:INFO:          matplotlib: 3.9.2
2024-12-24 13:57:52,981:INFO:          scikitplot: 0.3.7
2024-12-24 13:57:52,981:INFO:         yellowbrick: 1.5
2024-12-24 13:57:52,981:INFO:              plotly: 5.24.1
2024-12-24 13:57:52,981:INFO:    plotly-resampler: Not installed
2024-12-24 13:57:52,981:INFO:             kaleido: 0.2.1
2024-12-24 13:57:52,981:INFO:           schemdraw: 0.15
2024-12-24 13:57:52,981:INFO:         statsmodels: 0.14.2
2024-12-24 13:57:52,981:INFO:              sktime: 0.26.0
2024-12-24 13:57:52,981:INFO:               tbats: 1.1.3
2024-12-24 13:57:52,981:INFO:            pmdarima: 2.0.4
2024-12-24 13:57:52,981:INFO:              psutil: 5.9.0
2024-12-24 13:57:52,981:INFO:          markupsafe: 2.1.3
2024-12-24 13:57:52,981:INFO:             pickle5: Not installed
2024-12-24 13:57:52,982:INFO:         cloudpickle: 3.0.0
2024-12-24 13:57:52,982:INFO:         deprecation: 2.1.0
2024-12-24 13:57:52,982:INFO:              xxhash: 2.0.2
2024-12-24 13:57:52,982:INFO:           wurlitzer: 3.1.1
2024-12-24 13:57:52,982:INFO:PyCaret optional dependencies:
2024-12-24 13:57:53,053:INFO:                shap: Not installed
2024-12-24 13:57:53,053:INFO:           interpret: Not installed
2024-12-24 13:57:53,053:INFO:                umap: 0.5.3
2024-12-24 13:57:53,053:INFO:     ydata_profiling: Not installed
2024-12-24 13:57:53,053:INFO:  explainerdashboard: Not installed
2024-12-24 13:57:53,053:INFO:             autoviz: Not installed
2024-12-24 13:57:53,053:INFO:           fairlearn: Not installed
2024-12-24 13:57:53,053:INFO:          deepchecks: Not installed
2024-12-24 13:57:53,053:INFO:             xgboost: 2.1.2
2024-12-24 13:57:53,053:INFO:            catboost: 1.2.3
2024-12-24 13:57:53,053:INFO:              kmodes: 0.12.2
2024-12-24 13:57:53,053:INFO:             mlxtend: 0.23.1
2024-12-24 13:57:53,053:INFO:       statsforecast: Not installed
2024-12-24 13:57:53,053:INFO:        tune_sklearn: Not installed
2024-12-24 13:57:53,053:INFO:                 ray: Not installed
2024-12-24 13:57:53,053:INFO:            hyperopt: Not installed
2024-12-24 13:57:53,053:INFO:              optuna: Not installed
2024-12-24 13:57:53,053:INFO:               skopt: Not installed
2024-12-24 13:57:53,053:INFO:              mlflow: 2.16.2
2024-12-24 13:57:53,053:INFO:              gradio: Not installed
2024-12-24 13:57:53,053:INFO:             fastapi: Not installed
2024-12-24 13:57:53,053:INFO:             uvicorn: Not installed
2024-12-24 13:57:53,053:INFO:              m2cgen: Not installed
2024-12-24 13:57:53,054:INFO:           evidently: Not installed
2024-12-24 13:57:53,054:INFO:               fugue: Not installed
2024-12-24 13:57:53,054:INFO:           streamlit: Not installed
2024-12-24 13:57:53,054:INFO:             prophet: Not installed
2024-12-24 13:57:53,054:INFO:None
2024-12-24 13:57:53,054:INFO:Set up data.
2024-12-24 13:57:53,063:INFO:Set up folding strategy.
2024-12-24 13:57:53,063:INFO:Set up train/test split.
2024-12-24 13:57:53,074:INFO:Set up index.
2024-12-24 13:57:53,076:INFO:Assigning column types.
2024-12-24 13:57:53,079:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-24 13:57:53,079:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,084:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,088:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,171:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,173:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,288:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,293:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,297:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,381:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,381:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,383:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,384:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-24 13:57:53,387:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,468:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,470:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,474:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,478:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,556:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,558:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,558:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-24 13:57:53,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,643:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,645:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,728:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,728:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,730:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,731:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-24 13:57:53,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,819:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,822:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,905:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,905:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,907:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:53,908:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-24 13:57:53,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:53,989:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:53,991:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:54,042:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 13:57:54,076:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:54,078:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:54,078:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-24 13:57:54,161:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:54,163:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:54,248:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:54,250:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:54,252:INFO:Preparing preprocessing pipeline...
2024-12-24 13:57:54,252:INFO:Set up simple imputation.
2024-12-24 13:57:54,257:INFO:Set up encoding of ordinal features.
2024-12-24 13:57:54,258:INFO:Set up encoding of categorical features.
2024-12-24 13:57:54,354:INFO:Finished creating preprocessing pipeline.
2024-12-24 13:57:54,374:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket'],
                                                              handle_missing='return_nan')))])
2024-12-24 13:57:54,374:INFO:Creating final display dataframe.
2024-12-24 13:57:54,675:INFO:Setup _display_container:                     Description             Value
0                    Session id              5010
1                        Target          Survived
2                   Target type        Regression
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 13)
5   Transformed train set shape         (623, 13)
6    Transformed test set shape         (268, 13)
7              Numeric features                 6
8          Categorical features                 4
9      Rows with missing values             20.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                 5
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              92af
2024-12-24 13:57:54,766:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:54,768:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:54,853:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 13:57:54,855:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 13:57:54,856:INFO:setup() successfully completed in 2.01s...............
2024-12-24 13:57:57,014:INFO:Initializing compare_models()
2024-12-24 13:57:57,014:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-12-24 13:57:57,014:INFO:Checking exceptions
2024-12-24 13:57:57,016:INFO:Preparing display monitor
2024-12-24 13:57:57,038:INFO:Initializing Linear Regression
2024-12-24 13:57:57,038:INFO:Total runtime is 0.0 minutes
2024-12-24 13:57:57,040:INFO:SubProcess create_model() called ==================================
2024-12-24 13:57:57,041:INFO:Initializing create_model()
2024-12-24 13:57:57,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:57:57,041:INFO:Checking exceptions
2024-12-24 13:57:57,041:INFO:Importing libraries
2024-12-24 13:57:57,041:INFO:Copying training dataset
2024-12-24 13:57:57,047:INFO:Defining folds
2024-12-24 13:57:57,047:INFO:Declaring metric variables
2024-12-24 13:57:57,050:INFO:Importing untrained model
2024-12-24 13:57:57,052:INFO:Linear Regression Imported successfully
2024-12-24 13:57:57,059:INFO:Starting cross validation
2024-12-24 13:57:57,067:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:57:59,591:INFO:Calculating mean and std
2024-12-24 13:57:59,592:INFO:Creating metrics dataframe
2024-12-24 13:57:59,595:INFO:Uploading results into container
2024-12-24 13:57:59,595:INFO:Uploading model into container now
2024-12-24 13:57:59,595:INFO:_master_model_container: 1
2024-12-24 13:57:59,596:INFO:_display_container: 2
2024-12-24 13:57:59,596:INFO:LinearRegression(n_jobs=-1)
2024-12-24 13:57:59,596:INFO:create_model() successfully completed......................................
2024-12-24 13:57:59,715:INFO:SubProcess create_model() end ==================================
2024-12-24 13:57:59,715:INFO:Creating metrics dataframe
2024-12-24 13:57:59,719:INFO:Initializing Lasso Regression
2024-12-24 13:57:59,719:INFO:Total runtime is 0.044682582219441734 minutes
2024-12-24 13:57:59,723:INFO:SubProcess create_model() called ==================================
2024-12-24 13:57:59,723:INFO:Initializing create_model()
2024-12-24 13:57:59,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:57:59,723:INFO:Checking exceptions
2024-12-24 13:57:59,723:INFO:Importing libraries
2024-12-24 13:57:59,724:INFO:Copying training dataset
2024-12-24 13:57:59,727:INFO:Defining folds
2024-12-24 13:57:59,727:INFO:Declaring metric variables
2024-12-24 13:57:59,730:INFO:Importing untrained model
2024-12-24 13:57:59,731:INFO:Lasso Regression Imported successfully
2024-12-24 13:57:59,737:INFO:Starting cross validation
2024-12-24 13:57:59,738:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:01,582:INFO:Calculating mean and std
2024-12-24 13:58:01,584:INFO:Creating metrics dataframe
2024-12-24 13:58:01,586:INFO:Uploading results into container
2024-12-24 13:58:01,586:INFO:Uploading model into container now
2024-12-24 13:58:01,586:INFO:_master_model_container: 2
2024-12-24 13:58:01,587:INFO:_display_container: 2
2024-12-24 13:58:01,587:INFO:Lasso(random_state=5010)
2024-12-24 13:58:01,587:INFO:create_model() successfully completed......................................
2024-12-24 13:58:01,709:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:01,710:INFO:Creating metrics dataframe
2024-12-24 13:58:01,717:INFO:Initializing Ridge Regression
2024-12-24 13:58:01,717:INFO:Total runtime is 0.07797367572784425 minutes
2024-12-24 13:58:01,719:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:01,720:INFO:Initializing create_model()
2024-12-24 13:58:01,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:01,720:INFO:Checking exceptions
2024-12-24 13:58:01,720:INFO:Importing libraries
2024-12-24 13:58:01,720:INFO:Copying training dataset
2024-12-24 13:58:01,723:INFO:Defining folds
2024-12-24 13:58:01,723:INFO:Declaring metric variables
2024-12-24 13:58:01,726:INFO:Importing untrained model
2024-12-24 13:58:01,728:INFO:Ridge Regression Imported successfully
2024-12-24 13:58:01,733:INFO:Starting cross validation
2024-12-24 13:58:01,735:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:03,401:INFO:Calculating mean and std
2024-12-24 13:58:03,402:INFO:Creating metrics dataframe
2024-12-24 13:58:03,404:INFO:Uploading results into container
2024-12-24 13:58:03,405:INFO:Uploading model into container now
2024-12-24 13:58:03,405:INFO:_master_model_container: 3
2024-12-24 13:58:03,405:INFO:_display_container: 2
2024-12-24 13:58:03,406:INFO:Ridge(random_state=5010)
2024-12-24 13:58:03,406:INFO:create_model() successfully completed......................................
2024-12-24 13:58:03,509:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:03,509:INFO:Creating metrics dataframe
2024-12-24 13:58:03,515:INFO:Initializing Elastic Net
2024-12-24 13:58:03,515:INFO:Total runtime is 0.10795367558797202 minutes
2024-12-24 13:58:03,517:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:03,519:INFO:Initializing create_model()
2024-12-24 13:58:03,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:03,519:INFO:Checking exceptions
2024-12-24 13:58:03,519:INFO:Importing libraries
2024-12-24 13:58:03,519:INFO:Copying training dataset
2024-12-24 13:58:03,522:INFO:Defining folds
2024-12-24 13:58:03,522:INFO:Declaring metric variables
2024-12-24 13:58:03,525:INFO:Importing untrained model
2024-12-24 13:58:03,527:INFO:Elastic Net Imported successfully
2024-12-24 13:58:03,532:INFO:Starting cross validation
2024-12-24 13:58:03,533:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:03,628:INFO:Calculating mean and std
2024-12-24 13:58:03,629:INFO:Creating metrics dataframe
2024-12-24 13:58:03,631:INFO:Uploading results into container
2024-12-24 13:58:03,632:INFO:Uploading model into container now
2024-12-24 13:58:03,632:INFO:_master_model_container: 4
2024-12-24 13:58:03,632:INFO:_display_container: 2
2024-12-24 13:58:03,632:INFO:ElasticNet(random_state=5010)
2024-12-24 13:58:03,632:INFO:create_model() successfully completed......................................
2024-12-24 13:58:03,730:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:03,731:INFO:Creating metrics dataframe
2024-12-24 13:58:03,737:INFO:Initializing Least Angle Regression
2024-12-24 13:58:03,737:INFO:Total runtime is 0.11164753834406536 minutes
2024-12-24 13:58:03,740:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:03,740:INFO:Initializing create_model()
2024-12-24 13:58:03,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:03,740:INFO:Checking exceptions
2024-12-24 13:58:03,740:INFO:Importing libraries
2024-12-24 13:58:03,740:INFO:Copying training dataset
2024-12-24 13:58:03,745:INFO:Defining folds
2024-12-24 13:58:03,745:INFO:Declaring metric variables
2024-12-24 13:58:03,747:INFO:Importing untrained model
2024-12-24 13:58:03,749:INFO:Least Angle Regression Imported successfully
2024-12-24 13:58:03,754:INFO:Starting cross validation
2024-12-24 13:58:03,756:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:03,851:INFO:Calculating mean and std
2024-12-24 13:58:03,852:INFO:Creating metrics dataframe
2024-12-24 13:58:03,854:INFO:Uploading results into container
2024-12-24 13:58:03,854:INFO:Uploading model into container now
2024-12-24 13:58:03,855:INFO:_master_model_container: 5
2024-12-24 13:58:03,855:INFO:_display_container: 2
2024-12-24 13:58:03,855:INFO:Lars(random_state=5010)
2024-12-24 13:58:03,855:INFO:create_model() successfully completed......................................
2024-12-24 13:58:03,955:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:03,955:INFO:Creating metrics dataframe
2024-12-24 13:58:03,963:INFO:Initializing Lasso Least Angle Regression
2024-12-24 13:58:03,963:INFO:Total runtime is 0.11541399161020917 minutes
2024-12-24 13:58:03,966:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:03,966:INFO:Initializing create_model()
2024-12-24 13:58:03,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:03,966:INFO:Checking exceptions
2024-12-24 13:58:03,966:INFO:Importing libraries
2024-12-24 13:58:03,966:INFO:Copying training dataset
2024-12-24 13:58:03,970:INFO:Defining folds
2024-12-24 13:58:03,970:INFO:Declaring metric variables
2024-12-24 13:58:03,972:INFO:Importing untrained model
2024-12-24 13:58:03,975:INFO:Lasso Least Angle Regression Imported successfully
2024-12-24 13:58:03,980:INFO:Starting cross validation
2024-12-24 13:58:03,982:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:04,089:INFO:Calculating mean and std
2024-12-24 13:58:04,090:INFO:Creating metrics dataframe
2024-12-24 13:58:04,092:INFO:Uploading results into container
2024-12-24 13:58:04,092:INFO:Uploading model into container now
2024-12-24 13:58:04,092:INFO:_master_model_container: 6
2024-12-24 13:58:04,092:INFO:_display_container: 2
2024-12-24 13:58:04,092:INFO:LassoLars(random_state=5010)
2024-12-24 13:58:04,092:INFO:create_model() successfully completed......................................
2024-12-24 13:58:04,191:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:04,192:INFO:Creating metrics dataframe
2024-12-24 13:58:04,197:INFO:Initializing Orthogonal Matching Pursuit
2024-12-24 13:58:04,197:INFO:Total runtime is 0.11931890249252322 minutes
2024-12-24 13:58:04,201:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:04,201:INFO:Initializing create_model()
2024-12-24 13:58:04,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:04,201:INFO:Checking exceptions
2024-12-24 13:58:04,201:INFO:Importing libraries
2024-12-24 13:58:04,201:INFO:Copying training dataset
2024-12-24 13:58:04,205:INFO:Defining folds
2024-12-24 13:58:04,205:INFO:Declaring metric variables
2024-12-24 13:58:04,207:INFO:Importing untrained model
2024-12-24 13:58:04,210:INFO:Orthogonal Matching Pursuit Imported successfully
2024-12-24 13:58:04,215:INFO:Starting cross validation
2024-12-24 13:58:04,217:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:04,318:INFO:Calculating mean and std
2024-12-24 13:58:04,319:INFO:Creating metrics dataframe
2024-12-24 13:58:04,321:INFO:Uploading results into container
2024-12-24 13:58:04,322:INFO:Uploading model into container now
2024-12-24 13:58:04,322:INFO:_master_model_container: 7
2024-12-24 13:58:04,322:INFO:_display_container: 2
2024-12-24 13:58:04,322:INFO:OrthogonalMatchingPursuit()
2024-12-24 13:58:04,322:INFO:create_model() successfully completed......................................
2024-12-24 13:58:04,419:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:04,419:INFO:Creating metrics dataframe
2024-12-24 13:58:04,425:INFO:Initializing Bayesian Ridge
2024-12-24 13:58:04,425:INFO:Total runtime is 0.12312010924021406 minutes
2024-12-24 13:58:04,428:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:04,428:INFO:Initializing create_model()
2024-12-24 13:58:04,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:04,428:INFO:Checking exceptions
2024-12-24 13:58:04,428:INFO:Importing libraries
2024-12-24 13:58:04,428:INFO:Copying training dataset
2024-12-24 13:58:04,431:INFO:Defining folds
2024-12-24 13:58:04,432:INFO:Declaring metric variables
2024-12-24 13:58:04,434:INFO:Importing untrained model
2024-12-24 13:58:04,437:INFO:Bayesian Ridge Imported successfully
2024-12-24 13:58:04,442:INFO:Starting cross validation
2024-12-24 13:58:04,443:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:04,540:INFO:Calculating mean and std
2024-12-24 13:58:04,541:INFO:Creating metrics dataframe
2024-12-24 13:58:04,543:INFO:Uploading results into container
2024-12-24 13:58:04,544:INFO:Uploading model into container now
2024-12-24 13:58:04,544:INFO:_master_model_container: 8
2024-12-24 13:58:04,544:INFO:_display_container: 2
2024-12-24 13:58:04,545:INFO:BayesianRidge()
2024-12-24 13:58:04,545:INFO:create_model() successfully completed......................................
2024-12-24 13:58:04,641:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:04,641:INFO:Creating metrics dataframe
2024-12-24 13:58:04,649:INFO:Initializing Passive Aggressive Regressor
2024-12-24 13:58:04,649:INFO:Total runtime is 0.1268404563268026 minutes
2024-12-24 13:58:04,652:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:04,652:INFO:Initializing create_model()
2024-12-24 13:58:04,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:04,652:INFO:Checking exceptions
2024-12-24 13:58:04,652:INFO:Importing libraries
2024-12-24 13:58:04,652:INFO:Copying training dataset
2024-12-24 13:58:04,655:INFO:Defining folds
2024-12-24 13:58:04,655:INFO:Declaring metric variables
2024-12-24 13:58:04,657:INFO:Importing untrained model
2024-12-24 13:58:04,660:INFO:Passive Aggressive Regressor Imported successfully
2024-12-24 13:58:04,664:INFO:Starting cross validation
2024-12-24 13:58:04,667:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:04,767:INFO:Calculating mean and std
2024-12-24 13:58:04,768:INFO:Creating metrics dataframe
2024-12-24 13:58:04,769:INFO:Uploading results into container
2024-12-24 13:58:04,770:INFO:Uploading model into container now
2024-12-24 13:58:04,770:INFO:_master_model_container: 9
2024-12-24 13:58:04,770:INFO:_display_container: 2
2024-12-24 13:58:04,771:INFO:PassiveAggressiveRegressor(random_state=5010)
2024-12-24 13:58:04,771:INFO:create_model() successfully completed......................................
2024-12-24 13:58:04,868:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:04,869:INFO:Creating metrics dataframe
2024-12-24 13:58:04,875:INFO:Initializing Huber Regressor
2024-12-24 13:58:04,875:INFO:Total runtime is 0.13061799208323163 minutes
2024-12-24 13:58:04,877:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:04,878:INFO:Initializing create_model()
2024-12-24 13:58:04,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:04,878:INFO:Checking exceptions
2024-12-24 13:58:04,879:INFO:Importing libraries
2024-12-24 13:58:04,879:INFO:Copying training dataset
2024-12-24 13:58:04,882:INFO:Defining folds
2024-12-24 13:58:04,882:INFO:Declaring metric variables
2024-12-24 13:58:04,884:INFO:Importing untrained model
2024-12-24 13:58:04,886:INFO:Huber Regressor Imported successfully
2024-12-24 13:58:04,891:INFO:Starting cross validation
2024-12-24 13:58:04,893:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:04,971:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 13:58:04,971:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 13:58:04,984:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 13:58:04,991:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 13:58:04,996:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 13:58:05,023:INFO:Calculating mean and std
2024-12-24 13:58:05,024:INFO:Creating metrics dataframe
2024-12-24 13:58:05,025:INFO:Uploading results into container
2024-12-24 13:58:05,026:INFO:Uploading model into container now
2024-12-24 13:58:05,026:INFO:_master_model_container: 10
2024-12-24 13:58:05,026:INFO:_display_container: 2
2024-12-24 13:58:05,026:INFO:HuberRegressor()
2024-12-24 13:58:05,026:INFO:create_model() successfully completed......................................
2024-12-24 13:58:05,125:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:05,125:INFO:Creating metrics dataframe
2024-12-24 13:58:05,133:INFO:Initializing K Neighbors Regressor
2024-12-24 13:58:05,133:INFO:Total runtime is 0.1349165479342143 minutes
2024-12-24 13:58:05,135:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:05,135:INFO:Initializing create_model()
2024-12-24 13:58:05,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:05,135:INFO:Checking exceptions
2024-12-24 13:58:05,137:INFO:Importing libraries
2024-12-24 13:58:05,137:INFO:Copying training dataset
2024-12-24 13:58:05,140:INFO:Defining folds
2024-12-24 13:58:05,141:INFO:Declaring metric variables
2024-12-24 13:58:05,143:INFO:Importing untrained model
2024-12-24 13:58:05,147:INFO:K Neighbors Regressor Imported successfully
2024-12-24 13:58:05,151:INFO:Starting cross validation
2024-12-24 13:58:05,152:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:05,259:INFO:Calculating mean and std
2024-12-24 13:58:05,260:INFO:Creating metrics dataframe
2024-12-24 13:58:05,262:INFO:Uploading results into container
2024-12-24 13:58:05,262:INFO:Uploading model into container now
2024-12-24 13:58:05,263:INFO:_master_model_container: 11
2024-12-24 13:58:05,263:INFO:_display_container: 2
2024-12-24 13:58:05,263:INFO:KNeighborsRegressor(n_jobs=-1)
2024-12-24 13:58:05,263:INFO:create_model() successfully completed......................................
2024-12-24 13:58:05,363:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:05,363:INFO:Creating metrics dataframe
2024-12-24 13:58:05,370:INFO:Initializing Decision Tree Regressor
2024-12-24 13:58:05,370:INFO:Total runtime is 0.138861350218455 minutes
2024-12-24 13:58:05,373:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:05,373:INFO:Initializing create_model()
2024-12-24 13:58:05,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:05,373:INFO:Checking exceptions
2024-12-24 13:58:05,373:INFO:Importing libraries
2024-12-24 13:58:05,373:INFO:Copying training dataset
2024-12-24 13:58:05,378:INFO:Defining folds
2024-12-24 13:58:05,378:INFO:Declaring metric variables
2024-12-24 13:58:05,380:INFO:Importing untrained model
2024-12-24 13:58:05,382:INFO:Decision Tree Regressor Imported successfully
2024-12-24 13:58:05,387:INFO:Starting cross validation
2024-12-24 13:58:05,388:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:05,491:INFO:Calculating mean and std
2024-12-24 13:58:05,493:INFO:Creating metrics dataframe
2024-12-24 13:58:05,494:INFO:Uploading results into container
2024-12-24 13:58:05,495:INFO:Uploading model into container now
2024-12-24 13:58:05,495:INFO:_master_model_container: 12
2024-12-24 13:58:05,495:INFO:_display_container: 2
2024-12-24 13:58:05,496:INFO:DecisionTreeRegressor(random_state=5010)
2024-12-24 13:58:05,496:INFO:create_model() successfully completed......................................
2024-12-24 13:58:05,596:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:05,596:INFO:Creating metrics dataframe
2024-12-24 13:58:05,603:INFO:Initializing Random Forest Regressor
2024-12-24 13:58:05,604:INFO:Total runtime is 0.1427647034327189 minutes
2024-12-24 13:58:05,606:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:05,607:INFO:Initializing create_model()
2024-12-24 13:58:05,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:05,607:INFO:Checking exceptions
2024-12-24 13:58:05,607:INFO:Importing libraries
2024-12-24 13:58:05,607:INFO:Copying training dataset
2024-12-24 13:58:05,611:INFO:Defining folds
2024-12-24 13:58:05,611:INFO:Declaring metric variables
2024-12-24 13:58:05,614:INFO:Importing untrained model
2024-12-24 13:58:05,617:INFO:Random Forest Regressor Imported successfully
2024-12-24 13:58:05,622:INFO:Starting cross validation
2024-12-24 13:58:05,624:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:05,822:INFO:Calculating mean and std
2024-12-24 13:58:05,824:INFO:Creating metrics dataframe
2024-12-24 13:58:05,825:INFO:Uploading results into container
2024-12-24 13:58:05,826:INFO:Uploading model into container now
2024-12-24 13:58:05,826:INFO:_master_model_container: 13
2024-12-24 13:58:05,826:INFO:_display_container: 2
2024-12-24 13:58:05,827:INFO:RandomForestRegressor(n_jobs=-1, random_state=5010)
2024-12-24 13:58:05,827:INFO:create_model() successfully completed......................................
2024-12-24 13:58:05,924:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:05,924:INFO:Creating metrics dataframe
2024-12-24 13:58:05,933:INFO:Initializing Extra Trees Regressor
2024-12-24 13:58:05,933:INFO:Total runtime is 0.1482439637184143 minutes
2024-12-24 13:58:05,935:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:05,936:INFO:Initializing create_model()
2024-12-24 13:58:05,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:05,936:INFO:Checking exceptions
2024-12-24 13:58:05,936:INFO:Importing libraries
2024-12-24 13:58:05,936:INFO:Copying training dataset
2024-12-24 13:58:05,940:INFO:Defining folds
2024-12-24 13:58:05,940:INFO:Declaring metric variables
2024-12-24 13:58:05,943:INFO:Importing untrained model
2024-12-24 13:58:05,945:INFO:Extra Trees Regressor Imported successfully
2024-12-24 13:58:05,950:INFO:Starting cross validation
2024-12-24 13:58:05,951:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:06,118:INFO:Calculating mean and std
2024-12-24 13:58:06,119:INFO:Creating metrics dataframe
2024-12-24 13:58:06,121:INFO:Uploading results into container
2024-12-24 13:58:06,121:INFO:Uploading model into container now
2024-12-24 13:58:06,123:INFO:_master_model_container: 14
2024-12-24 13:58:06,123:INFO:_display_container: 2
2024-12-24 13:58:06,123:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5010)
2024-12-24 13:58:06,123:INFO:create_model() successfully completed......................................
2024-12-24 13:58:06,224:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:06,224:INFO:Creating metrics dataframe
2024-12-24 13:58:06,231:INFO:Initializing AdaBoost Regressor
2024-12-24 13:58:06,231:INFO:Total runtime is 0.15320804913838704 minutes
2024-12-24 13:58:06,234:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:06,234:INFO:Initializing create_model()
2024-12-24 13:58:06,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:06,234:INFO:Checking exceptions
2024-12-24 13:58:06,234:INFO:Importing libraries
2024-12-24 13:58:06,235:INFO:Copying training dataset
2024-12-24 13:58:06,239:INFO:Defining folds
2024-12-24 13:58:06,239:INFO:Declaring metric variables
2024-12-24 13:58:06,241:INFO:Importing untrained model
2024-12-24 13:58:06,243:INFO:AdaBoost Regressor Imported successfully
2024-12-24 13:58:06,249:INFO:Starting cross validation
2024-12-24 13:58:06,250:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:06,352:INFO:Calculating mean and std
2024-12-24 13:58:06,353:INFO:Creating metrics dataframe
2024-12-24 13:58:06,356:INFO:Uploading results into container
2024-12-24 13:58:06,357:INFO:Uploading model into container now
2024-12-24 13:58:06,357:INFO:_master_model_container: 15
2024-12-24 13:58:06,357:INFO:_display_container: 2
2024-12-24 13:58:06,357:INFO:AdaBoostRegressor(random_state=5010)
2024-12-24 13:58:06,357:INFO:create_model() successfully completed......................................
2024-12-24 13:58:06,458:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:06,458:INFO:Creating metrics dataframe
2024-12-24 13:58:06,466:INFO:Initializing Gradient Boosting Regressor
2024-12-24 13:58:06,466:INFO:Total runtime is 0.1571356733640035 minutes
2024-12-24 13:58:06,469:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:06,469:INFO:Initializing create_model()
2024-12-24 13:58:06,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:06,471:INFO:Checking exceptions
2024-12-24 13:58:06,471:INFO:Importing libraries
2024-12-24 13:58:06,471:INFO:Copying training dataset
2024-12-24 13:58:06,473:INFO:Defining folds
2024-12-24 13:58:06,473:INFO:Declaring metric variables
2024-12-24 13:58:06,475:INFO:Importing untrained model
2024-12-24 13:58:06,478:INFO:Gradient Boosting Regressor Imported successfully
2024-12-24 13:58:06,483:INFO:Starting cross validation
2024-12-24 13:58:06,484:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:06,639:INFO:Calculating mean and std
2024-12-24 13:58:06,640:INFO:Creating metrics dataframe
2024-12-24 13:58:06,642:INFO:Uploading results into container
2024-12-24 13:58:06,642:INFO:Uploading model into container now
2024-12-24 13:58:06,642:INFO:_master_model_container: 16
2024-12-24 13:58:06,642:INFO:_display_container: 2
2024-12-24 13:58:06,644:INFO:GradientBoostingRegressor(random_state=5010)
2024-12-24 13:58:06,644:INFO:create_model() successfully completed......................................
2024-12-24 13:58:06,745:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:06,746:INFO:Creating metrics dataframe
2024-12-24 13:58:06,754:INFO:Initializing Extreme Gradient Boosting
2024-12-24 13:58:06,754:INFO:Total runtime is 0.16193575461705526 minutes
2024-12-24 13:58:06,756:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:06,758:INFO:Initializing create_model()
2024-12-24 13:58:06,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:06,758:INFO:Checking exceptions
2024-12-24 13:58:06,758:INFO:Importing libraries
2024-12-24 13:58:06,758:INFO:Copying training dataset
2024-12-24 13:58:06,761:INFO:Defining folds
2024-12-24 13:58:06,761:INFO:Declaring metric variables
2024-12-24 13:58:06,763:INFO:Importing untrained model
2024-12-24 13:58:06,766:INFO:Extreme Gradient Boosting Imported successfully
2024-12-24 13:58:06,770:INFO:Starting cross validation
2024-12-24 13:58:06,772:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:08,932:INFO:Calculating mean and std
2024-12-24 13:58:08,933:INFO:Creating metrics dataframe
2024-12-24 13:58:08,936:INFO:Uploading results into container
2024-12-24 13:58:08,936:INFO:Uploading model into container now
2024-12-24 13:58:08,937:INFO:_master_model_container: 17
2024-12-24 13:58:08,937:INFO:_display_container: 2
2024-12-24 13:58:08,938:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=5010, ...)
2024-12-24 13:58:08,938:INFO:create_model() successfully completed......................................
2024-12-24 13:58:09,058:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:09,058:INFO:Creating metrics dataframe
2024-12-24 13:58:09,068:INFO:Initializing Light Gradient Boosting Machine
2024-12-24 13:58:09,068:INFO:Total runtime is 0.20049995183944702 minutes
2024-12-24 13:58:09,071:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:09,071:INFO:Initializing create_model()
2024-12-24 13:58:09,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:09,072:INFO:Checking exceptions
2024-12-24 13:58:09,072:INFO:Importing libraries
2024-12-24 13:58:09,072:INFO:Copying training dataset
2024-12-24 13:58:09,075:INFO:Defining folds
2024-12-24 13:58:09,075:INFO:Declaring metric variables
2024-12-24 13:58:09,077:INFO:Importing untrained model
2024-12-24 13:58:09,079:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 13:58:09,084:INFO:Starting cross validation
2024-12-24 13:58:09,086:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:10,776:INFO:Calculating mean and std
2024-12-24 13:58:10,777:INFO:Creating metrics dataframe
2024-12-24 13:58:10,779:INFO:Uploading results into container
2024-12-24 13:58:10,779:INFO:Uploading model into container now
2024-12-24 13:58:10,779:INFO:_master_model_container: 18
2024-12-24 13:58:10,780:INFO:_display_container: 2
2024-12-24 13:58:10,780:INFO:LGBMRegressor(n_jobs=-1, random_state=5010)
2024-12-24 13:58:10,780:INFO:create_model() successfully completed......................................
2024-12-24 13:58:10,885:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:10,886:INFO:Creating metrics dataframe
2024-12-24 13:58:10,894:INFO:Initializing CatBoost Regressor
2024-12-24 13:58:10,894:INFO:Total runtime is 0.23092818657557168 minutes
2024-12-24 13:58:10,897:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:10,897:INFO:Initializing create_model()
2024-12-24 13:58:10,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:10,897:INFO:Checking exceptions
2024-12-24 13:58:10,897:INFO:Importing libraries
2024-12-24 13:58:10,898:INFO:Copying training dataset
2024-12-24 13:58:10,902:INFO:Defining folds
2024-12-24 13:58:10,902:INFO:Declaring metric variables
2024-12-24 13:58:10,905:INFO:Importing untrained model
2024-12-24 13:58:10,912:INFO:CatBoost Regressor Imported successfully
2024-12-24 13:58:10,918:INFO:Starting cross validation
2024-12-24 13:58:10,919:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:14,102:WARNING:D:\Anaconda\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 276, in fit
    fitted_estimator = self._memory_fit(
  File "D:\Anaconda\lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "D:\Anaconda\lib\site-packages\catboost\core.py", line 5807, in fit
    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,
  File "D:\Anaconda\lib\site-packages\catboost\core.py", line 2396, in _fit
    self._train(
  File "D:\Anaconda\lib\site-packages\catboost\core.py", line 1776, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4833, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4882, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-12-24 13:58:14,102:INFO:Calculating mean and std
2024-12-24 13:58:14,103:INFO:Creating metrics dataframe
2024-12-24 13:58:14,105:INFO:Uploading results into container
2024-12-24 13:58:14,105:INFO:Uploading model into container now
2024-12-24 13:58:14,106:INFO:_master_model_container: 19
2024-12-24 13:58:14,106:INFO:_display_container: 2
2024-12-24 13:58:14,106:INFO:<catboost.core.CatBoostRegressor object at 0x000001928F62C7C0>
2024-12-24 13:58:14,106:INFO:create_model() successfully completed......................................
2024-12-24 13:58:14,211:WARNING:create_model() for <catboost.core.CatBoostRegressor object at 0x000001928F62C7C0> raised an exception or returned all 0.0, trying without fit_kwargs:
2024-12-24 13:58:14,214:WARNING:Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-12-24 13:58:14,214:INFO:Initializing create_model()
2024-12-24 13:58:14,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:14,214:INFO:Checking exceptions
2024-12-24 13:58:14,214:INFO:Importing libraries
2024-12-24 13:58:14,214:INFO:Copying training dataset
2024-12-24 13:58:14,218:INFO:Defining folds
2024-12-24 13:58:14,218:INFO:Declaring metric variables
2024-12-24 13:58:14,221:INFO:Importing untrained model
2024-12-24 13:58:14,223:INFO:CatBoost Regressor Imported successfully
2024-12-24 13:58:14,228:INFO:Starting cross validation
2024-12-24 13:58:14,229:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:17,696:INFO:Calculating mean and std
2024-12-24 13:58:17,698:INFO:Creating metrics dataframe
2024-12-24 13:58:17,700:INFO:Uploading results into container
2024-12-24 13:58:17,700:INFO:Uploading model into container now
2024-12-24 13:58:17,701:INFO:_master_model_container: 20
2024-12-24 13:58:17,701:INFO:_display_container: 2
2024-12-24 13:58:17,701:INFO:<catboost.core.CatBoostRegressor object at 0x000001928F62C5E0>
2024-12-24 13:58:17,701:INFO:create_model() successfully completed......................................
2024-12-24 13:58:17,809:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:17,810:INFO:Creating metrics dataframe
2024-12-24 13:58:17,818:INFO:Initializing Dummy Regressor
2024-12-24 13:58:17,818:INFO:Total runtime is 0.3463285366694132 minutes
2024-12-24 13:58:17,821:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:17,821:INFO:Initializing create_model()
2024-12-24 13:58:17,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F616C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:17,821:INFO:Checking exceptions
2024-12-24 13:58:17,821:INFO:Importing libraries
2024-12-24 13:58:17,821:INFO:Copying training dataset
2024-12-24 13:58:17,825:INFO:Defining folds
2024-12-24 13:58:17,825:INFO:Declaring metric variables
2024-12-24 13:58:17,828:INFO:Importing untrained model
2024-12-24 13:58:17,830:INFO:Dummy Regressor Imported successfully
2024-12-24 13:58:17,835:INFO:Starting cross validation
2024-12-24 13:58:17,836:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:19,444:INFO:Calculating mean and std
2024-12-24 13:58:19,447:INFO:Creating metrics dataframe
2024-12-24 13:58:19,449:INFO:Uploading results into container
2024-12-24 13:58:19,449:INFO:Uploading model into container now
2024-12-24 13:58:19,449:INFO:_master_model_container: 21
2024-12-24 13:58:19,449:INFO:_display_container: 2
2024-12-24 13:58:19,450:INFO:DummyRegressor()
2024-12-24 13:58:19,450:INFO:create_model() successfully completed......................................
2024-12-24 13:58:19,556:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:19,557:INFO:Creating metrics dataframe
2024-12-24 13:58:19,565:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-24 13:58:19,572:INFO:Initializing create_model()
2024-12-24 13:58:19,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=Ridge(random_state=5010), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:19,572:INFO:Checking exceptions
2024-12-24 13:58:19,573:INFO:Importing libraries
2024-12-24 13:58:19,574:INFO:Copying training dataset
2024-12-24 13:58:19,577:INFO:Defining folds
2024-12-24 13:58:19,577:INFO:Declaring metric variables
2024-12-24 13:58:19,577:INFO:Importing untrained model
2024-12-24 13:58:19,577:INFO:Declaring custom model
2024-12-24 13:58:19,578:INFO:Ridge Regression Imported successfully
2024-12-24 13:58:19,579:INFO:Cross validation set to False
2024-12-24 13:58:19,579:INFO:Fitting Model
2024-12-24 13:58:19,635:INFO:Ridge(random_state=5010)
2024-12-24 13:58:19,635:INFO:create_model() successfully completed......................................
2024-12-24 13:58:19,763:INFO:_master_model_container: 21
2024-12-24 13:58:19,763:INFO:_display_container: 2
2024-12-24 13:58:19,765:INFO:Ridge(random_state=5010)
2024-12-24 13:58:19,765:INFO:compare_models() successfully completed......................................
2024-12-24 13:58:22,944:INFO:Initializing tune_model()
2024-12-24 13:58:22,944:INFO:tune_model(estimator=Ridge(random_state=5010), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>)
2024-12-24 13:58:22,944:INFO:Checking exceptions
2024-12-24 13:58:22,958:INFO:Copying training dataset
2024-12-24 13:58:22,961:INFO:Checking base model
2024-12-24 13:58:22,961:INFO:Base model : Ridge Regression
2024-12-24 13:58:22,965:INFO:Declaring metric variables
2024-12-24 13:58:22,969:INFO:Defining Hyperparameters
2024-12-24 13:58:23,071:INFO:Tuning with n_jobs=-1
2024-12-24 13:58:23,071:INFO:Initializing RandomizedSearchCV
2024-12-24 13:58:23,814:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 8.45}
2024-12-24 13:58:23,814:INFO:Hyperparameter search completed
2024-12-24 13:58:23,814:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:23,814:INFO:Initializing create_model()
2024-12-24 13:58:23,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=Ridge(random_state=5010), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F48CF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 8.45})
2024-12-24 13:58:23,814:INFO:Checking exceptions
2024-12-24 13:58:23,815:INFO:Importing libraries
2024-12-24 13:58:23,815:INFO:Copying training dataset
2024-12-24 13:58:23,818:INFO:Defining folds
2024-12-24 13:58:23,818:INFO:Declaring metric variables
2024-12-24 13:58:23,824:INFO:Importing untrained model
2024-12-24 13:58:23,824:INFO:Declaring custom model
2024-12-24 13:58:23,830:INFO:Ridge Regression Imported successfully
2024-12-24 13:58:23,839:INFO:Starting cross validation
2024-12-24 13:58:23,841:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:23,952:INFO:Calculating mean and std
2024-12-24 13:58:23,953:INFO:Creating metrics dataframe
2024-12-24 13:58:23,959:INFO:Finalizing model
2024-12-24 13:58:24,008:INFO:Uploading results into container
2024-12-24 13:58:24,008:INFO:Uploading model into container now
2024-12-24 13:58:24,008:INFO:_master_model_container: 22
2024-12-24 13:58:24,008:INFO:_display_container: 3
2024-12-24 13:58:24,009:INFO:Ridge(alpha=8.45, random_state=5010)
2024-12-24 13:58:24,009:INFO:create_model() successfully completed......................................
2024-12-24 13:58:24,111:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:24,111:INFO:choose_better activated
2024-12-24 13:58:24,115:INFO:SubProcess create_model() called ==================================
2024-12-24 13:58:24,116:INFO:Initializing create_model()
2024-12-24 13:58:24,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928807EF80>, estimator=Ridge(random_state=5010), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 13:58:24,116:INFO:Checking exceptions
2024-12-24 13:58:24,118:INFO:Importing libraries
2024-12-24 13:58:24,118:INFO:Copying training dataset
2024-12-24 13:58:24,122:INFO:Defining folds
2024-12-24 13:58:24,122:INFO:Declaring metric variables
2024-12-24 13:58:24,122:INFO:Importing untrained model
2024-12-24 13:58:24,122:INFO:Declaring custom model
2024-12-24 13:58:24,122:INFO:Ridge Regression Imported successfully
2024-12-24 13:58:24,123:INFO:Starting cross validation
2024-12-24 13:58:24,124:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 13:58:24,241:INFO:Calculating mean and std
2024-12-24 13:58:24,241:INFO:Creating metrics dataframe
2024-12-24 13:58:24,242:INFO:Finalizing model
2024-12-24 13:58:24,285:INFO:Uploading results into container
2024-12-24 13:58:24,286:INFO:Uploading model into container now
2024-12-24 13:58:24,286:INFO:_master_model_container: 23
2024-12-24 13:58:24,286:INFO:_display_container: 4
2024-12-24 13:58:24,286:INFO:Ridge(random_state=5010)
2024-12-24 13:58:24,286:INFO:create_model() successfully completed......................................
2024-12-24 13:58:24,397:INFO:SubProcess create_model() end ==================================
2024-12-24 13:58:24,398:INFO:Ridge(random_state=5010) result for R2 is 0.2645
2024-12-24 13:58:24,398:INFO:Ridge(alpha=8.45, random_state=5010) result for R2 is 0.3747
2024-12-24 13:58:24,398:INFO:Ridge(alpha=8.45, random_state=5010) is best model
2024-12-24 13:58:24,398:INFO:choose_better completed
2024-12-24 13:58:24,406:INFO:_master_model_container: 23
2024-12-24 13:58:24,406:INFO:_display_container: 3
2024-12-24 13:58:24,406:INFO:Ridge(alpha=8.45, random_state=5010)
2024-12-24 13:58:24,406:INFO:tune_model() successfully completed......................................
2024-12-24 14:04:42,332:INFO:PyCaret RegressionExperiment
2024-12-24 14:04:42,332:INFO:Logging name: reg-default-name
2024-12-24 14:04:42,332:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-24 14:04:42,332:INFO:version 3.3.1
2024-12-24 14:04:42,332:INFO:Initializing setup()
2024-12-24 14:04:42,332:INFO:self.USI: 17f4
2024-12-24 14:04:42,332:INFO:self._variable_keys: {'_available_plots', 'data', 'y_test', 'html_param', 'pipeline', 'X_test', '_ml_usecase', 'idx', 'target_param', 'fold_generator', 'seed', 'X_train', 'X', 'fold_groups_param', 'transform_target_param', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'y_train', 'fold_shuffle_param', 'y', 'USI', 'gpu_param', 'logging_param', 'exp_name_log', 'memory', 'log_plots_param'}
2024-12-24 14:04:42,332:INFO:Checking environment
2024-12-24 14:04:42,332:INFO:python_version: 3.10.15
2024-12-24 14:04:42,332:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-24 14:04:42,332:INFO:machine: AMD64
2024-12-24 14:04:42,333:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-24 14:04:42,333:INFO:Memory: svmem(total=16312721408, available=4241248256, percent=74.0, used=12071473152, free=4241248256)
2024-12-24 14:04:42,333:INFO:Physical Core: 6
2024-12-24 14:04:42,333:INFO:Logical Core: 12
2024-12-24 14:04:42,333:INFO:Checking libraries
2024-12-24 14:04:42,333:INFO:System:
2024-12-24 14:04:42,333:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-24 14:04:42,333:INFO:executable: D:\Anaconda\python.exe
2024-12-24 14:04:42,333:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-24 14:04:42,333:INFO:PyCaret required dependencies:
2024-12-24 14:04:42,333:INFO:                 pip: 24.2
2024-12-24 14:04:42,333:INFO:          setuptools: 75.1.0
2024-12-24 14:04:42,333:INFO:             pycaret: 3.3.1
2024-12-24 14:04:42,333:INFO:             IPython: 8.27.0
2024-12-24 14:04:42,333:INFO:          ipywidgets: 8.1.2
2024-12-24 14:04:42,333:INFO:                tqdm: 4.66.5
2024-12-24 14:04:42,333:INFO:               numpy: 1.26.4
2024-12-24 14:04:42,333:INFO:              pandas: 2.1.4
2024-12-24 14:04:42,334:INFO:              jinja2: 3.1.4
2024-12-24 14:04:42,334:INFO:               scipy: 1.11.4
2024-12-24 14:04:42,334:INFO:              joblib: 1.2.0
2024-12-24 14:04:42,334:INFO:             sklearn: 1.4.2
2024-12-24 14:04:42,334:INFO:                pyod: 2.0.2
2024-12-24 14:04:42,334:INFO:            imblearn: 0.12.3
2024-12-24 14:04:42,334:INFO:   category_encoders: 2.6.3
2024-12-24 14:04:42,334:INFO:            lightgbm: 4.5.0
2024-12-24 14:04:42,334:INFO:               numba: 0.60.0
2024-12-24 14:04:42,334:INFO:            requests: 2.32.3
2024-12-24 14:04:42,334:INFO:          matplotlib: 3.9.2
2024-12-24 14:04:42,334:INFO:          scikitplot: 0.3.7
2024-12-24 14:04:42,334:INFO:         yellowbrick: 1.5
2024-12-24 14:04:42,334:INFO:              plotly: 5.24.1
2024-12-24 14:04:42,334:INFO:    plotly-resampler: Not installed
2024-12-24 14:04:42,334:INFO:             kaleido: 0.2.1
2024-12-24 14:04:42,334:INFO:           schemdraw: 0.15
2024-12-24 14:04:42,334:INFO:         statsmodels: 0.14.2
2024-12-24 14:04:42,334:INFO:              sktime: 0.26.0
2024-12-24 14:04:42,334:INFO:               tbats: 1.1.3
2024-12-24 14:04:42,334:INFO:            pmdarima: 2.0.4
2024-12-24 14:04:42,334:INFO:              psutil: 5.9.0
2024-12-24 14:04:42,334:INFO:          markupsafe: 2.1.3
2024-12-24 14:04:42,334:INFO:             pickle5: Not installed
2024-12-24 14:04:42,334:INFO:         cloudpickle: 3.0.0
2024-12-24 14:04:42,334:INFO:         deprecation: 2.1.0
2024-12-24 14:04:42,334:INFO:              xxhash: 2.0.2
2024-12-24 14:04:42,334:INFO:           wurlitzer: 3.1.1
2024-12-24 14:04:42,334:INFO:PyCaret optional dependencies:
2024-12-24 14:04:42,335:INFO:                shap: Not installed
2024-12-24 14:04:42,335:INFO:           interpret: Not installed
2024-12-24 14:04:42,335:INFO:                umap: 0.5.3
2024-12-24 14:04:42,335:INFO:     ydata_profiling: Not installed
2024-12-24 14:04:42,335:INFO:  explainerdashboard: Not installed
2024-12-24 14:04:42,335:INFO:             autoviz: Not installed
2024-12-24 14:04:42,335:INFO:           fairlearn: Not installed
2024-12-24 14:04:42,335:INFO:          deepchecks: Not installed
2024-12-24 14:04:42,335:INFO:             xgboost: 2.1.2
2024-12-24 14:04:42,335:INFO:            catboost: 1.2.3
2024-12-24 14:04:42,335:INFO:              kmodes: 0.12.2
2024-12-24 14:04:42,335:INFO:             mlxtend: 0.23.1
2024-12-24 14:04:42,335:INFO:       statsforecast: Not installed
2024-12-24 14:04:42,335:INFO:        tune_sklearn: Not installed
2024-12-24 14:04:42,335:INFO:                 ray: Not installed
2024-12-24 14:04:42,335:INFO:            hyperopt: Not installed
2024-12-24 14:04:42,335:INFO:              optuna: Not installed
2024-12-24 14:04:42,336:INFO:               skopt: Not installed
2024-12-24 14:04:42,336:INFO:              mlflow: 2.16.2
2024-12-24 14:04:42,336:INFO:              gradio: Not installed
2024-12-24 14:04:42,336:INFO:             fastapi: Not installed
2024-12-24 14:04:42,336:INFO:             uvicorn: Not installed
2024-12-24 14:04:42,336:INFO:              m2cgen: Not installed
2024-12-24 14:04:42,336:INFO:           evidently: Not installed
2024-12-24 14:04:42,336:INFO:               fugue: Not installed
2024-12-24 14:04:42,336:INFO:           streamlit: Not installed
2024-12-24 14:04:42,336:INFO:             prophet: Not installed
2024-12-24 14:04:42,336:INFO:None
2024-12-24 14:04:42,336:INFO:Set up data.
2024-12-24 14:04:42,342:INFO:Set up folding strategy.
2024-12-24 14:04:42,342:INFO:Set up train/test split.
2024-12-24 14:04:42,345:INFO:Set up index.
2024-12-24 14:04:42,346:INFO:Assigning column types.
2024-12-24 14:04:42,348:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-24 14:04:42,349:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,353:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,357:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,435:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,438:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:42,439:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,442:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,523:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,525:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:42,526:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-24 14:04:42,529:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,533:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,611:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,613:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:42,617:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,664:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,699:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,701:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:42,702:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-24 14:04:42,709:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,787:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,789:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:42,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,875:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,877:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:42,878:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-24 14:04:42,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:42,963:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:42,965:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:43,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:04:43,050:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,052:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,052:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-24 14:04:43,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:43,138:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,140:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-24 14:04:43,225:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,227:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,228:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-24 14:04:43,312:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,314:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,400:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,402:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,403:INFO:Preparing preprocessing pipeline...
2024-12-24 14:04:43,404:INFO:Set up simple imputation.
2024-12-24 14:04:43,406:INFO:Set up encoding of ordinal features.
2024-12-24 14:04:43,407:INFO:Set up encoding of categorical features.
2024-12-24 14:04:43,487:INFO:Finished creating preprocessing pipeline.
2024-12-24 14:04:43,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket'],
                                                              handle_missing='return_nan')))])
2024-12-24 14:04:43,504:INFO:Creating final display dataframe.
2024-12-24 14:04:43,818:INFO:Setup _display_container:                     Description             Value
0                    Session id              6105
1                        Target          Survived
2                   Target type        Regression
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 13)
5   Transformed train set shape         (623, 13)
6    Transformed test set shape         (268, 13)
7              Numeric features                 6
8          Categorical features                 4
9      Rows with missing values             20.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                 5
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              17f4
2024-12-24 14:04:43,910:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,912:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,995:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:04:43,997:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:04:43,998:INFO:setup() successfully completed in 1.67s...............
2024-12-24 14:04:45,986:INFO:Initializing compare_models()
2024-12-24 14:04:45,987:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-12-24 14:04:45,987:INFO:Checking exceptions
2024-12-24 14:04:45,988:INFO:Preparing display monitor
2024-12-24 14:04:46,007:INFO:Initializing Linear Regression
2024-12-24 14:04:46,007:INFO:Total runtime is 0.0 minutes
2024-12-24 14:04:46,009:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:46,011:INFO:Initializing create_model()
2024-12-24 14:04:46,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:46,011:INFO:Checking exceptions
2024-12-24 14:04:46,011:INFO:Importing libraries
2024-12-24 14:04:46,011:INFO:Copying training dataset
2024-12-24 14:04:46,016:INFO:Defining folds
2024-12-24 14:04:46,016:INFO:Declaring metric variables
2024-12-24 14:04:46,019:INFO:Importing untrained model
2024-12-24 14:04:46,021:INFO:Linear Regression Imported successfully
2024-12-24 14:04:46,027:INFO:Starting cross validation
2024-12-24 14:04:46,028:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:49,113:INFO:Calculating mean and std
2024-12-24 14:04:49,114:INFO:Creating metrics dataframe
2024-12-24 14:04:49,117:INFO:Uploading results into container
2024-12-24 14:04:49,118:INFO:Uploading model into container now
2024-12-24 14:04:49,118:INFO:_master_model_container: 1
2024-12-24 14:04:49,119:INFO:_display_container: 2
2024-12-24 14:04:49,119:INFO:LinearRegression(n_jobs=-1)
2024-12-24 14:04:49,119:INFO:create_model() successfully completed......................................
2024-12-24 14:04:49,236:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:49,236:INFO:Creating metrics dataframe
2024-12-24 14:04:49,241:INFO:Initializing Lasso Regression
2024-12-24 14:04:49,241:INFO:Total runtime is 0.05390608708063761 minutes
2024-12-24 14:04:49,244:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:49,244:INFO:Initializing create_model()
2024-12-24 14:04:49,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:49,245:INFO:Checking exceptions
2024-12-24 14:04:49,245:INFO:Importing libraries
2024-12-24 14:04:49,245:INFO:Copying training dataset
2024-12-24 14:04:49,249:INFO:Defining folds
2024-12-24 14:04:49,250:INFO:Declaring metric variables
2024-12-24 14:04:49,252:INFO:Importing untrained model
2024-12-24 14:04:49,254:INFO:Lasso Regression Imported successfully
2024-12-24 14:04:49,259:INFO:Starting cross validation
2024-12-24 14:04:49,260:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:51,314:INFO:Calculating mean and std
2024-12-24 14:04:51,315:INFO:Creating metrics dataframe
2024-12-24 14:04:51,317:INFO:Uploading results into container
2024-12-24 14:04:51,318:INFO:Uploading model into container now
2024-12-24 14:04:51,319:INFO:_master_model_container: 2
2024-12-24 14:04:51,319:INFO:_display_container: 2
2024-12-24 14:04:51,319:INFO:Lasso(random_state=6105)
2024-12-24 14:04:51,319:INFO:create_model() successfully completed......................................
2024-12-24 14:04:51,426:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:51,427:INFO:Creating metrics dataframe
2024-12-24 14:04:51,432:INFO:Initializing Ridge Regression
2024-12-24 14:04:51,432:INFO:Total runtime is 0.09042512973149618 minutes
2024-12-24 14:04:51,435:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:51,435:INFO:Initializing create_model()
2024-12-24 14:04:51,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:51,435:INFO:Checking exceptions
2024-12-24 14:04:51,437:INFO:Importing libraries
2024-12-24 14:04:51,437:INFO:Copying training dataset
2024-12-24 14:04:51,440:INFO:Defining folds
2024-12-24 14:04:51,440:INFO:Declaring metric variables
2024-12-24 14:04:51,443:INFO:Importing untrained model
2024-12-24 14:04:51,446:INFO:Ridge Regression Imported successfully
2024-12-24 14:04:51,450:INFO:Starting cross validation
2024-12-24 14:04:51,451:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:53,079:INFO:Calculating mean and std
2024-12-24 14:04:53,081:INFO:Creating metrics dataframe
2024-12-24 14:04:53,082:INFO:Uploading results into container
2024-12-24 14:04:53,083:INFO:Uploading model into container now
2024-12-24 14:04:53,083:INFO:_master_model_container: 3
2024-12-24 14:04:53,083:INFO:_display_container: 2
2024-12-24 14:04:53,083:INFO:Ridge(random_state=6105)
2024-12-24 14:04:53,083:INFO:create_model() successfully completed......................................
2024-12-24 14:04:53,189:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:53,190:INFO:Creating metrics dataframe
2024-12-24 14:04:53,196:INFO:Initializing Elastic Net
2024-12-24 14:04:53,196:INFO:Total runtime is 0.11981093486150106 minutes
2024-12-24 14:04:53,198:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:53,199:INFO:Initializing create_model()
2024-12-24 14:04:53,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:53,199:INFO:Checking exceptions
2024-12-24 14:04:53,199:INFO:Importing libraries
2024-12-24 14:04:53,199:INFO:Copying training dataset
2024-12-24 14:04:53,203:INFO:Defining folds
2024-12-24 14:04:53,203:INFO:Declaring metric variables
2024-12-24 14:04:53,206:INFO:Importing untrained model
2024-12-24 14:04:53,208:INFO:Elastic Net Imported successfully
2024-12-24 14:04:53,213:INFO:Starting cross validation
2024-12-24 14:04:53,214:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:53,314:INFO:Calculating mean and std
2024-12-24 14:04:53,316:INFO:Creating metrics dataframe
2024-12-24 14:04:53,318:INFO:Uploading results into container
2024-12-24 14:04:53,318:INFO:Uploading model into container now
2024-12-24 14:04:53,319:INFO:_master_model_container: 4
2024-12-24 14:04:53,319:INFO:_display_container: 2
2024-12-24 14:04:53,319:INFO:ElasticNet(random_state=6105)
2024-12-24 14:04:53,319:INFO:create_model() successfully completed......................................
2024-12-24 14:04:53,420:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:53,420:INFO:Creating metrics dataframe
2024-12-24 14:04:53,426:INFO:Initializing Least Angle Regression
2024-12-24 14:04:53,426:INFO:Total runtime is 0.12364908854166667 minutes
2024-12-24 14:04:53,428:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:53,429:INFO:Initializing create_model()
2024-12-24 14:04:53,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:53,429:INFO:Checking exceptions
2024-12-24 14:04:53,429:INFO:Importing libraries
2024-12-24 14:04:53,430:INFO:Copying training dataset
2024-12-24 14:04:53,432:INFO:Defining folds
2024-12-24 14:04:53,432:INFO:Declaring metric variables
2024-12-24 14:04:53,435:INFO:Importing untrained model
2024-12-24 14:04:53,437:INFO:Least Angle Regression Imported successfully
2024-12-24 14:04:53,441:INFO:Starting cross validation
2024-12-24 14:04:53,442:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:53,542:INFO:Calculating mean and std
2024-12-24 14:04:53,543:INFO:Creating metrics dataframe
2024-12-24 14:04:53,545:INFO:Uploading results into container
2024-12-24 14:04:53,545:INFO:Uploading model into container now
2024-12-24 14:04:53,545:INFO:_master_model_container: 5
2024-12-24 14:04:53,545:INFO:_display_container: 2
2024-12-24 14:04:53,545:INFO:Lars(random_state=6105)
2024-12-24 14:04:53,545:INFO:create_model() successfully completed......................................
2024-12-24 14:04:53,645:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:53,646:INFO:Creating metrics dataframe
2024-12-24 14:04:53,652:INFO:Initializing Lasso Least Angle Regression
2024-12-24 14:04:53,652:INFO:Total runtime is 0.12742254734039307 minutes
2024-12-24 14:04:53,654:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:53,654:INFO:Initializing create_model()
2024-12-24 14:04:53,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:53,654:INFO:Checking exceptions
2024-12-24 14:04:53,654:INFO:Importing libraries
2024-12-24 14:04:53,654:INFO:Copying training dataset
2024-12-24 14:04:53,658:INFO:Defining folds
2024-12-24 14:04:53,658:INFO:Declaring metric variables
2024-12-24 14:04:53,661:INFO:Importing untrained model
2024-12-24 14:04:53,664:INFO:Lasso Least Angle Regression Imported successfully
2024-12-24 14:04:53,668:INFO:Starting cross validation
2024-12-24 14:04:53,669:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:53,768:INFO:Calculating mean and std
2024-12-24 14:04:53,769:INFO:Creating metrics dataframe
2024-12-24 14:04:53,771:INFO:Uploading results into container
2024-12-24 14:04:53,772:INFO:Uploading model into container now
2024-12-24 14:04:53,773:INFO:_master_model_container: 6
2024-12-24 14:04:53,773:INFO:_display_container: 2
2024-12-24 14:04:53,773:INFO:LassoLars(random_state=6105)
2024-12-24 14:04:53,773:INFO:create_model() successfully completed......................................
2024-12-24 14:04:53,873:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:53,874:INFO:Creating metrics dataframe
2024-12-24 14:04:53,881:INFO:Initializing Orthogonal Matching Pursuit
2024-12-24 14:04:53,881:INFO:Total runtime is 0.13122930924097698 minutes
2024-12-24 14:04:53,884:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:53,884:INFO:Initializing create_model()
2024-12-24 14:04:53,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:53,884:INFO:Checking exceptions
2024-12-24 14:04:53,884:INFO:Importing libraries
2024-12-24 14:04:53,884:INFO:Copying training dataset
2024-12-24 14:04:53,887:INFO:Defining folds
2024-12-24 14:04:53,887:INFO:Declaring metric variables
2024-12-24 14:04:53,890:INFO:Importing untrained model
2024-12-24 14:04:53,892:INFO:Orthogonal Matching Pursuit Imported successfully
2024-12-24 14:04:53,897:INFO:Starting cross validation
2024-12-24 14:04:53,899:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:54,000:INFO:Calculating mean and std
2024-12-24 14:04:54,001:INFO:Creating metrics dataframe
2024-12-24 14:04:54,003:INFO:Uploading results into container
2024-12-24 14:04:54,003:INFO:Uploading model into container now
2024-12-24 14:04:54,004:INFO:_master_model_container: 7
2024-12-24 14:04:54,004:INFO:_display_container: 2
2024-12-24 14:04:54,004:INFO:OrthogonalMatchingPursuit()
2024-12-24 14:04:54,005:INFO:create_model() successfully completed......................................
2024-12-24 14:04:54,104:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:54,105:INFO:Creating metrics dataframe
2024-12-24 14:04:54,111:INFO:Initializing Bayesian Ridge
2024-12-24 14:04:54,111:INFO:Total runtime is 0.13506580193837484 minutes
2024-12-24 14:04:54,114:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:54,114:INFO:Initializing create_model()
2024-12-24 14:04:54,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:54,114:INFO:Checking exceptions
2024-12-24 14:04:54,114:INFO:Importing libraries
2024-12-24 14:04:54,115:INFO:Copying training dataset
2024-12-24 14:04:54,118:INFO:Defining folds
2024-12-24 14:04:54,119:INFO:Declaring metric variables
2024-12-24 14:04:54,121:INFO:Importing untrained model
2024-12-24 14:04:54,123:INFO:Bayesian Ridge Imported successfully
2024-12-24 14:04:54,128:INFO:Starting cross validation
2024-12-24 14:04:54,129:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:54,226:INFO:Calculating mean and std
2024-12-24 14:04:54,227:INFO:Creating metrics dataframe
2024-12-24 14:04:54,229:INFO:Uploading results into container
2024-12-24 14:04:54,230:INFO:Uploading model into container now
2024-12-24 14:04:54,230:INFO:_master_model_container: 8
2024-12-24 14:04:54,230:INFO:_display_container: 2
2024-12-24 14:04:54,230:INFO:BayesianRidge()
2024-12-24 14:04:54,230:INFO:create_model() successfully completed......................................
2024-12-24 14:04:54,334:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:54,334:INFO:Creating metrics dataframe
2024-12-24 14:04:54,340:INFO:Initializing Passive Aggressive Regressor
2024-12-24 14:04:54,340:INFO:Total runtime is 0.13887846867243447 minutes
2024-12-24 14:04:54,343:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:54,343:INFO:Initializing create_model()
2024-12-24 14:04:54,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:54,344:INFO:Checking exceptions
2024-12-24 14:04:54,344:INFO:Importing libraries
2024-12-24 14:04:54,344:INFO:Copying training dataset
2024-12-24 14:04:54,347:INFO:Defining folds
2024-12-24 14:04:54,347:INFO:Declaring metric variables
2024-12-24 14:04:54,350:INFO:Importing untrained model
2024-12-24 14:04:54,353:INFO:Passive Aggressive Regressor Imported successfully
2024-12-24 14:04:54,358:INFO:Starting cross validation
2024-12-24 14:04:54,359:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:54,458:INFO:Calculating mean and std
2024-12-24 14:04:54,459:INFO:Creating metrics dataframe
2024-12-24 14:04:54,462:INFO:Uploading results into container
2024-12-24 14:04:54,462:INFO:Uploading model into container now
2024-12-24 14:04:54,463:INFO:_master_model_container: 9
2024-12-24 14:04:54,463:INFO:_display_container: 2
2024-12-24 14:04:54,463:INFO:PassiveAggressiveRegressor(random_state=6105)
2024-12-24 14:04:54,463:INFO:create_model() successfully completed......................................
2024-12-24 14:04:54,562:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:54,562:INFO:Creating metrics dataframe
2024-12-24 14:04:54,569:INFO:Initializing Huber Regressor
2024-12-24 14:04:54,569:INFO:Total runtime is 0.14270479281743367 minutes
2024-12-24 14:04:54,572:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:54,572:INFO:Initializing create_model()
2024-12-24 14:04:54,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:54,573:INFO:Checking exceptions
2024-12-24 14:04:54,573:INFO:Importing libraries
2024-12-24 14:04:54,573:INFO:Copying training dataset
2024-12-24 14:04:54,576:INFO:Defining folds
2024-12-24 14:04:54,576:INFO:Declaring metric variables
2024-12-24 14:04:54,579:INFO:Importing untrained model
2024-12-24 14:04:54,581:INFO:Huber Regressor Imported successfully
2024-12-24 14:04:54,586:INFO:Starting cross validation
2024-12-24 14:04:54,587:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:54,661:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 14:04:54,671:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 14:04:54,671:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 14:04:54,681:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 14:04:54,683:WARNING:D:\Anaconda\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-24 14:04:54,705:INFO:Calculating mean and std
2024-12-24 14:04:54,707:INFO:Creating metrics dataframe
2024-12-24 14:04:54,708:INFO:Uploading results into container
2024-12-24 14:04:54,710:INFO:Uploading model into container now
2024-12-24 14:04:54,710:INFO:_master_model_container: 10
2024-12-24 14:04:54,710:INFO:_display_container: 2
2024-12-24 14:04:54,711:INFO:HuberRegressor()
2024-12-24 14:04:54,711:INFO:create_model() successfully completed......................................
2024-12-24 14:04:54,811:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:54,812:INFO:Creating metrics dataframe
2024-12-24 14:04:54,820:INFO:Initializing K Neighbors Regressor
2024-12-24 14:04:54,820:INFO:Total runtime is 0.1468860944112142 minutes
2024-12-24 14:04:54,822:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:54,822:INFO:Initializing create_model()
2024-12-24 14:04:54,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:54,822:INFO:Checking exceptions
2024-12-24 14:04:54,823:INFO:Importing libraries
2024-12-24 14:04:54,823:INFO:Copying training dataset
2024-12-24 14:04:54,827:INFO:Defining folds
2024-12-24 14:04:54,827:INFO:Declaring metric variables
2024-12-24 14:04:54,829:INFO:Importing untrained model
2024-12-24 14:04:54,832:INFO:K Neighbors Regressor Imported successfully
2024-12-24 14:04:54,836:INFO:Starting cross validation
2024-12-24 14:04:54,837:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:54,949:INFO:Calculating mean and std
2024-12-24 14:04:54,950:INFO:Creating metrics dataframe
2024-12-24 14:04:54,952:INFO:Uploading results into container
2024-12-24 14:04:54,952:INFO:Uploading model into container now
2024-12-24 14:04:54,952:INFO:_master_model_container: 11
2024-12-24 14:04:54,953:INFO:_display_container: 2
2024-12-24 14:04:54,953:INFO:KNeighborsRegressor(n_jobs=-1)
2024-12-24 14:04:54,953:INFO:create_model() successfully completed......................................
2024-12-24 14:04:55,054:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:55,054:INFO:Creating metrics dataframe
2024-12-24 14:04:55,062:INFO:Initializing Decision Tree Regressor
2024-12-24 14:04:55,062:INFO:Total runtime is 0.1509139140446981 minutes
2024-12-24 14:04:55,064:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:55,065:INFO:Initializing create_model()
2024-12-24 14:04:55,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:55,065:INFO:Checking exceptions
2024-12-24 14:04:55,065:INFO:Importing libraries
2024-12-24 14:04:55,065:INFO:Copying training dataset
2024-12-24 14:04:55,069:INFO:Defining folds
2024-12-24 14:04:55,069:INFO:Declaring metric variables
2024-12-24 14:04:55,071:INFO:Importing untrained model
2024-12-24 14:04:55,074:INFO:Decision Tree Regressor Imported successfully
2024-12-24 14:04:55,079:INFO:Starting cross validation
2024-12-24 14:04:55,080:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:55,170:INFO:Calculating mean and std
2024-12-24 14:04:55,171:INFO:Creating metrics dataframe
2024-12-24 14:04:55,174:INFO:Uploading results into container
2024-12-24 14:04:55,174:INFO:Uploading model into container now
2024-12-24 14:04:55,174:INFO:_master_model_container: 12
2024-12-24 14:04:55,174:INFO:_display_container: 2
2024-12-24 14:04:55,175:INFO:DecisionTreeRegressor(random_state=6105)
2024-12-24 14:04:55,175:INFO:create_model() successfully completed......................................
2024-12-24 14:04:55,272:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:55,272:INFO:Creating metrics dataframe
2024-12-24 14:04:55,279:INFO:Initializing Random Forest Regressor
2024-12-24 14:04:55,279:INFO:Total runtime is 0.15453743934631348 minutes
2024-12-24 14:04:55,281:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:55,283:INFO:Initializing create_model()
2024-12-24 14:04:55,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:55,283:INFO:Checking exceptions
2024-12-24 14:04:55,283:INFO:Importing libraries
2024-12-24 14:04:55,283:INFO:Copying training dataset
2024-12-24 14:04:55,286:INFO:Defining folds
2024-12-24 14:04:55,287:INFO:Declaring metric variables
2024-12-24 14:04:55,289:INFO:Importing untrained model
2024-12-24 14:04:55,292:INFO:Random Forest Regressor Imported successfully
2024-12-24 14:04:55,297:INFO:Starting cross validation
2024-12-24 14:04:55,299:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:55,515:INFO:Calculating mean and std
2024-12-24 14:04:55,516:INFO:Creating metrics dataframe
2024-12-24 14:04:55,517:INFO:Uploading results into container
2024-12-24 14:04:55,517:INFO:Uploading model into container now
2024-12-24 14:04:55,519:INFO:_master_model_container: 13
2024-12-24 14:04:55,519:INFO:_display_container: 2
2024-12-24 14:04:55,519:INFO:RandomForestRegressor(n_jobs=-1, random_state=6105)
2024-12-24 14:04:55,519:INFO:create_model() successfully completed......................................
2024-12-24 14:04:55,620:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:55,621:INFO:Creating metrics dataframe
2024-12-24 14:04:55,628:INFO:Initializing Extra Trees Regressor
2024-12-24 14:04:55,628:INFO:Total runtime is 0.16035923560460408 minutes
2024-12-24 14:04:55,631:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:55,631:INFO:Initializing create_model()
2024-12-24 14:04:55,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:55,631:INFO:Checking exceptions
2024-12-24 14:04:55,633:INFO:Importing libraries
2024-12-24 14:04:55,633:INFO:Copying training dataset
2024-12-24 14:04:55,636:INFO:Defining folds
2024-12-24 14:04:55,636:INFO:Declaring metric variables
2024-12-24 14:04:55,638:INFO:Importing untrained model
2024-12-24 14:04:55,640:INFO:Extra Trees Regressor Imported successfully
2024-12-24 14:04:55,646:INFO:Starting cross validation
2024-12-24 14:04:55,648:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:55,828:INFO:Calculating mean and std
2024-12-24 14:04:55,830:INFO:Creating metrics dataframe
2024-12-24 14:04:55,832:INFO:Uploading results into container
2024-12-24 14:04:55,833:INFO:Uploading model into container now
2024-12-24 14:04:55,833:INFO:_master_model_container: 14
2024-12-24 14:04:55,833:INFO:_display_container: 2
2024-12-24 14:04:55,834:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6105)
2024-12-24 14:04:55,834:INFO:create_model() successfully completed......................................
2024-12-24 14:04:55,931:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:55,931:INFO:Creating metrics dataframe
2024-12-24 14:04:55,939:INFO:Initializing AdaBoost Regressor
2024-12-24 14:04:55,939:INFO:Total runtime is 0.16553858121236165 minutes
2024-12-24 14:04:55,941:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:55,942:INFO:Initializing create_model()
2024-12-24 14:04:55,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:55,942:INFO:Checking exceptions
2024-12-24 14:04:55,942:INFO:Importing libraries
2024-12-24 14:04:55,942:INFO:Copying training dataset
2024-12-24 14:04:55,945:INFO:Defining folds
2024-12-24 14:04:55,945:INFO:Declaring metric variables
2024-12-24 14:04:55,948:INFO:Importing untrained model
2024-12-24 14:04:55,951:INFO:AdaBoost Regressor Imported successfully
2024-12-24 14:04:55,955:INFO:Starting cross validation
2024-12-24 14:04:55,956:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:56,055:INFO:Calculating mean and std
2024-12-24 14:04:56,056:INFO:Creating metrics dataframe
2024-12-24 14:04:56,058:INFO:Uploading results into container
2024-12-24 14:04:56,059:INFO:Uploading model into container now
2024-12-24 14:04:56,059:INFO:_master_model_container: 15
2024-12-24 14:04:56,059:INFO:_display_container: 2
2024-12-24 14:04:56,059:INFO:AdaBoostRegressor(random_state=6105)
2024-12-24 14:04:56,059:INFO:create_model() successfully completed......................................
2024-12-24 14:04:56,159:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:56,160:INFO:Creating metrics dataframe
2024-12-24 14:04:56,168:INFO:Initializing Gradient Boosting Regressor
2024-12-24 14:04:56,168:INFO:Total runtime is 0.16935441493988038 minutes
2024-12-24 14:04:56,170:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:56,171:INFO:Initializing create_model()
2024-12-24 14:04:56,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:56,171:INFO:Checking exceptions
2024-12-24 14:04:56,171:INFO:Importing libraries
2024-12-24 14:04:56,171:INFO:Copying training dataset
2024-12-24 14:04:56,175:INFO:Defining folds
2024-12-24 14:04:56,175:INFO:Declaring metric variables
2024-12-24 14:04:56,178:INFO:Importing untrained model
2024-12-24 14:04:56,181:INFO:Gradient Boosting Regressor Imported successfully
2024-12-24 14:04:56,186:INFO:Starting cross validation
2024-12-24 14:04:56,188:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:56,334:INFO:Calculating mean and std
2024-12-24 14:04:56,335:INFO:Creating metrics dataframe
2024-12-24 14:04:56,336:INFO:Uploading results into container
2024-12-24 14:04:56,337:INFO:Uploading model into container now
2024-12-24 14:04:56,338:INFO:_master_model_container: 16
2024-12-24 14:04:56,338:INFO:_display_container: 2
2024-12-24 14:04:56,338:INFO:GradientBoostingRegressor(random_state=6105)
2024-12-24 14:04:56,338:INFO:create_model() successfully completed......................................
2024-12-24 14:04:56,441:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:56,441:INFO:Creating metrics dataframe
2024-12-24 14:04:56,449:INFO:Initializing Extreme Gradient Boosting
2024-12-24 14:04:56,449:INFO:Total runtime is 0.1740287184715271 minutes
2024-12-24 14:04:56,451:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:56,452:INFO:Initializing create_model()
2024-12-24 14:04:56,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:56,452:INFO:Checking exceptions
2024-12-24 14:04:56,452:INFO:Importing libraries
2024-12-24 14:04:56,452:INFO:Copying training dataset
2024-12-24 14:04:56,456:INFO:Defining folds
2024-12-24 14:04:56,456:INFO:Declaring metric variables
2024-12-24 14:04:56,460:INFO:Importing untrained model
2024-12-24 14:04:56,462:INFO:Extreme Gradient Boosting Imported successfully
2024-12-24 14:04:56,466:INFO:Starting cross validation
2024-12-24 14:04:56,467:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:04:58,576:INFO:Calculating mean and std
2024-12-24 14:04:58,577:INFO:Creating metrics dataframe
2024-12-24 14:04:58,580:INFO:Uploading results into container
2024-12-24 14:04:58,580:INFO:Uploading model into container now
2024-12-24 14:04:58,581:INFO:_master_model_container: 17
2024-12-24 14:04:58,581:INFO:_display_container: 2
2024-12-24 14:04:58,582:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=6105, ...)
2024-12-24 14:04:58,582:INFO:create_model() successfully completed......................................
2024-12-24 14:04:58,696:INFO:SubProcess create_model() end ==================================
2024-12-24 14:04:58,697:INFO:Creating metrics dataframe
2024-12-24 14:04:58,705:INFO:Initializing Light Gradient Boosting Machine
2024-12-24 14:04:58,706:INFO:Total runtime is 0.21164521376291912 minutes
2024-12-24 14:04:58,708:INFO:SubProcess create_model() called ==================================
2024-12-24 14:04:58,708:INFO:Initializing create_model()
2024-12-24 14:04:58,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:04:58,709:INFO:Checking exceptions
2024-12-24 14:04:58,709:INFO:Importing libraries
2024-12-24 14:04:58,709:INFO:Copying training dataset
2024-12-24 14:04:58,713:INFO:Defining folds
2024-12-24 14:04:58,713:INFO:Declaring metric variables
2024-12-24 14:04:58,716:INFO:Importing untrained model
2024-12-24 14:04:58,718:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:04:58,723:INFO:Starting cross validation
2024-12-24 14:04:58,725:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:05:00,348:INFO:Calculating mean and std
2024-12-24 14:05:00,348:INFO:Creating metrics dataframe
2024-12-24 14:05:00,350:INFO:Uploading results into container
2024-12-24 14:05:00,350:INFO:Uploading model into container now
2024-12-24 14:05:00,351:INFO:_master_model_container: 18
2024-12-24 14:05:00,351:INFO:_display_container: 2
2024-12-24 14:05:00,351:INFO:LGBMRegressor(n_jobs=-1, random_state=6105)
2024-12-24 14:05:00,351:INFO:create_model() successfully completed......................................
2024-12-24 14:05:00,460:INFO:SubProcess create_model() end ==================================
2024-12-24 14:05:00,460:INFO:Creating metrics dataframe
2024-12-24 14:05:00,469:INFO:Initializing CatBoost Regressor
2024-12-24 14:05:00,469:INFO:Total runtime is 0.24103341499964398 minutes
2024-12-24 14:05:00,472:INFO:SubProcess create_model() called ==================================
2024-12-24 14:05:00,473:INFO:Initializing create_model()
2024-12-24 14:05:00,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:05:00,473:INFO:Checking exceptions
2024-12-24 14:05:00,473:INFO:Importing libraries
2024-12-24 14:05:00,473:INFO:Copying training dataset
2024-12-24 14:05:00,477:INFO:Defining folds
2024-12-24 14:05:00,477:INFO:Declaring metric variables
2024-12-24 14:05:00,481:INFO:Importing untrained model
2024-12-24 14:05:00,483:INFO:CatBoost Regressor Imported successfully
2024-12-24 14:05:00,487:INFO:Starting cross validation
2024-12-24 14:05:00,489:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:05:03,862:INFO:Calculating mean and std
2024-12-24 14:05:03,863:INFO:Creating metrics dataframe
2024-12-24 14:05:03,865:INFO:Uploading results into container
2024-12-24 14:05:03,866:INFO:Uploading model into container now
2024-12-24 14:05:03,866:INFO:_master_model_container: 19
2024-12-24 14:05:03,866:INFO:_display_container: 2
2024-12-24 14:05:03,866:INFO:<catboost.core.CatBoostRegressor object at 0x00000192902D8A00>
2024-12-24 14:05:03,866:INFO:create_model() successfully completed......................................
2024-12-24 14:05:03,972:INFO:SubProcess create_model() end ==================================
2024-12-24 14:05:03,972:INFO:Creating metrics dataframe
2024-12-24 14:05:03,981:INFO:Initializing Dummy Regressor
2024-12-24 14:05:03,981:INFO:Total runtime is 0.2995611111323039 minutes
2024-12-24 14:05:03,983:INFO:SubProcess create_model() called ==================================
2024-12-24 14:05:03,983:INFO:Initializing create_model()
2024-12-24 14:05:03,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F148580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:05:03,983:INFO:Checking exceptions
2024-12-24 14:05:03,984:INFO:Importing libraries
2024-12-24 14:05:03,984:INFO:Copying training dataset
2024-12-24 14:05:03,987:INFO:Defining folds
2024-12-24 14:05:03,987:INFO:Declaring metric variables
2024-12-24 14:05:03,989:INFO:Importing untrained model
2024-12-24 14:05:03,992:INFO:Dummy Regressor Imported successfully
2024-12-24 14:05:03,997:INFO:Starting cross validation
2024-12-24 14:05:03,998:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:05:05,621:INFO:Calculating mean and std
2024-12-24 14:05:05,623:INFO:Creating metrics dataframe
2024-12-24 14:05:05,624:INFO:Uploading results into container
2024-12-24 14:05:05,625:INFO:Uploading model into container now
2024-12-24 14:05:05,625:INFO:_master_model_container: 20
2024-12-24 14:05:05,625:INFO:_display_container: 2
2024-12-24 14:05:05,626:INFO:DummyRegressor()
2024-12-24 14:05:05,626:INFO:create_model() successfully completed......................................
2024-12-24 14:05:05,731:INFO:SubProcess create_model() end ==================================
2024-12-24 14:05:05,731:INFO:Creating metrics dataframe
2024-12-24 14:05:05,741:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-24 14:05:05,747:INFO:Initializing create_model()
2024-12-24 14:05:05,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=Ridge(random_state=6105), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:05:05,747:INFO:Checking exceptions
2024-12-24 14:05:05,750:INFO:Importing libraries
2024-12-24 14:05:05,751:INFO:Copying training dataset
2024-12-24 14:05:05,754:INFO:Defining folds
2024-12-24 14:05:05,754:INFO:Declaring metric variables
2024-12-24 14:05:05,755:INFO:Importing untrained model
2024-12-24 14:05:05,755:INFO:Declaring custom model
2024-12-24 14:05:05,755:INFO:Ridge Regression Imported successfully
2024-12-24 14:05:05,756:INFO:Cross validation set to False
2024-12-24 14:05:05,757:INFO:Fitting Model
2024-12-24 14:05:05,797:INFO:Ridge(random_state=6105)
2024-12-24 14:05:05,797:INFO:create_model() successfully completed......................................
2024-12-24 14:05:05,919:INFO:_master_model_container: 20
2024-12-24 14:05:05,919:INFO:_display_container: 2
2024-12-24 14:05:05,919:INFO:Ridge(random_state=6105)
2024-12-24 14:05:05,919:INFO:compare_models() successfully completed......................................
2024-12-24 14:05:19,609:INFO:Initializing tune_model()
2024-12-24 14:05:19,609:INFO:tune_model(estimator=Ridge(random_state=6105), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>)
2024-12-24 14:05:19,609:INFO:Checking exceptions
2024-12-24 14:05:19,625:INFO:Copying training dataset
2024-12-24 14:05:19,629:INFO:Checking base model
2024-12-24 14:05:19,630:INFO:Base model : Ridge Regression
2024-12-24 14:05:19,634:INFO:Declaring metric variables
2024-12-24 14:05:19,638:INFO:Defining Hyperparameters
2024-12-24 14:05:19,740:INFO:Tuning with n_jobs=-1
2024-12-24 14:05:19,740:INFO:Initializing RandomizedSearchCV
2024-12-24 14:05:21,719:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 8.47}
2024-12-24 14:05:21,720:INFO:Hyperparameter search completed
2024-12-24 14:05:21,720:INFO:SubProcess create_model() called ==================================
2024-12-24 14:05:21,721:INFO:Initializing create_model()
2024-12-24 14:05:21,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=Ridge(random_state=6105), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000192902D9AE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 8.47})
2024-12-24 14:05:21,721:INFO:Checking exceptions
2024-12-24 14:05:21,721:INFO:Importing libraries
2024-12-24 14:05:21,721:INFO:Copying training dataset
2024-12-24 14:05:21,725:INFO:Defining folds
2024-12-24 14:05:21,725:INFO:Declaring metric variables
2024-12-24 14:05:21,729:INFO:Importing untrained model
2024-12-24 14:05:21,729:INFO:Declaring custom model
2024-12-24 14:05:21,733:INFO:Ridge Regression Imported successfully
2024-12-24 14:05:21,741:INFO:Starting cross validation
2024-12-24 14:05:21,743:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:05:21,848:INFO:Calculating mean and std
2024-12-24 14:05:21,849:INFO:Creating metrics dataframe
2024-12-24 14:05:21,855:INFO:Finalizing model
2024-12-24 14:05:21,903:INFO:Uploading results into container
2024-12-24 14:05:21,903:INFO:Uploading model into container now
2024-12-24 14:05:21,904:INFO:_master_model_container: 21
2024-12-24 14:05:21,904:INFO:_display_container: 3
2024-12-24 14:05:21,904:INFO:Ridge(alpha=8.47, random_state=6105)
2024-12-24 14:05:21,904:INFO:create_model() successfully completed......................................
2024-12-24 14:05:22,016:INFO:SubProcess create_model() end ==================================
2024-12-24 14:05:22,016:INFO:choose_better activated
2024-12-24 14:05:22,022:INFO:SubProcess create_model() called ==================================
2024-12-24 14:05:22,022:INFO:Initializing create_model()
2024-12-24 14:05:22,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001928F62D2A0>, estimator=Ridge(random_state=6105), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:05:22,023:INFO:Checking exceptions
2024-12-24 14:05:22,025:INFO:Importing libraries
2024-12-24 14:05:22,025:INFO:Copying training dataset
2024-12-24 14:05:22,029:INFO:Defining folds
2024-12-24 14:05:22,029:INFO:Declaring metric variables
2024-12-24 14:05:22,029:INFO:Importing untrained model
2024-12-24 14:05:22,029:INFO:Declaring custom model
2024-12-24 14:05:22,030:INFO:Ridge Regression Imported successfully
2024-12-24 14:05:22,030:INFO:Starting cross validation
2024-12-24 14:05:22,031:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:05:22,134:INFO:Calculating mean and std
2024-12-24 14:05:22,135:INFO:Creating metrics dataframe
2024-12-24 14:05:22,137:INFO:Finalizing model
2024-12-24 14:05:22,180:INFO:Uploading results into container
2024-12-24 14:05:22,181:INFO:Uploading model into container now
2024-12-24 14:05:22,181:INFO:_master_model_container: 22
2024-12-24 14:05:22,181:INFO:_display_container: 4
2024-12-24 14:05:22,181:INFO:Ridge(random_state=6105)
2024-12-24 14:05:22,181:INFO:create_model() successfully completed......................................
2024-12-24 14:05:22,289:INFO:SubProcess create_model() end ==================================
2024-12-24 14:05:22,289:INFO:Ridge(random_state=6105) result for R2 is 0.2584
2024-12-24 14:05:22,290:INFO:Ridge(alpha=8.47, random_state=6105) result for R2 is 0.369
2024-12-24 14:05:22,290:INFO:Ridge(alpha=8.47, random_state=6105) is best model
2024-12-24 14:05:22,290:INFO:choose_better completed
2024-12-24 14:05:22,297:INFO:_master_model_container: 22
2024-12-24 14:05:22,297:INFO:_display_container: 3
2024-12-24 14:05:22,298:INFO:Ridge(alpha=8.47, random_state=6105)
2024-12-24 14:05:22,298:INFO:tune_model() successfully completed......................................
2024-12-24 14:22:27,580:INFO:PyCaret ClassificationExperiment
2024-12-24 14:22:27,580:INFO:Logging name: clf-default-name
2024-12-24 14:22:27,580:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-24 14:22:27,580:INFO:version 3.3.1
2024-12-24 14:22:27,580:INFO:Initializing setup()
2024-12-24 14:22:27,580:INFO:self.USI: af2c
2024-12-24 14:22:27,580:INFO:self._variable_keys: {'_available_plots', 'data', 'y_test', 'html_param', 'fix_imbalance', 'pipeline', 'X_test', '_ml_usecase', 'idx', 'target_param', 'fold_generator', 'seed', 'X_train', 'X', 'fold_groups_param', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'y_train', 'fold_shuffle_param', 'y', 'is_multiclass', 'USI', 'gpu_param', 'logging_param', 'exp_name_log', 'memory', 'log_plots_param'}
2024-12-24 14:22:27,580:INFO:Checking environment
2024-12-24 14:22:27,580:INFO:python_version: 3.10.15
2024-12-24 14:22:27,580:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-24 14:22:27,580:INFO:machine: AMD64
2024-12-24 14:22:27,580:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-24 14:22:27,580:INFO:Memory: svmem(total=16312721408, available=4765974528, percent=70.8, used=11546746880, free=4765974528)
2024-12-24 14:22:27,580:INFO:Physical Core: 6
2024-12-24 14:22:27,580:INFO:Logical Core: 12
2024-12-24 14:22:27,581:INFO:Checking libraries
2024-12-24 14:22:27,581:INFO:System:
2024-12-24 14:22:27,581:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-24 14:22:27,581:INFO:executable: D:\Anaconda\python.exe
2024-12-24 14:22:27,581:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-24 14:22:27,581:INFO:PyCaret required dependencies:
2024-12-24 14:22:27,581:INFO:                 pip: 24.2
2024-12-24 14:22:27,581:INFO:          setuptools: 75.1.0
2024-12-24 14:22:27,581:INFO:             pycaret: 3.3.1
2024-12-24 14:22:27,581:INFO:             IPython: 8.27.0
2024-12-24 14:22:27,581:INFO:          ipywidgets: 8.1.2
2024-12-24 14:22:27,581:INFO:                tqdm: 4.66.5
2024-12-24 14:22:27,581:INFO:               numpy: 1.26.4
2024-12-24 14:22:27,581:INFO:              pandas: 2.1.4
2024-12-24 14:22:27,581:INFO:              jinja2: 3.1.4
2024-12-24 14:22:27,581:INFO:               scipy: 1.11.4
2024-12-24 14:22:27,581:INFO:              joblib: 1.2.0
2024-12-24 14:22:27,581:INFO:             sklearn: 1.4.2
2024-12-24 14:22:27,581:INFO:                pyod: 2.0.2
2024-12-24 14:22:27,581:INFO:            imblearn: 0.12.3
2024-12-24 14:22:27,581:INFO:   category_encoders: 2.6.3
2024-12-24 14:22:27,581:INFO:            lightgbm: 4.5.0
2024-12-24 14:22:27,582:INFO:               numba: 0.60.0
2024-12-24 14:22:27,582:INFO:            requests: 2.32.3
2024-12-24 14:22:27,582:INFO:          matplotlib: 3.9.2
2024-12-24 14:22:27,582:INFO:          scikitplot: 0.3.7
2024-12-24 14:22:27,582:INFO:         yellowbrick: 1.5
2024-12-24 14:22:27,582:INFO:              plotly: 5.24.1
2024-12-24 14:22:27,582:INFO:    plotly-resampler: Not installed
2024-12-24 14:22:27,582:INFO:             kaleido: 0.2.1
2024-12-24 14:22:27,582:INFO:           schemdraw: 0.15
2024-12-24 14:22:27,582:INFO:         statsmodels: 0.14.2
2024-12-24 14:22:27,582:INFO:              sktime: 0.26.0
2024-12-24 14:22:27,582:INFO:               tbats: 1.1.3
2024-12-24 14:22:27,582:INFO:            pmdarima: 2.0.4
2024-12-24 14:22:27,582:INFO:              psutil: 5.9.0
2024-12-24 14:22:27,582:INFO:          markupsafe: 2.1.3
2024-12-24 14:22:27,582:INFO:             pickle5: Not installed
2024-12-24 14:22:27,582:INFO:         cloudpickle: 3.0.0
2024-12-24 14:22:27,582:INFO:         deprecation: 2.1.0
2024-12-24 14:22:27,582:INFO:              xxhash: 2.0.2
2024-12-24 14:22:27,582:INFO:           wurlitzer: 3.1.1
2024-12-24 14:22:27,582:INFO:PyCaret optional dependencies:
2024-12-24 14:22:27,582:INFO:                shap: Not installed
2024-12-24 14:22:27,582:INFO:           interpret: Not installed
2024-12-24 14:22:27,582:INFO:                umap: 0.5.3
2024-12-24 14:22:27,582:INFO:     ydata_profiling: Not installed
2024-12-24 14:22:27,582:INFO:  explainerdashboard: Not installed
2024-12-24 14:22:27,582:INFO:             autoviz: Not installed
2024-12-24 14:22:27,582:INFO:           fairlearn: Not installed
2024-12-24 14:22:27,582:INFO:          deepchecks: Not installed
2024-12-24 14:22:27,582:INFO:             xgboost: 2.1.2
2024-12-24 14:22:27,582:INFO:            catboost: 1.2.3
2024-12-24 14:22:27,582:INFO:              kmodes: 0.12.2
2024-12-24 14:22:27,582:INFO:             mlxtend: 0.23.1
2024-12-24 14:22:27,582:INFO:       statsforecast: Not installed
2024-12-24 14:22:27,582:INFO:        tune_sklearn: Not installed
2024-12-24 14:22:27,582:INFO:                 ray: Not installed
2024-12-24 14:22:27,582:INFO:            hyperopt: Not installed
2024-12-24 14:22:27,582:INFO:              optuna: Not installed
2024-12-24 14:22:27,582:INFO:               skopt: Not installed
2024-12-24 14:22:27,582:INFO:              mlflow: 2.16.2
2024-12-24 14:22:27,582:INFO:              gradio: Not installed
2024-12-24 14:22:27,582:INFO:             fastapi: Not installed
2024-12-24 14:22:27,583:INFO:             uvicorn: Not installed
2024-12-24 14:22:27,583:INFO:              m2cgen: Not installed
2024-12-24 14:22:27,583:INFO:           evidently: Not installed
2024-12-24 14:22:27,583:INFO:               fugue: Not installed
2024-12-24 14:22:27,583:INFO:           streamlit: Not installed
2024-12-24 14:22:27,583:INFO:             prophet: Not installed
2024-12-24 14:22:27,583:INFO:None
2024-12-24 14:22:27,583:INFO:Set up data.
2024-12-24 14:22:27,589:INFO:Set up folding strategy.
2024-12-24 14:22:27,589:INFO:Set up train/test split.
2024-12-24 14:22:27,596:INFO:Set up index.
2024-12-24 14:22:27,596:INFO:Assigning column types.
2024-12-24 14:22:27,599:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-24 14:22:27,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:22:27,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:22:27,668:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:27,670:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:27,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:22:27,705:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:22:27,726:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:27,728:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:27,729:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-24 14:22:27,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:22:27,784:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:27,786:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:27,821:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:22:27,843:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:27,845:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:27,846:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-24 14:22:27,902:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:27,904:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:27,959:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:27,961:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:27,962:INFO:Preparing preprocessing pipeline...
2024-12-24 14:22:27,963:INFO:Set up simple imputation.
2024-12-24 14:22:27,965:INFO:Set up encoding of ordinal features.
2024-12-24 14:22:27,966:INFO:Set up encoding of categorical features.
2024-12-24 14:22:28,062:INFO:Finished creating preprocessing pipeline.
2024-12-24 14:22:28,074:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-12-24 14:22:28,074:INFO:Creating final display dataframe.
2024-12-24 14:22:28,427:INFO:Setup _display_container:                     Description             Value
0                    Session id              2619
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                 5
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              af2c
2024-12-24 14:22:28,494:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:28,497:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:28,555:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:22:28,557:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:22:28,559:INFO:setup() successfully completed in 0.98s...............
2024-12-24 14:44:57,135:INFO:PyCaret ClassificationExperiment
2024-12-24 14:44:57,135:INFO:Logging name: clf-default-name
2024-12-24 14:44:57,135:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-24 14:44:57,135:INFO:version 3.3.1
2024-12-24 14:44:57,135:INFO:Initializing setup()
2024-12-24 14:44:57,135:INFO:self.USI: 7bd4
2024-12-24 14:44:57,135:INFO:self._variable_keys: {'_available_plots', 'data', 'y_test', 'html_param', 'fix_imbalance', 'pipeline', 'X_test', '_ml_usecase', 'idx', 'target_param', 'fold_generator', 'seed', 'X_train', 'X', 'fold_groups_param', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'y_train', 'fold_shuffle_param', 'y', 'is_multiclass', 'USI', 'gpu_param', 'logging_param', 'exp_name_log', 'memory', 'log_plots_param'}
2024-12-24 14:44:57,136:INFO:Checking environment
2024-12-24 14:44:57,136:INFO:python_version: 3.10.15
2024-12-24 14:44:57,136:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-24 14:44:57,136:INFO:machine: AMD64
2024-12-24 14:44:57,136:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-24 14:44:57,136:INFO:Memory: svmem(total=16312721408, available=4707389440, percent=71.1, used=11605331968, free=4707389440)
2024-12-24 14:44:57,136:INFO:Physical Core: 6
2024-12-24 14:44:57,136:INFO:Logical Core: 12
2024-12-24 14:44:57,136:INFO:Checking libraries
2024-12-24 14:44:57,136:INFO:System:
2024-12-24 14:44:57,136:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-24 14:44:57,136:INFO:executable: D:\Anaconda\python.exe
2024-12-24 14:44:57,136:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-24 14:44:57,136:INFO:PyCaret required dependencies:
2024-12-24 14:44:57,136:INFO:                 pip: 24.2
2024-12-24 14:44:57,136:INFO:          setuptools: 75.1.0
2024-12-24 14:44:57,136:INFO:             pycaret: 3.3.1
2024-12-24 14:44:57,136:INFO:             IPython: 8.27.0
2024-12-24 14:44:57,136:INFO:          ipywidgets: 8.1.2
2024-12-24 14:44:57,136:INFO:                tqdm: 4.66.5
2024-12-24 14:44:57,137:INFO:               numpy: 1.26.4
2024-12-24 14:44:57,137:INFO:              pandas: 2.1.4
2024-12-24 14:44:57,137:INFO:              jinja2: 3.1.4
2024-12-24 14:44:57,137:INFO:               scipy: 1.11.4
2024-12-24 14:44:57,137:INFO:              joblib: 1.2.0
2024-12-24 14:44:57,137:INFO:             sklearn: 1.4.2
2024-12-24 14:44:57,137:INFO:                pyod: 2.0.2
2024-12-24 14:44:57,137:INFO:            imblearn: 0.12.3
2024-12-24 14:44:57,137:INFO:   category_encoders: 2.6.3
2024-12-24 14:44:57,137:INFO:            lightgbm: 4.5.0
2024-12-24 14:44:57,137:INFO:               numba: 0.60.0
2024-12-24 14:44:57,137:INFO:            requests: 2.32.3
2024-12-24 14:44:57,137:INFO:          matplotlib: 3.9.2
2024-12-24 14:44:57,137:INFO:          scikitplot: 0.3.7
2024-12-24 14:44:57,137:INFO:         yellowbrick: 1.5
2024-12-24 14:44:57,138:INFO:              plotly: 5.24.1
2024-12-24 14:44:57,138:INFO:    plotly-resampler: Not installed
2024-12-24 14:44:57,138:INFO:             kaleido: 0.2.1
2024-12-24 14:44:57,138:INFO:           schemdraw: 0.15
2024-12-24 14:44:57,138:INFO:         statsmodels: 0.14.2
2024-12-24 14:44:57,138:INFO:              sktime: 0.26.0
2024-12-24 14:44:57,138:INFO:               tbats: 1.1.3
2024-12-24 14:44:57,138:INFO:            pmdarima: 2.0.4
2024-12-24 14:44:57,138:INFO:              psutil: 5.9.0
2024-12-24 14:44:57,138:INFO:          markupsafe: 2.1.3
2024-12-24 14:44:57,138:INFO:             pickle5: Not installed
2024-12-24 14:44:57,138:INFO:         cloudpickle: 3.0.0
2024-12-24 14:44:57,138:INFO:         deprecation: 2.1.0
2024-12-24 14:44:57,138:INFO:              xxhash: 2.0.2
2024-12-24 14:44:57,138:INFO:           wurlitzer: 3.1.1
2024-12-24 14:44:57,138:INFO:PyCaret optional dependencies:
2024-12-24 14:44:57,138:INFO:                shap: Not installed
2024-12-24 14:44:57,138:INFO:           interpret: Not installed
2024-12-24 14:44:57,138:INFO:                umap: 0.5.3
2024-12-24 14:44:57,138:INFO:     ydata_profiling: Not installed
2024-12-24 14:44:57,138:INFO:  explainerdashboard: Not installed
2024-12-24 14:44:57,138:INFO:             autoviz: Not installed
2024-12-24 14:44:57,138:INFO:           fairlearn: Not installed
2024-12-24 14:44:57,138:INFO:          deepchecks: Not installed
2024-12-24 14:44:57,138:INFO:             xgboost: 2.1.2
2024-12-24 14:44:57,138:INFO:            catboost: 1.2.3
2024-12-24 14:44:57,138:INFO:              kmodes: 0.12.2
2024-12-24 14:44:57,138:INFO:             mlxtend: 0.23.1
2024-12-24 14:44:57,138:INFO:       statsforecast: Not installed
2024-12-24 14:44:57,138:INFO:        tune_sklearn: Not installed
2024-12-24 14:44:57,138:INFO:                 ray: Not installed
2024-12-24 14:44:57,138:INFO:            hyperopt: Not installed
2024-12-24 14:44:57,138:INFO:              optuna: Not installed
2024-12-24 14:44:57,138:INFO:               skopt: Not installed
2024-12-24 14:44:57,139:INFO:              mlflow: 2.16.2
2024-12-24 14:44:57,139:INFO:              gradio: Not installed
2024-12-24 14:44:57,139:INFO:             fastapi: Not installed
2024-12-24 14:44:57,139:INFO:             uvicorn: Not installed
2024-12-24 14:44:57,139:INFO:              m2cgen: Not installed
2024-12-24 14:44:57,139:INFO:           evidently: Not installed
2024-12-24 14:44:57,139:INFO:               fugue: Not installed
2024-12-24 14:44:57,139:INFO:           streamlit: Not installed
2024-12-24 14:44:57,139:INFO:             prophet: Not installed
2024-12-24 14:44:57,139:INFO:None
2024-12-24 14:44:57,139:INFO:Set up data.
2024-12-24 14:44:57,143:INFO:Set up folding strategy.
2024-12-24 14:44:57,143:INFO:Set up train/test split.
2024-12-24 14:44:57,147:INFO:Set up index.
2024-12-24 14:44:57,147:INFO:Assigning column types.
2024-12-24 14:44:57,149:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-24 14:44:57,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:44:57,190:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:44:57,213:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,215:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-24 14:44:57,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:44:57,269:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,271:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,272:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-24 14:44:57,305:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:44:57,324:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,326:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,361:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-24 14:44:57,382:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,383:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,385:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-24 14:44:57,439:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,441:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,495:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,497:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,498:INFO:Preparing preprocessing pipeline...
2024-12-24 14:44:57,499:INFO:Set up simple imputation.
2024-12-24 14:44:57,501:INFO:Set up encoding of ordinal features.
2024-12-24 14:44:57,501:INFO:Set up encoding of categorical features.
2024-12-24 14:44:57,544:INFO:Finished creating preprocessing pipeline.
2024-12-24 14:44:57,556:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tran...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-12-24 14:44:57,556:INFO:Creating final display dataframe.
2024-12-24 14:44:57,698:INFO:Setup _display_container:                     Description             Value
0                    Session id              7222
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 8)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (623, 10)
6    Transformed test set shape         (268, 10)
7              Numeric features                 5
8          Categorical features                 2
9      Rows with missing values             20.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                 5
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              7bd4
2024-12-24 14:44:57,758:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,760:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,816:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-24 14:44:57,818:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-24 14:44:57,819:INFO:setup() successfully completed in 0.69s...............
2024-12-24 14:45:01,436:INFO:Initializing compare_models()
2024-12-24 14:45:01,437:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-24 14:45:01,437:INFO:Checking exceptions
2024-12-24 14:45:01,443:INFO:Preparing display monitor
2024-12-24 14:45:01,461:INFO:Initializing Logistic Regression
2024-12-24 14:45:01,461:INFO:Total runtime is 0.0 minutes
2024-12-24 14:45:01,465:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:01,465:INFO:Initializing create_model()
2024-12-24 14:45:01,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:01,465:INFO:Checking exceptions
2024-12-24 14:45:01,465:INFO:Importing libraries
2024-12-24 14:45:01,465:INFO:Copying training dataset
2024-12-24 14:45:01,469:INFO:Defining folds
2024-12-24 14:45:01,469:INFO:Declaring metric variables
2024-12-24 14:45:01,471:INFO:Importing untrained model
2024-12-24 14:45:01,474:INFO:Logistic Regression Imported successfully
2024-12-24 14:45:01,479:INFO:Starting cross validation
2024-12-24 14:45:01,481:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:04,686:INFO:Calculating mean and std
2024-12-24 14:45:04,689:INFO:Creating metrics dataframe
2024-12-24 14:45:04,691:INFO:Uploading results into container
2024-12-24 14:45:04,692:INFO:Uploading model into container now
2024-12-24 14:45:04,692:INFO:_master_model_container: 1
2024-12-24 14:45:04,692:INFO:_display_container: 2
2024-12-24 14:45:04,692:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7222, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-24 14:45:04,693:INFO:create_model() successfully completed......................................
2024-12-24 14:45:04,817:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:04,817:INFO:Creating metrics dataframe
2024-12-24 14:45:04,824:INFO:Initializing K Neighbors Classifier
2024-12-24 14:45:04,824:INFO:Total runtime is 0.05603918234507243 minutes
2024-12-24 14:45:04,826:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:04,827:INFO:Initializing create_model()
2024-12-24 14:45:04,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:04,827:INFO:Checking exceptions
2024-12-24 14:45:04,827:INFO:Importing libraries
2024-12-24 14:45:04,827:INFO:Copying training dataset
2024-12-24 14:45:04,831:INFO:Defining folds
2024-12-24 14:45:04,831:INFO:Declaring metric variables
2024-12-24 14:45:04,835:INFO:Importing untrained model
2024-12-24 14:45:04,837:INFO:K Neighbors Classifier Imported successfully
2024-12-24 14:45:04,842:INFO:Starting cross validation
2024-12-24 14:45:04,843:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:06,683:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,684:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,698:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,704:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,706:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,717:INFO:Calculating mean and std
2024-12-24 14:45:06,718:INFO:Creating metrics dataframe
2024-12-24 14:45:06,721:INFO:Uploading results into container
2024-12-24 14:45:06,722:INFO:Uploading model into container now
2024-12-24 14:45:06,722:INFO:_master_model_container: 2
2024-12-24 14:45:06,722:INFO:_display_container: 2
2024-12-24 14:45:06,722:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-24 14:45:06,723:INFO:create_model() successfully completed......................................
2024-12-24 14:45:06,844:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:06,844:INFO:Creating metrics dataframe
2024-12-24 14:45:06,850:INFO:Initializing Naive Bayes
2024-12-24 14:45:06,850:INFO:Total runtime is 0.08981719414393108 minutes
2024-12-24 14:45:06,853:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:06,853:INFO:Initializing create_model()
2024-12-24 14:45:06,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=nb, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:06,853:INFO:Checking exceptions
2024-12-24 14:45:06,853:INFO:Importing libraries
2024-12-24 14:45:06,853:INFO:Copying training dataset
2024-12-24 14:45:06,857:INFO:Defining folds
2024-12-24 14:45:06,857:INFO:Declaring metric variables
2024-12-24 14:45:06,860:INFO:Importing untrained model
2024-12-24 14:45:06,862:INFO:Naive Bayes Imported successfully
2024-12-24 14:45:06,866:INFO:Starting cross validation
2024-12-24 14:45:06,869:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:06,935:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,942:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:06,943:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,462:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,464:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,473:INFO:Calculating mean and std
2024-12-24 14:45:08,474:INFO:Creating metrics dataframe
2024-12-24 14:45:08,475:INFO:Uploading results into container
2024-12-24 14:45:08,476:INFO:Uploading model into container now
2024-12-24 14:45:08,476:INFO:_master_model_container: 3
2024-12-24 14:45:08,476:INFO:_display_container: 2
2024-12-24 14:45:08,476:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-24 14:45:08,477:INFO:create_model() successfully completed......................................
2024-12-24 14:45:08,585:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:08,585:INFO:Creating metrics dataframe
2024-12-24 14:45:08,592:INFO:Initializing Decision Tree Classifier
2024-12-24 14:45:08,592:INFO:Total runtime is 0.11884462038675944 minutes
2024-12-24 14:45:08,594:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:08,594:INFO:Initializing create_model()
2024-12-24 14:45:08,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:08,594:INFO:Checking exceptions
2024-12-24 14:45:08,594:INFO:Importing libraries
2024-12-24 14:45:08,594:INFO:Copying training dataset
2024-12-24 14:45:08,598:INFO:Defining folds
2024-12-24 14:45:08,598:INFO:Declaring metric variables
2024-12-24 14:45:08,601:INFO:Importing untrained model
2024-12-24 14:45:08,604:INFO:Decision Tree Classifier Imported successfully
2024-12-24 14:45:08,609:INFO:Starting cross validation
2024-12-24 14:45:08,611:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:08,671:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,672:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,672:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,675:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,676:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:08,685:INFO:Calculating mean and std
2024-12-24 14:45:08,687:INFO:Creating metrics dataframe
2024-12-24 14:45:08,688:INFO:Uploading results into container
2024-12-24 14:45:08,689:INFO:Uploading model into container now
2024-12-24 14:45:08,689:INFO:_master_model_container: 4
2024-12-24 14:45:08,689:INFO:_display_container: 2
2024-12-24 14:45:08,689:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7222, splitter='best')
2024-12-24 14:45:08,689:INFO:create_model() successfully completed......................................
2024-12-24 14:45:08,792:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:08,792:INFO:Creating metrics dataframe
2024-12-24 14:45:08,797:INFO:Initializing SVM - Linear Kernel
2024-12-24 14:45:08,797:INFO:Total runtime is 0.12227012713750203 minutes
2024-12-24 14:45:08,801:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:08,801:INFO:Initializing create_model()
2024-12-24 14:45:08,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=svm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:08,801:INFO:Checking exceptions
2024-12-24 14:45:08,801:INFO:Importing libraries
2024-12-24 14:45:08,801:INFO:Copying training dataset
2024-12-24 14:45:08,805:INFO:Defining folds
2024-12-24 14:45:08,805:INFO:Declaring metric variables
2024-12-24 14:45:08,807:INFO:Importing untrained model
2024-12-24 14:45:08,810:INFO:SVM - Linear Kernel Imported successfully
2024-12-24 14:45:08,814:INFO:Starting cross validation
2024-12-24 14:45:08,815:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:08,891:INFO:Calculating mean and std
2024-12-24 14:45:08,892:INFO:Creating metrics dataframe
2024-12-24 14:45:08,893:INFO:Uploading results into container
2024-12-24 14:45:08,894:INFO:Uploading model into container now
2024-12-24 14:45:08,894:INFO:_master_model_container: 5
2024-12-24 14:45:08,894:INFO:_display_container: 2
2024-12-24 14:45:08,894:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7222, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-24 14:45:08,895:INFO:create_model() successfully completed......................................
2024-12-24 14:45:08,995:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:08,995:INFO:Creating metrics dataframe
2024-12-24 14:45:09,002:INFO:Initializing Ridge Classifier
2024-12-24 14:45:09,002:INFO:Total runtime is 0.1256732185681661 minutes
2024-12-24 14:45:09,004:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:09,004:INFO:Initializing create_model()
2024-12-24 14:45:09,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:09,004:INFO:Checking exceptions
2024-12-24 14:45:09,004:INFO:Importing libraries
2024-12-24 14:45:09,004:INFO:Copying training dataset
2024-12-24 14:45:09,008:INFO:Defining folds
2024-12-24 14:45:09,008:INFO:Declaring metric variables
2024-12-24 14:45:09,011:INFO:Importing untrained model
2024-12-24 14:45:09,013:INFO:Ridge Classifier Imported successfully
2024-12-24 14:45:09,018:INFO:Starting cross validation
2024-12-24 14:45:09,019:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:09,101:INFO:Calculating mean and std
2024-12-24 14:45:09,101:INFO:Creating metrics dataframe
2024-12-24 14:45:09,103:INFO:Uploading results into container
2024-12-24 14:45:09,103:INFO:Uploading model into container now
2024-12-24 14:45:09,103:INFO:_master_model_container: 6
2024-12-24 14:45:09,103:INFO:_display_container: 2
2024-12-24 14:45:09,104:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7222, solver='auto',
                tol=0.0001)
2024-12-24 14:45:09,104:INFO:create_model() successfully completed......................................
2024-12-24 14:45:09,205:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:09,205:INFO:Creating metrics dataframe
2024-12-24 14:45:09,211:INFO:Initializing Random Forest Classifier
2024-12-24 14:45:09,212:INFO:Total runtime is 0.12918359835942586 minutes
2024-12-24 14:45:09,214:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:09,214:INFO:Initializing create_model()
2024-12-24 14:45:09,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:09,215:INFO:Checking exceptions
2024-12-24 14:45:09,215:INFO:Importing libraries
2024-12-24 14:45:09,215:INFO:Copying training dataset
2024-12-24 14:45:09,218:INFO:Defining folds
2024-12-24 14:45:09,218:INFO:Declaring metric variables
2024-12-24 14:45:09,221:INFO:Importing untrained model
2024-12-24 14:45:09,224:INFO:Random Forest Classifier Imported successfully
2024-12-24 14:45:09,228:INFO:Starting cross validation
2024-12-24 14:45:09,229:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:09,423:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:09,423:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:09,423:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:09,433:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:09,435:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:09,442:INFO:Calculating mean and std
2024-12-24 14:45:09,445:INFO:Creating metrics dataframe
2024-12-24 14:45:09,446:INFO:Uploading results into container
2024-12-24 14:45:09,447:INFO:Uploading model into container now
2024-12-24 14:45:09,447:INFO:_master_model_container: 7
2024-12-24 14:45:09,447:INFO:_display_container: 2
2024-12-24 14:45:09,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7222, verbose=0,
                       warm_start=False)
2024-12-24 14:45:09,448:INFO:create_model() successfully completed......................................
2024-12-24 14:45:09,549:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:09,549:INFO:Creating metrics dataframe
2024-12-24 14:45:09,556:INFO:Initializing Quadratic Discriminant Analysis
2024-12-24 14:45:09,556:INFO:Total runtime is 0.13491652409235635 minutes
2024-12-24 14:45:09,558:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:09,559:INFO:Initializing create_model()
2024-12-24 14:45:09,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=qda, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:09,559:INFO:Checking exceptions
2024-12-24 14:45:09,559:INFO:Importing libraries
2024-12-24 14:45:09,560:INFO:Copying training dataset
2024-12-24 14:45:09,562:INFO:Defining folds
2024-12-24 14:45:09,563:INFO:Declaring metric variables
2024-12-24 14:45:09,566:INFO:Importing untrained model
2024-12-24 14:45:09,568:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-24 14:45:09,572:INFO:Starting cross validation
2024-12-24 14:45:09,574:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:09,623:WARNING:D:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-24 14:45:09,623:WARNING:D:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-24 14:45:09,623:WARNING:D:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-24 14:45:09,656:INFO:Calculating mean and std
2024-12-24 14:45:09,657:INFO:Creating metrics dataframe
2024-12-24 14:45:09,658:INFO:Uploading results into container
2024-12-24 14:45:09,658:INFO:Uploading model into container now
2024-12-24 14:45:09,659:INFO:_master_model_container: 8
2024-12-24 14:45:09,659:INFO:_display_container: 2
2024-12-24 14:45:09,659:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-24 14:45:09,659:INFO:create_model() successfully completed......................................
2024-12-24 14:45:09,764:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:09,764:INFO:Creating metrics dataframe
2024-12-24 14:45:09,771:INFO:Initializing Ada Boost Classifier
2024-12-24 14:45:09,771:INFO:Total runtime is 0.13848960796991983 minutes
2024-12-24 14:45:09,774:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:09,774:INFO:Initializing create_model()
2024-12-24 14:45:09,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:09,774:INFO:Checking exceptions
2024-12-24 14:45:09,774:INFO:Importing libraries
2024-12-24 14:45:09,775:INFO:Copying training dataset
2024-12-24 14:45:09,777:INFO:Defining folds
2024-12-24 14:45:09,778:INFO:Declaring metric variables
2024-12-24 14:45:09,780:INFO:Importing untrained model
2024-12-24 14:45:09,782:INFO:Ada Boost Classifier Imported successfully
2024-12-24 14:45:09,786:INFO:Starting cross validation
2024-12-24 14:45:09,788:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:09,826:WARNING:D:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-24 14:45:09,826:WARNING:D:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-24 14:45:09,826:WARNING:D:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-24 14:45:09,828:WARNING:D:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-24 14:45:09,829:WARNING:D:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-24 14:45:09,940:INFO:Calculating mean and std
2024-12-24 14:45:09,941:INFO:Creating metrics dataframe
2024-12-24 14:45:09,944:INFO:Uploading results into container
2024-12-24 14:45:09,945:INFO:Uploading model into container now
2024-12-24 14:45:09,945:INFO:_master_model_container: 9
2024-12-24 14:45:09,945:INFO:_display_container: 2
2024-12-24 14:45:09,946:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7222)
2024-12-24 14:45:09,946:INFO:create_model() successfully completed......................................
2024-12-24 14:45:10,047:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:10,047:INFO:Creating metrics dataframe
2024-12-24 14:45:10,054:INFO:Initializing Gradient Boosting Classifier
2024-12-24 14:45:10,054:INFO:Total runtime is 0.14320758581161497 minutes
2024-12-24 14:45:10,057:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:10,057:INFO:Initializing create_model()
2024-12-24 14:45:10,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=gbc, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:10,057:INFO:Checking exceptions
2024-12-24 14:45:10,057:INFO:Importing libraries
2024-12-24 14:45:10,057:INFO:Copying training dataset
2024-12-24 14:45:10,060:INFO:Defining folds
2024-12-24 14:45:10,061:INFO:Declaring metric variables
2024-12-24 14:45:10,063:INFO:Importing untrained model
2024-12-24 14:45:10,066:INFO:Gradient Boosting Classifier Imported successfully
2024-12-24 14:45:10,070:INFO:Starting cross validation
2024-12-24 14:45:10,071:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:10,233:INFO:Calculating mean and std
2024-12-24 14:45:10,234:INFO:Creating metrics dataframe
2024-12-24 14:45:10,236:INFO:Uploading results into container
2024-12-24 14:45:10,236:INFO:Uploading model into container now
2024-12-24 14:45:10,237:INFO:_master_model_container: 10
2024-12-24 14:45:10,237:INFO:_display_container: 2
2024-12-24 14:45:10,237:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7222, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-24 14:45:10,238:INFO:create_model() successfully completed......................................
2024-12-24 14:45:10,341:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:10,341:INFO:Creating metrics dataframe
2024-12-24 14:45:10,348:INFO:Initializing Linear Discriminant Analysis
2024-12-24 14:45:10,349:INFO:Total runtime is 0.14813470443089802 minutes
2024-12-24 14:45:10,352:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:10,352:INFO:Initializing create_model()
2024-12-24 14:45:10,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=lda, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:10,352:INFO:Checking exceptions
2024-12-24 14:45:10,353:INFO:Importing libraries
2024-12-24 14:45:10,353:INFO:Copying training dataset
2024-12-24 14:45:10,356:INFO:Defining folds
2024-12-24 14:45:10,356:INFO:Declaring metric variables
2024-12-24 14:45:10,359:INFO:Importing untrained model
2024-12-24 14:45:10,361:INFO:Linear Discriminant Analysis Imported successfully
2024-12-24 14:45:10,366:INFO:Starting cross validation
2024-12-24 14:45:10,367:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:10,460:INFO:Calculating mean and std
2024-12-24 14:45:10,461:INFO:Creating metrics dataframe
2024-12-24 14:45:10,462:INFO:Uploading results into container
2024-12-24 14:45:10,463:INFO:Uploading model into container now
2024-12-24 14:45:10,464:INFO:_master_model_container: 11
2024-12-24 14:45:10,464:INFO:_display_container: 2
2024-12-24 14:45:10,464:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-24 14:45:10,465:INFO:create_model() successfully completed......................................
2024-12-24 14:45:10,569:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:10,569:INFO:Creating metrics dataframe
2024-12-24 14:45:10,577:INFO:Initializing Extra Trees Classifier
2024-12-24 14:45:10,577:INFO:Total runtime is 0.15193655093510944 minutes
2024-12-24 14:45:10,579:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:10,580:INFO:Initializing create_model()
2024-12-24 14:45:10,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:10,580:INFO:Checking exceptions
2024-12-24 14:45:10,580:INFO:Importing libraries
2024-12-24 14:45:10,580:INFO:Copying training dataset
2024-12-24 14:45:10,585:INFO:Defining folds
2024-12-24 14:45:10,585:INFO:Declaring metric variables
2024-12-24 14:45:10,588:INFO:Importing untrained model
2024-12-24 14:45:10,590:INFO:Extra Trees Classifier Imported successfully
2024-12-24 14:45:10,595:INFO:Starting cross validation
2024-12-24 14:45:10,596:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:10,763:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:10,766:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:10,768:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:10,774:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:10,783:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:10,790:INFO:Calculating mean and std
2024-12-24 14:45:10,792:INFO:Creating metrics dataframe
2024-12-24 14:45:10,794:INFO:Uploading results into container
2024-12-24 14:45:10,795:INFO:Uploading model into container now
2024-12-24 14:45:10,795:INFO:_master_model_container: 12
2024-12-24 14:45:10,795:INFO:_display_container: 2
2024-12-24 14:45:10,796:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7222, verbose=0,
                     warm_start=False)
2024-12-24 14:45:10,796:INFO:create_model() successfully completed......................................
2024-12-24 14:45:10,897:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:10,897:INFO:Creating metrics dataframe
2024-12-24 14:45:10,906:INFO:Initializing Extreme Gradient Boosting
2024-12-24 14:45:10,906:INFO:Total runtime is 0.1574085434277852 minutes
2024-12-24 14:45:10,908:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:10,908:INFO:Initializing create_model()
2024-12-24 14:45:10,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:10,908:INFO:Checking exceptions
2024-12-24 14:45:10,908:INFO:Importing libraries
2024-12-24 14:45:10,908:INFO:Copying training dataset
2024-12-24 14:45:10,912:INFO:Defining folds
2024-12-24 14:45:10,912:INFO:Declaring metric variables
2024-12-24 14:45:10,916:INFO:Importing untrained model
2024-12-24 14:45:10,918:INFO:Extreme Gradient Boosting Imported successfully
2024-12-24 14:45:10,923:INFO:Starting cross validation
2024-12-24 14:45:10,924:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:13,159:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,161:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,162:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,164:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,166:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,179:INFO:Calculating mean and std
2024-12-24 14:45:13,181:INFO:Creating metrics dataframe
2024-12-24 14:45:13,183:INFO:Uploading results into container
2024-12-24 14:45:13,184:INFO:Uploading model into container now
2024-12-24 14:45:13,184:INFO:_master_model_container: 13
2024-12-24 14:45:13,184:INFO:_display_container: 2
2024-12-24 14:45:13,185:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-24 14:45:13,185:INFO:create_model() successfully completed......................................
2024-12-24 14:45:13,320:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:13,320:INFO:Creating metrics dataframe
2024-12-24 14:45:13,330:INFO:Initializing Light Gradient Boosting Machine
2024-12-24 14:45:13,330:INFO:Total runtime is 0.19782001972198482 minutes
2024-12-24 14:45:13,334:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:13,335:INFO:Initializing create_model()
2024-12-24 14:45:13,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:13,335:INFO:Checking exceptions
2024-12-24 14:45:13,335:INFO:Importing libraries
2024-12-24 14:45:13,335:INFO:Copying training dataset
2024-12-24 14:45:13,338:INFO:Defining folds
2024-12-24 14:45:13,338:INFO:Declaring metric variables
2024-12-24 14:45:13,341:INFO:Importing untrained model
2024-12-24 14:45:13,345:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:45:13,350:INFO:Starting cross validation
2024-12-24 14:45:13,352:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:13,905:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,907:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,912:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:13,952:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:14,986:INFO:Calculating mean and std
2024-12-24 14:45:14,988:INFO:Creating metrics dataframe
2024-12-24 14:45:14,990:INFO:Uploading results into container
2024-12-24 14:45:14,990:INFO:Uploading model into container now
2024-12-24 14:45:14,990:INFO:_master_model_container: 14
2024-12-24 14:45:14,990:INFO:_display_container: 2
2024-12-24 14:45:14,991:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:45:14,991:INFO:create_model() successfully completed......................................
2024-12-24 14:45:15,101:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:15,101:INFO:Creating metrics dataframe
2024-12-24 14:45:15,109:INFO:Initializing CatBoost Classifier
2024-12-24 14:45:15,109:INFO:Total runtime is 0.22746611833572383 minutes
2024-12-24 14:45:15,112:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:15,112:INFO:Initializing create_model()
2024-12-24 14:45:15,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:15,113:INFO:Checking exceptions
2024-12-24 14:45:15,113:INFO:Importing libraries
2024-12-24 14:45:15,113:INFO:Copying training dataset
2024-12-24 14:45:15,116:INFO:Defining folds
2024-12-24 14:45:15,116:INFO:Declaring metric variables
2024-12-24 14:45:15,119:INFO:Importing untrained model
2024-12-24 14:45:15,122:INFO:CatBoost Classifier Imported successfully
2024-12-24 14:45:15,127:INFO:Starting cross validation
2024-12-24 14:45:15,128:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:17,372:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:17,372:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:17,382:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:18,990:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:18,999:INFO:Calculating mean and std
2024-12-24 14:45:19,000:INFO:Creating metrics dataframe
2024-12-24 14:45:19,002:INFO:Uploading results into container
2024-12-24 14:45:19,003:INFO:Uploading model into container now
2024-12-24 14:45:19,003:INFO:_master_model_container: 15
2024-12-24 14:45:19,003:INFO:_display_container: 2
2024-12-24 14:45:19,003:INFO:<catboost.core.CatBoostClassifier object at 0x000001928F8F8AF0>
2024-12-24 14:45:19,003:INFO:create_model() successfully completed......................................
2024-12-24 14:45:19,107:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:19,107:INFO:Creating metrics dataframe
2024-12-24 14:45:19,115:INFO:Initializing Dummy Classifier
2024-12-24 14:45:19,115:INFO:Total runtime is 0.2942343354225158 minutes
2024-12-24 14:45:19,118:INFO:SubProcess create_model() called ==================================
2024-12-24 14:45:19,118:INFO:Initializing create_model()
2024-12-24 14:45:19,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019290174CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:19,118:INFO:Checking exceptions
2024-12-24 14:45:19,118:INFO:Importing libraries
2024-12-24 14:45:19,119:INFO:Copying training dataset
2024-12-24 14:45:19,121:INFO:Defining folds
2024-12-24 14:45:19,121:INFO:Declaring metric variables
2024-12-24 14:45:19,125:INFO:Importing untrained model
2024-12-24 14:45:19,128:INFO:Dummy Classifier Imported successfully
2024-12-24 14:45:19,133:INFO:Starting cross validation
2024-12-24 14:45:19,135:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:45:19,191:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:19,191:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:19,192:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:19,197:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-24 14:45:19,197:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-24 14:45:19,197:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-24 14:45:20,707:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:20,710:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:45:20,712:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-24 14:45:20,713:WARNING:D:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-24 14:45:20,718:INFO:Calculating mean and std
2024-12-24 14:45:20,719:INFO:Creating metrics dataframe
2024-12-24 14:45:20,721:INFO:Uploading results into container
2024-12-24 14:45:20,722:INFO:Uploading model into container now
2024-12-24 14:45:20,722:INFO:_master_model_container: 16
2024-12-24 14:45:20,722:INFO:_display_container: 2
2024-12-24 14:45:20,722:INFO:DummyClassifier(constant=None, random_state=7222, strategy='prior')
2024-12-24 14:45:20,723:INFO:create_model() successfully completed......................................
2024-12-24 14:45:20,831:INFO:SubProcess create_model() end ==================================
2024-12-24 14:45:20,831:INFO:Creating metrics dataframe
2024-12-24 14:45:20,841:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-24 14:45:20,847:INFO:Initializing create_model()
2024-12-24 14:45:20,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:45:20,847:INFO:Checking exceptions
2024-12-24 14:45:20,849:INFO:Importing libraries
2024-12-24 14:45:20,849:INFO:Copying training dataset
2024-12-24 14:45:20,853:INFO:Defining folds
2024-12-24 14:45:20,853:INFO:Declaring metric variables
2024-12-24 14:45:20,853:INFO:Importing untrained model
2024-12-24 14:45:20,853:INFO:Declaring custom model
2024-12-24 14:45:20,854:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:45:20,855:INFO:Cross validation set to False
2024-12-24 14:45:20,855:INFO:Fitting Model
2024-12-24 14:45:20,885:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-24 14:45:20,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.
2024-12-24 14:45:20,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-24 14:45:20,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-24 14:45:20,886:INFO:[LightGBM] [Info] Total Bins 191
2024-12-24 14:45:20,886:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-24 14:45:20,887:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-24 14:45:20,887:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-24 14:45:20,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:45:20,939:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:45:20,939:INFO:create_model() successfully completed......................................
2024-12-24 14:45:21,083:INFO:_master_model_container: 16
2024-12-24 14:45:21,084:INFO:_display_container: 2
2024-12-24 14:45:21,084:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:45:21,084:INFO:compare_models() successfully completed......................................
2024-12-24 14:47:53,590:INFO:Initializing tune_model()
2024-12-24 14:47:53,590:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>)
2024-12-24 14:47:53,590:INFO:Checking exceptions
2024-12-24 14:47:53,606:INFO:Copying training dataset
2024-12-24 14:47:53,608:INFO:Checking base model
2024-12-24 14:47:53,608:INFO:Base model : Light Gradient Boosting Machine
2024-12-24 14:47:53,612:INFO:Declaring metric variables
2024-12-24 14:47:53,616:INFO:Defining Hyperparameters
2024-12-24 14:47:53,732:INFO:Tuning with n_jobs=-1
2024-12-24 14:47:53,732:INFO:Initializing RandomizedSearchCV
2024-12-24 14:47:56,752:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.4}
2024-12-24 14:47:56,753:INFO:Hyperparameter search completed
2024-12-24 14:47:56,753:INFO:SubProcess create_model() called ==================================
2024-12-24 14:47:56,754:INFO:Initializing create_model()
2024-12-24 14:47:56,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928EAD41C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 0.5, 'num_leaves': 70, 'n_estimators': 80, 'min_split_gain': 0.7, 'min_child_samples': 1, 'learning_rate': 0.4, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.4})
2024-12-24 14:47:56,754:INFO:Checking exceptions
2024-12-24 14:47:56,754:INFO:Importing libraries
2024-12-24 14:47:56,754:INFO:Copying training dataset
2024-12-24 14:47:56,759:INFO:Defining folds
2024-12-24 14:47:56,759:INFO:Declaring metric variables
2024-12-24 14:47:56,765:INFO:Importing untrained model
2024-12-24 14:47:56,765:INFO:Declaring custom model
2024-12-24 14:47:56,770:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:47:56,780:INFO:Starting cross validation
2024-12-24 14:47:56,781:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:47:56,887:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:56,889:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:56,890:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:56,905:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:56,912:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:56,923:INFO:Calculating mean and std
2024-12-24 14:47:56,925:INFO:Creating metrics dataframe
2024-12-24 14:47:56,932:INFO:Finalizing model
2024-12-24 14:47:56,973:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-12-24 14:47:56,973:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2024-12-24 14:47:56,973:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-12-24 14:47:56,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-12-24 14:47:56,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2024-12-24 14:47:56,974:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-12-24 14:47:56,974:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-24 14:47:56,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.
2024-12-24 14:47:56,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-24 14:47:56,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-24 14:47:56,975:INFO:[LightGBM] [Info] Total Bins 191
2024-12-24 14:47:56,975:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-24 14:47:56,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-24 14:47:56,976:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-24 14:47:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:47:57,002:INFO:Uploading results into container
2024-12-24 14:47:57,002:INFO:Uploading model into container now
2024-12-24 14:47:57,004:INFO:_master_model_container: 17
2024-12-24 14:47:57,004:INFO:_display_container: 3
2024-12-24 14:47:57,004:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:47:57,004:INFO:create_model() successfully completed......................................
2024-12-24 14:47:57,124:INFO:SubProcess create_model() end ==================================
2024-12-24 14:47:57,124:INFO:choose_better activated
2024-12-24 14:47:57,128:INFO:SubProcess create_model() called ==================================
2024-12-24 14:47:57,129:INFO:Initializing create_model()
2024-12-24 14:47:57,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:47:57,129:INFO:Checking exceptions
2024-12-24 14:47:57,131:INFO:Importing libraries
2024-12-24 14:47:57,131:INFO:Copying training dataset
2024-12-24 14:47:57,134:INFO:Defining folds
2024-12-24 14:47:57,134:INFO:Declaring metric variables
2024-12-24 14:47:57,135:INFO:Importing untrained model
2024-12-24 14:47:57,135:INFO:Declaring custom model
2024-12-24 14:47:57,135:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:47:57,135:INFO:Starting cross validation
2024-12-24 14:47:57,136:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:47:57,322:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:57,334:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:57,343:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:57,377:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:57,441:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:47:57,452:INFO:Calculating mean and std
2024-12-24 14:47:57,452:INFO:Creating metrics dataframe
2024-12-24 14:47:57,454:INFO:Finalizing model
2024-12-24 14:47:57,491:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-24 14:47:57,491:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.
2024-12-24 14:47:57,492:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-24 14:47:57,492:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-24 14:47:57,492:INFO:[LightGBM] [Info] Total Bins 191
2024-12-24 14:47:57,492:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-24 14:47:57,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-24 14:47:57,492:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-24 14:47:57,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:47:57,554:INFO:Uploading results into container
2024-12-24 14:47:57,554:INFO:Uploading model into container now
2024-12-24 14:47:57,555:INFO:_master_model_container: 18
2024-12-24 14:47:57,555:INFO:_display_container: 4
2024-12-24 14:47:57,555:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:47:57,555:INFO:create_model() successfully completed......................................
2024-12-24 14:47:57,675:INFO:SubProcess create_model() end ==================================
2024-12-24 14:47:57,675:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.793
2024-12-24 14:47:57,676:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8025
2024-12-24 14:47:57,676:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-12-24 14:47:57,676:INFO:choose_better completed
2024-12-24 14:47:57,683:INFO:_master_model_container: 18
2024-12-24 14:47:57,683:INFO:_display_container: 3
2024-12-24 14:47:57,684:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:47:57,684:INFO:tune_model() successfully completed......................................
2024-12-24 14:48:27,510:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:48:27,511:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:48:27,519:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:48:27,519:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:48:27,522:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:48:27,523:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:48:27,526:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:48:27,527:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:48:27,530:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:48:27,530:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:53:54,354:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:53:54,354:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:53:54,359:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:53:54,359:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:53:54,363:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:53:54,364:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:53:54,367:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:53:54,368:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:53:54,372:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:53:54,372:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:54:20,104:INFO:Initializing tune_model()
2024-12-24 14:54:20,106:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>)
2024-12-24 14:54:20,106:INFO:Checking exceptions
2024-12-24 14:54:20,121:INFO:Copying training dataset
2024-12-24 14:54:20,126:INFO:Checking base model
2024-12-24 14:54:20,126:INFO:Base model : Light Gradient Boosting Machine
2024-12-24 14:54:20,131:INFO:Declaring metric variables
2024-12-24 14:54:20,135:INFO:Defining Hyperparameters
2024-12-24 14:54:20,246:INFO:Tuning with n_jobs=-1
2024-12-24 14:54:20,246:INFO:Initializing RandomizedSearchCV
2024-12-24 14:54:28,764:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 0.5, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 80, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 1, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.4}
2024-12-24 14:54:28,765:INFO:Hyperparameter search completed
2024-12-24 14:54:28,765:INFO:SubProcess create_model() called ==================================
2024-12-24 14:54:28,766:INFO:Initializing create_model()
2024-12-24 14:54:28,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001928F62E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 0.5, 'num_leaves': 70, 'n_estimators': 80, 'min_split_gain': 0.7, 'min_child_samples': 1, 'learning_rate': 0.4, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.4})
2024-12-24 14:54:28,766:INFO:Checking exceptions
2024-12-24 14:54:28,766:INFO:Importing libraries
2024-12-24 14:54:28,767:INFO:Copying training dataset
2024-12-24 14:54:28,771:INFO:Defining folds
2024-12-24 14:54:28,771:INFO:Declaring metric variables
2024-12-24 14:54:28,776:INFO:Importing untrained model
2024-12-24 14:54:28,776:INFO:Declaring custom model
2024-12-24 14:54:28,781:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:54:28,791:INFO:Starting cross validation
2024-12-24 14:54:28,793:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:54:28,900:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:28,961:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:28,961:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:28,966:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:28,976:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:28,988:INFO:Calculating mean and std
2024-12-24 14:54:28,989:INFO:Creating metrics dataframe
2024-12-24 14:54:28,996:INFO:Finalizing model
2024-12-24 14:54:29,036:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-12-24 14:54:29,037:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2024-12-24 14:54:29,037:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-12-24 14:54:29,038:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-12-24 14:54:29,038:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2024-12-24 14:54:29,038:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2024-12-24 14:54:29,038:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-24 14:54:29,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.
2024-12-24 14:54:29,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-24 14:54:29,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-24 14:54:29,039:INFO:[LightGBM] [Info] Total Bins 191
2024-12-24 14:54:29,039:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-24 14:54:29,040:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-24 14:54:29,040:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-24 14:54:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-12-24 14:54:29,063:INFO:Uploading results into container
2024-12-24 14:54:29,064:INFO:Uploading model into container now
2024-12-24 14:54:29,064:INFO:_master_model_container: 19
2024-12-24 14:54:29,065:INFO:_display_container: 4
2024-12-24 14:54:29,065:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:54:29,065:INFO:create_model() successfully completed......................................
2024-12-24 14:54:29,193:INFO:SubProcess create_model() end ==================================
2024-12-24 14:54:29,193:INFO:choose_better activated
2024-12-24 14:54:29,197:INFO:SubProcess create_model() called ==================================
2024-12-24 14:54:29,198:INFO:Initializing create_model()
2024-12-24 14:54:29,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001928C1A9780>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-24 14:54:29,198:INFO:Checking exceptions
2024-12-24 14:54:29,201:INFO:Importing libraries
2024-12-24 14:54:29,201:INFO:Copying training dataset
2024-12-24 14:54:29,204:INFO:Defining folds
2024-12-24 14:54:29,204:INFO:Declaring metric variables
2024-12-24 14:54:29,205:INFO:Importing untrained model
2024-12-24 14:54:29,205:INFO:Declaring custom model
2024-12-24 14:54:29,205:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-24 14:54:29,205:INFO:Starting cross validation
2024-12-24 14:54:29,206:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-12-24 14:54:29,418:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:29,424:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:29,444:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:29,468:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:29,479:WARNING:D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "D:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "D:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "D:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "D:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "D:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "D:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-24 14:54:29,491:INFO:Calculating mean and std
2024-12-24 14:54:29,492:INFO:Creating metrics dataframe
2024-12-24 14:54:29,494:INFO:Finalizing model
2024-12-24 14:54:29,534:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-12-24 14:54:29,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-12-24 14:54:29,535:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-12-24 14:54:29,535:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-12-24 14:54:29,535:INFO:[LightGBM] [Info] Total Bins 191
2024-12-24 14:54:29,535:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 9
2024-12-24 14:54:29,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-12-24 14:54:29,535:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-12-24 14:54:29,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-12-24 14:54:29,611:INFO:Uploading results into container
2024-12-24 14:54:29,612:INFO:Uploading model into container now
2024-12-24 14:54:29,612:INFO:_master_model_container: 20
2024-12-24 14:54:29,612:INFO:_display_container: 5
2024-12-24 14:54:29,612:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:54:29,612:INFO:create_model() successfully completed......................................
2024-12-24 14:54:29,739:INFO:SubProcess create_model() end ==================================
2024-12-24 14:54:29,740:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7222, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.793
2024-12-24 14:54:29,740:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8025
2024-12-24 14:54:29,741:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-12-24 14:54:29,741:INFO:choose_better completed
2024-12-24 14:54:29,748:INFO:_master_model_container: 20
2024-12-24 14:54:29,748:INFO:_display_container: 4
2024-12-24 14:54:29,748:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=1, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=80, n_jobs=-1, num_leaves=70, objective=None,
               random_state=7222, reg_alpha=0.5, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-24 14:54:29,748:INFO:tune_model() successfully completed......................................
2024-12-24 14:54:52,139:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:54:52,140:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:54:52,144:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:54:52,144:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:54:52,147:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:54:52,148:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:54:52,151:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:54:52,151:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 14:54:52,154:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2024-12-24 14:54:52,155:WARNING:D:\Anaconda\lib\site-packages\sklearn\preprocessing\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)

2024-12-24 16:13:08,512:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7fd87b9e6a2e4fbd957460b18ab3b143
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,512:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_51cd48fc66ca41fda471e6eba9730d5b_c72e01a3c2b6430b82019e1e426608d9
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,512:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_e556c69517184a84b6c9845616e9215c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,512:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_35b83101f21d4cff87127b8fdf11e86d_6af9cfab6b4d47d89d45aa251e6bfa69
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,512:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7683f6e998fc4530a51f8190c10cf704
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_b7aae8da95d2418493e9c73ea5dc9ea6_b00091a3dca74adf8e94c428b575812f
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7b9f4ff0e2b248c4b81226cccbe87383
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_7048f8efffe24bef97be12335519d107_3e29bb67834d43afbe79da61e6deb79a
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_4702a1cc18bc49748b69bb552f07b336
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_06284fa5d97b44f2a9532092f1715745_14181eb0c37e45338b168c142e71b484
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_c304a331eb9a4311a4773ad21ff8f38a
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_cac5507f701844608b8923a852091b23_1868c4d23e7f4108ba353d7c8fcfe05e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_5c492a1afddd4a18a8f2bb67913a2875
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_8f9240c7f7744c22ad99851a0de1cb78_ed15b163085648ae9abdd70ccaec73a7
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,513:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_e2fdfcb344944ebda07af80a437cf796
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,514:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_0b1b76fc638c45dfa61d164cf35dd3f7_3c39a328ea534a95a3aad3f77fefbda2
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,514:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_0ae82bbebe4b4a09b41398b2bac41a6c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,514:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_afe2058fc23549f19ae008971e67faf7_3d30beb55a9842c69083602ea03466fd
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,514:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_13f87b162a484824b55a23f14cbf1b00
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_e71816a306834b1f90aba3663a4458b1_84ab9da9ee224b43a0461534d44b3ae1
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7a898cfb5be348d4a1076e64768ec89d
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_e5b55dfd161f4bba8c3c12770225e802_a78ccef5aa3e4d8eb52228132160b29b
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_d95afe94418f4b6ba76e26b151e40d26
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_d6daa7553a0743338b2bccb593978387_3d630be0857644beb322a4cd8bfbd770
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_dbd6c56aa1a742208d22afa96955d649
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_53f01d12ec6c43028ee206bb7fa193b8_687318806f8c447fba70f9a6efd2f85e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_afc671b839c24bf29d5d56812178bb9b
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_029fa86bb1fa487298de12474be38c4f_13cb8c7ecec44f3b8acd2fd6b06a280d
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7708f67cf3bd4adaa7fce2abe8760c13
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,515:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_c6d0d3fe8e434dee80aed65c7d17e154_2cb72727c5434d6cb8f9474ab532c795
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_a74c3bfc8fa2477bae4284b65d6bbc02
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_5d709552fd4541ac8f5bfda48a0ad203_91b3056c9f584df98ac9ae45d6710aa0
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_c455622bca1546a7999c706b5e50e7be
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_e6f838f00c7f4b2ea75ad51830128a95_d8e3adbfb7064b38b8ca036ecc3b40b7
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_698d6ba2480b484d8d00e21832c1b7a7
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_747de2e6099d4c45a1de73255f7f35a2_1fb3ea3a3eb640ffbc5eacaaf8778f10
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_c91839ab61024d539bfd100db920d470
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_0dab50815c0549ee9fe614d531a8a20e_6988a2d73b84436cb10f59ca4ecb0c12
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,516:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_585ec33c88fe42529111ec422ddf43d0
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_567dc5242d414db4a3549be79a01d02b_0d06a2222d0f465fad43830fdebb1d66
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_03af73bfa87c4e929024acb8f5c3aba6
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_a6c04f2dec064473b1ad5736a9502cc2_d7db939d67b44efb9e6f920299466099
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_df43f368354147739643ab370ba6b72c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_f2d8013d32be4c5b801aab7c3872f9cc_d40bd20af3cd448c9050368482e6439a
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_9fc94f11bcaf4d1ea927cfe8af88144d
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_8df928c9410244e58f0d8e3c6d076eec_739ed7fedbeb4507bcea9d0afbe71d4b
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_6ff31349498942209dd916ec9a2104d1
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_82f01aae2ed64f15a0d44011e1afe535_9234202882714fd883339ed99f8a188b
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_d2e4872a590647ac835678edd3125b5c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_96f16303499a465eaf49f732297fbfe7_9eae55f350874d96bc9bde65ee0f27ea
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_fb975e793c974bb280651c354de8251e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,517:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_96c2b1db2af64ead8dcbd74704eca61b_c16bd61a70004cfca6d61bca6b2c0572
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_f5f2407799334dd0ae2a82be5f08de91
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_0cdba55ef98c4902b2e93b49a3f8e675_27e1670b03ae42d7af19d12d69873772
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_ddc1f4326cad42a8b6dcec6d4cad1795
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_3e01520c72d14ac6b05d7adf339c31c5_b42b8973245947d286a12d56e4f4fc64
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7edbf01868004d9a84b936d8e16fd311
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_9ac635718ee24ab4a9da4e26d8a8a6e1_b7bc319807744fe1b8353094b44e4ecd
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_3d058b0507fa46d4b90bc5156d52f17c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_fecb8e7b93164d5093c54c95eee6160e_0b12e9b122d84d5ebd0977fc4ca50f56
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_17a144e64dc64368bcc6674f20510e6d
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,518:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_d1de57ca5e9f480b95b10db0aa86954d_e3ac4e0e22754957a9dfafdebdd4fbbf
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_4b051516287d4f1a9a57672152a01656
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_fd35ca7197714b67bf1a019fe03fe38c_ccd833235aec41afb5d5b07c675587b1
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_63c908b3088648648b993cde936f1db5
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_642d5ff7d6e147cf93916d8cfb3bacb6_4c5971cc36f041ec84fe70169e78fb47
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_98acbd5c7af14dc6a017cf7a2200afe4
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_edc5fe2d81d249aa936be8c0196d5d27_5b669ca68bec4bbcb4279d6916dcda6d
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_dd8ca3cce5f74dfda15c3ba6907ba967
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_519765e805e04048b3102bf8e12772df_8790fa44a0074dfd8e4dc85a2b9e3a90
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,519:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_eb24895d9ba34a20afba7fb6de3307eb
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_6871a935c09749eca3a13bc8ebfe10e2_fb222fdce78d44ed82bf6d8773095c6e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_2c74c7df5e0f4ed59bee9fc28139a4fb
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_9a1a5467f6f945c38bf0e756e5d3d1c5_d2a7f373d1b6491aa491ae1bbe27c9b0
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_ba6395d1233c4c6da455d9d5ff1745cb
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_3abfe002587e46bc9023b32e2f9fa432_4fdc66919fee492087d877c2f1f36399
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_a790e5a229ea4361b4eeebfc16cee0f5
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_2f0ecf8aa83b485fa5e85e6a1b9d2405_e9204e5e548f4f11a530376ba6c2b1db
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_8f76cd8313704d09b3c0d9fb600ff52e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_ba230fdb993c4b6da8b0270fab4101a8_4fece593b9964b07b3e0ac348311d40c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_a44f6cdf846249758d522c37e7950da9
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_755171e1cb654a41b146a26609a61143_cdbd9028064e40de95a1d8446d1e6fc6
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,520:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_17239bf7cf14474889006f3cda6e7781
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_539447fa444b4860a80cfd0ed24c0ec6_504efd95857d4caeaca03d10343a28e1
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_b075b8ded863457997448716d1344fc2
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_05d370078925404ba452a8b3780dd703_f2256e25f27e4a198263bace8f6b592c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_d879a2f3c20a423492fd57ccda4f559b
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_99fb3c0e5fe14d53bf9d3583f9481f66_d6140efbca0e49e7ae0a5d3418ac519a
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_0c5139a9cc124cb3a444d2310d2b6e13
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_7a7c116ef1f74d3e9046dd700d2b5049_5d4ba95104984dd2946bfee8ccd7fdd1
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_bd92039f69f44f9581bf02e4ece81078
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_4e2f2b34046b471db30f4a27b1ec667c_48369e9fcf044e6b884a2e05bced2d39
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_810c904a0fba4f3fa18d88273fc69c62
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_3bd6dbcd2cdc450183cb312fc4bbe175_d306085df480494b9f90978ac333ca95
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_2f14938904ba4408982b7b570edb62df
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,521:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_f3aec25ceaf845d6b2b8776c6439a4f2_68b9f8330c71481b8d7113d9f35276d9
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_6195abbe7e6e4d6fa49bb50ea37d9155
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_dfb515bf5b454d2eb37dda0ef4286f1c_1ed22341570c4ea8a51b4c79b76dd3f3
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_f5a8eefd78b4475a88211c40d753fb17
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_502403f0e8d94e23ac71bafe4e42d8d5_4ec41424ace74b1fad6ba9ad1d2f8553
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_29490499c69a48ec823fcb1ef6e15f59
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_a081fd6c8b734ea4b77374bb8bf8a831_c88255f569d1408c9bb82a7631c5cc35
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_11580389fa164797892dfa116fd113f5
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_d38132edd69a449da0561a5541445f3b_f48d857cb50546b1a1992f0bbe4350ea
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,523:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_e74d1b10437645dc8af596b2eb91f8c8
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_dad50b00de224ed9b7b8c24b1569866b_c43c08e6f5c64bdfb9a8cc8aba3cb008
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_813ab0807aa543298e007c5d8769dc65
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_bb247310dcdf4a7cba55c7f22c23030d_0d19b214ea094bb4b8b4d76ce8f9ec97
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_6183415afb45441289410de917d3b370
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_5d732c6ce9b94b668373503efa804378_78a7c3d082b749508324d371d3dbdc02
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_0486f9f949d84153ab7fd58575e640da
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_50c8613e5817487eb410f5bd0c4104b2_b7e0262b935742688a518b823658c219
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_44ed9cd752dd4b468ec2b5062f486079
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_6ee60015145243d691c2e02c1e756df7_96cdbe7cc60e46fe8b032cbdf323291c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_9cc8fa42564c433c97911df3716cd8b5
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_5761f5ed60aa478cb6d0ec4dc36969fd_bf30e14353404b73a06d92489cb60754
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,524:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_169f91786eba4a889bc3ca493a910abd
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_4b30f650b52b4649aabc109df240fec5_3b107fc2da424ceeacecc3aa6935f94c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_7f10759197e94d76b509b1225fe0c693
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_ded599dda9e04c47a37d01a500256ccd_8181866248934f38921f55b7ae0cf57c
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_99ababfa632e4bbd96d1e6114eae53b9
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_2f245ce64da24169a9bbdf9e83c3466e_0275342ecb504305abcd789faa742938
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_8cee8deb699443c487c169671075b9e8
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_b1f029fb325a46b3a65f732d3c510898_8dc7a5b8ba8446f0a93756ce6bb678b8
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_e8601ec5b2c44abb81979bd1ab079c2e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_f24d04a2059746b9a263ffd429c59154_bd2581e1786e40358b92c4bd66bb4576
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,525:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_cdade19a67964401bfae378590dab500
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_ca53071f00604c4eb05361ab933ec638_479262a8c7a642efa5672c0894a13ab2
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_a021a044539b4c4988c6120fcd80748e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_f9b768a7c030488688afa519fa0f0691_8b8001238ca64fab9899585709c65acf
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_57381e4532494261b7be173ae7ca481e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_6937de7095c74b5eaf57b5df8168b26b_0f025491c40b46aeabcbb3579d533ff9
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_472e2136a4264e21a492f168caec4847
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_065899cb0c8f49cb9a00c408bfbcfc5b_74c7b74b51304871895dc6dea6f45124
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_751cdb5a6275452eb8faa83bcb146361
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_763a3788561a4c0a9607bbabbc2550c3_00e12f8d0cfb42868f0379366cc51616
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_fbd57b33f11b49a483b0ed08fa0b7d5e
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-24 16:13:08,526:WARNING:D:\Anaconda\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\LENOVO\AppData\Local\Temp\joblib_memmapping_folder_12488_211ffefaeaa842b9b9bee7c8bda20f52_ea2dc6b3a35e46fba6378bea03fb9824
  warnings.warn("Failed to delete temporary folder: {}"

2024-12-27 10:35:40,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-27 10:35:40,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-27 10:35:40,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-27 10:35:40,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-28 09:51:41,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-28 09:51:41,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-28 09:51:41,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-28 09:51:41,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-28 10:54:38,082:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3381118840.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True)

2024-12-28 10:54:50,662:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3381118840.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True)

2024-12-28 10:59:07,399:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\4160851265.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 10:59:07,401:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\4160851265.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X.dropna(subset=['Embarked'], inplace=True) #drop rows with missing values

2024-12-28 11:01:44,477:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\2472744080.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 11:01:44,481:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\2472744080.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True) #fill missing values with mode  (most frequent value)

2024-12-28 11:12:55,769:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3271732328.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 11:12:55,770:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3271732328.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True) #fill missing values with mode  (most frequent value)

2024-12-28 11:13:16,541:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\164436887.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 11:13:16,541:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\164436887.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True) #fill missing values with mode  (most frequent value)

2024-12-28 11:13:16,543:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\164436887.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Sex']=X['Sex'].map({'male':0,'female':1})

2024-12-28 11:14:24,556:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 11:14:24,557:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True) #fill missing values with mode  (most frequent value)

2024-12-28 11:14:24,559:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Sex']=X['Sex'].map({'male':0,'female':1})

2024-12-28 11:14:24,559:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:8: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked']=X['Embarked'].map({'S':0,'C':1,'Q':2})

2024-12-28 11:14:30,645:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3338940479.py:491: UserWarning: cannot convert float NaN to integer
  warnings.warn(str(e))

2024-12-28 11:14:37,997:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3338940479.py:491: UserWarning: cannot convert float NaN to integer
  warnings.warn(str(e))

2024-12-28 11:14:43,778:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 11:14:43,779:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True) #fill missing values with mode  (most frequent value)

2024-12-28 11:14:43,780:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Sex']=X['Sex'].map({'male':0,'female':1})

2024-12-28 11:14:43,781:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:8: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked']=X['Embarked'].map({'S':0,'C':1,'Q':2})

2024-12-28 11:14:47,756:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3338940479.py:491: UserWarning: cannot convert float NaN to integer
  warnings.warn(str(e))

2024-12-28 11:14:47,927:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3338940479.py:491: UserWarning: cannot convert float NaN to integer
  warnings.warn(str(e))

2024-12-28 11:15:05,383:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3338940479.py:491: UserWarning: cannot convert float NaN to integer
  warnings.warn(str(e))

2024-12-28 11:15:05,555:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\3338940479.py:491: UserWarning: cannot convert float NaN to integer
  warnings.warn(str(e))

2024-12-28 11:15:26,009:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Age'].fillna(int(X['Age'].mean()), inplace=True) #fill missing values with mean

2024-12-28 11:15:26,009:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked'].fillna(X['Embarked'].mode()[0], inplace=True) #fill missing values with mode  (most frequent value)

2024-12-28 11:15:26,010:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Sex']=X['Sex'].map({'male':0,'female':1})

2024-12-28 11:15:26,010:WARNING:C:\Users\LENOVO\AppData\Local\Temp\ipykernel_2268\305808392.py:8: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  X['Embarked']=X['Embarked'].map({'S':0,'C':1,'Q':2})

2024-12-28 11:44:25,736:INFO:PyCaret ClassificationExperiment
2024-12-28 11:44:25,736:INFO:Logging name: clf-default-name
2024-12-28 11:44:25,736:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-28 11:44:25,736:INFO:version 3.3.1
2024-12-28 11:44:25,736:INFO:Initializing setup()
2024-12-28 11:44:25,736:INFO:self.USI: 8234
2024-12-28 11:44:25,736:INFO:self._variable_keys: {'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', 'log_plots_param', 'USI', '_available_plots', 'pipeline', 'idx', 'X_test', 'html_param', '_ml_usecase', 'X', 'n_jobs_param', 'target_param', 'fold_generator', 'memory', 'is_multiclass', 'exp_id', 'logging_param', 'exp_name_log', 'fold_groups_param', 'y_test', 'X_train', 'seed', 'gpu_param', 'y_train', 'fold_shuffle_param'}
2024-12-28 11:44:25,736:INFO:Checking environment
2024-12-28 11:44:25,736:INFO:python_version: 3.10.15
2024-12-28 11:44:25,736:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-28 11:44:25,736:INFO:machine: AMD64
2024-12-28 11:44:25,736:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-28 11:44:25,736:INFO:Memory: svmem(total=16312721408, available=4616011776, percent=71.7, used=11696709632, free=4616011776)
2024-12-28 11:44:25,736:INFO:Physical Core: 6
2024-12-28 11:44:25,736:INFO:Logical Core: 12
2024-12-28 11:44:25,736:INFO:Checking libraries
2024-12-28 11:44:25,736:INFO:System:
2024-12-28 11:44:25,736:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-28 11:44:25,736:INFO:executable: d:\Anaconda\python.exe
2024-12-28 11:44:25,736:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-28 11:44:25,736:INFO:PyCaret required dependencies:
2024-12-28 11:44:25,889:INFO:                 pip: 24.2
2024-12-28 11:44:25,889:INFO:          setuptools: 75.1.0
2024-12-28 11:44:25,889:INFO:             pycaret: 3.3.1
2024-12-28 11:44:25,889:INFO:             IPython: 8.27.0
2024-12-28 11:44:25,889:INFO:          ipywidgets: 8.1.2
2024-12-28 11:44:25,889:INFO:                tqdm: 4.66.5
2024-12-28 11:44:25,890:INFO:               numpy: 1.26.4
2024-12-28 11:44:25,890:INFO:              pandas: 2.1.4
2024-12-28 11:44:25,890:INFO:              jinja2: 3.1.4
2024-12-28 11:44:25,890:INFO:               scipy: 1.11.4
2024-12-28 11:44:25,890:INFO:              joblib: 1.2.0
2024-12-28 11:44:25,890:INFO:             sklearn: 1.4.2
2024-12-28 11:44:25,890:INFO:                pyod: 2.0.2
2024-12-28 11:44:25,890:INFO:            imblearn: 0.12.3
2024-12-28 11:44:25,890:INFO:   category_encoders: 2.6.3
2024-12-28 11:44:25,890:INFO:            lightgbm: 4.5.0
2024-12-28 11:44:25,890:INFO:               numba: 0.60.0
2024-12-28 11:44:25,890:INFO:            requests: 2.32.3
2024-12-28 11:44:25,890:INFO:          matplotlib: 3.9.2
2024-12-28 11:44:25,890:INFO:          scikitplot: 0.3.7
2024-12-28 11:44:25,890:INFO:         yellowbrick: 1.5
2024-12-28 11:44:25,890:INFO:              plotly: 5.24.1
2024-12-28 11:44:25,890:INFO:    plotly-resampler: Not installed
2024-12-28 11:44:25,890:INFO:             kaleido: 0.2.1
2024-12-28 11:44:25,890:INFO:           schemdraw: 0.15
2024-12-28 11:44:25,890:INFO:         statsmodels: 0.14.2
2024-12-28 11:44:25,890:INFO:              sktime: 0.26.0
2024-12-28 11:44:25,890:INFO:               tbats: 1.1.3
2024-12-28 11:44:25,890:INFO:            pmdarima: 2.0.4
2024-12-28 11:44:25,890:INFO:              psutil: 5.9.0
2024-12-28 11:44:25,890:INFO:          markupsafe: 2.1.3
2024-12-28 11:44:25,890:INFO:             pickle5: Not installed
2024-12-28 11:44:25,890:INFO:         cloudpickle: 3.0.0
2024-12-28 11:44:25,890:INFO:         deprecation: 2.1.0
2024-12-28 11:44:25,891:INFO:              xxhash: 2.0.2
2024-12-28 11:44:25,891:INFO:           wurlitzer: 3.1.1
2024-12-28 11:44:25,891:INFO:PyCaret optional dependencies:
2024-12-28 11:44:25,969:INFO:                shap: Not installed
2024-12-28 11:44:25,969:INFO:           interpret: Not installed
2024-12-28 11:44:25,969:INFO:                umap: 0.5.3
2024-12-28 11:44:25,969:INFO:     ydata_profiling: Not installed
2024-12-28 11:44:25,969:INFO:  explainerdashboard: Not installed
2024-12-28 11:44:25,970:INFO:             autoviz: Not installed
2024-12-28 11:44:25,970:INFO:           fairlearn: Not installed
2024-12-28 11:44:25,970:INFO:          deepchecks: Not installed
2024-12-28 11:44:25,970:INFO:             xgboost: 2.1.2
2024-12-28 11:44:25,970:INFO:            catboost: 1.2.3
2024-12-28 11:44:25,970:INFO:              kmodes: 0.12.2
2024-12-28 11:44:25,970:INFO:             mlxtend: 0.23.1
2024-12-28 11:44:25,970:INFO:       statsforecast: Not installed
2024-12-28 11:44:25,970:INFO:        tune_sklearn: Not installed
2024-12-28 11:44:25,970:INFO:                 ray: Not installed
2024-12-28 11:44:25,970:INFO:            hyperopt: Not installed
2024-12-28 11:44:25,970:INFO:              optuna: Not installed
2024-12-28 11:44:25,970:INFO:               skopt: Not installed
2024-12-28 11:44:25,970:INFO:              mlflow: 2.16.2
2024-12-28 11:44:25,970:INFO:              gradio: Not installed
2024-12-28 11:44:25,970:INFO:             fastapi: Not installed
2024-12-28 11:44:25,970:INFO:             uvicorn: Not installed
2024-12-28 11:44:25,970:INFO:              m2cgen: Not installed
2024-12-28 11:44:25,970:INFO:           evidently: Not installed
2024-12-28 11:44:25,970:INFO:               fugue: Not installed
2024-12-28 11:44:25,970:INFO:           streamlit: Not installed
2024-12-28 11:44:25,970:INFO:             prophet: Not installed
2024-12-28 11:44:25,970:INFO:None
2024-12-28 11:44:25,970:INFO:Set up data.
2024-12-28 11:44:25,975:INFO:Set up folding strategy.
2024-12-28 11:44:25,975:INFO:Set up train/test split.
2024-12-28 11:44:25,984:INFO:Set up index.
2024-12-28 11:44:25,985:INFO:Assigning column types.
2024-12-28 11:44:25,988:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-28 11:44:26,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-28 11:44:26,030:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:44:26,062:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,065:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-28 11:44:26,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:44:26,249:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,251:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,251:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-28 11:44:26,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:44:26,305:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,308:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,343:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:44:26,364:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,366:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,366:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-28 11:44:26,421:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,424:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,480:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,482:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,483:INFO:Preparing preprocessing pipeline...
2024-12-28 11:44:26,486:INFO:Set up simple imputation.
2024-12-28 11:44:26,506:INFO:Finished creating preprocessing pipeline.
2024-12-28 11:44:26,511:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-28 11:44:26,511:INFO:Creating final display dataframe.
2024-12-28 11:44:26,565:INFO:Setup _display_container:                     Description             Value
0                    Session id              5449
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 7)
4        Transformed data shape          (891, 7)
5   Transformed train set shape          (623, 7)
6    Transformed test set shape          (268, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8234
2024-12-28 11:44:26,629:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,631:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,690:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:44:26,692:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:44:26,693:INFO:setup() successfully completed in 0.96s...............
2024-12-28 11:44:26,693:INFO:Initializing compare_models()
2024-12-28 11:44:26,694:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-28 11:44:26,694:INFO:Checking exceptions
2024-12-28 11:44:26,698:INFO:Preparing display monitor
2024-12-28 11:44:26,715:INFO:Initializing Logistic Regression
2024-12-28 11:44:26,715:INFO:Total runtime is 0.0 minutes
2024-12-28 11:44:26,718:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:26,719:INFO:Initializing create_model()
2024-12-28 11:44:26,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:26,719:INFO:Checking exceptions
2024-12-28 11:44:26,719:INFO:Importing libraries
2024-12-28 11:44:26,720:INFO:Copying training dataset
2024-12-28 11:44:26,723:INFO:Defining folds
2024-12-28 11:44:26,723:INFO:Declaring metric variables
2024-12-28 11:44:26,726:INFO:Importing untrained model
2024-12-28 11:44:26,730:INFO:Logistic Regression Imported successfully
2024-12-28 11:44:26,737:INFO:Starting cross validation
2024-12-28 11:44:26,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:30,418:INFO:Calculating mean and std
2024-12-28 11:44:30,419:INFO:Creating metrics dataframe
2024-12-28 11:44:30,422:INFO:Uploading results into container
2024-12-28 11:44:30,423:INFO:Uploading model into container now
2024-12-28 11:44:30,424:INFO:_master_model_container: 1
2024-12-28 11:44:30,424:INFO:_display_container: 2
2024-12-28 11:44:30,425:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5449, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-28 11:44:30,425:INFO:create_model() successfully completed......................................
2024-12-28 11:44:30,600:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:30,600:INFO:Creating metrics dataframe
2024-12-28 11:44:30,605:INFO:Initializing K Neighbors Classifier
2024-12-28 11:44:30,606:INFO:Total runtime is 0.06486073335011801 minutes
2024-12-28 11:44:30,609:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:30,609:INFO:Initializing create_model()
2024-12-28 11:44:30,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:30,609:INFO:Checking exceptions
2024-12-28 11:44:30,609:INFO:Importing libraries
2024-12-28 11:44:30,610:INFO:Copying training dataset
2024-12-28 11:44:30,613:INFO:Defining folds
2024-12-28 11:44:30,613:INFO:Declaring metric variables
2024-12-28 11:44:30,616:INFO:Importing untrained model
2024-12-28 11:44:30,619:INFO:K Neighbors Classifier Imported successfully
2024-12-28 11:44:30,625:INFO:Starting cross validation
2024-12-28 11:44:30,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:32,241:INFO:Calculating mean and std
2024-12-28 11:44:32,242:INFO:Creating metrics dataframe
2024-12-28 11:44:32,244:INFO:Uploading results into container
2024-12-28 11:44:32,244:INFO:Uploading model into container now
2024-12-28 11:44:32,244:INFO:_master_model_container: 2
2024-12-28 11:44:32,244:INFO:_display_container: 2
2024-12-28 11:44:32,246:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-28 11:44:32,246:INFO:create_model() successfully completed......................................
2024-12-28 11:44:32,382:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:32,382:INFO:Creating metrics dataframe
2024-12-28 11:44:32,388:INFO:Initializing Naive Bayes
2024-12-28 11:44:32,388:INFO:Total runtime is 0.09455666939417522 minutes
2024-12-28 11:44:32,391:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:32,392:INFO:Initializing create_model()
2024-12-28 11:44:32,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:32,392:INFO:Checking exceptions
2024-12-28 11:44:32,392:INFO:Importing libraries
2024-12-28 11:44:32,392:INFO:Copying training dataset
2024-12-28 11:44:32,396:INFO:Defining folds
2024-12-28 11:44:32,396:INFO:Declaring metric variables
2024-12-28 11:44:32,400:INFO:Importing untrained model
2024-12-28 11:44:32,402:INFO:Naive Bayes Imported successfully
2024-12-28 11:44:32,408:INFO:Starting cross validation
2024-12-28 11:44:32,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:32,466:INFO:Calculating mean and std
2024-12-28 11:44:32,466:INFO:Creating metrics dataframe
2024-12-28 11:44:32,468:INFO:Uploading results into container
2024-12-28 11:44:32,468:INFO:Uploading model into container now
2024-12-28 11:44:32,468:INFO:_master_model_container: 3
2024-12-28 11:44:32,468:INFO:_display_container: 2
2024-12-28 11:44:32,469:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-28 11:44:32,469:INFO:create_model() successfully completed......................................
2024-12-28 11:44:32,594:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:32,594:INFO:Creating metrics dataframe
2024-12-28 11:44:32,601:INFO:Initializing Decision Tree Classifier
2024-12-28 11:44:32,601:INFO:Total runtime is 0.09810382525126139 minutes
2024-12-28 11:44:32,603:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:32,603:INFO:Initializing create_model()
2024-12-28 11:44:32,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:32,604:INFO:Checking exceptions
2024-12-28 11:44:32,604:INFO:Importing libraries
2024-12-28 11:44:32,604:INFO:Copying training dataset
2024-12-28 11:44:32,608:INFO:Defining folds
2024-12-28 11:44:32,608:INFO:Declaring metric variables
2024-12-28 11:44:32,611:INFO:Importing untrained model
2024-12-28 11:44:32,614:INFO:Decision Tree Classifier Imported successfully
2024-12-28 11:44:32,620:INFO:Starting cross validation
2024-12-28 11:44:32,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:32,675:INFO:Calculating mean and std
2024-12-28 11:44:32,676:INFO:Creating metrics dataframe
2024-12-28 11:44:32,678:INFO:Uploading results into container
2024-12-28 11:44:32,678:INFO:Uploading model into container now
2024-12-28 11:44:32,679:INFO:_master_model_container: 4
2024-12-28 11:44:32,679:INFO:_display_container: 2
2024-12-28 11:44:32,679:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5449, splitter='best')
2024-12-28 11:44:32,679:INFO:create_model() successfully completed......................................
2024-12-28 11:44:32,808:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:32,808:INFO:Creating metrics dataframe
2024-12-28 11:44:32,814:INFO:Initializing SVM - Linear Kernel
2024-12-28 11:44:32,815:INFO:Total runtime is 0.1016660451889038 minutes
2024-12-28 11:44:32,818:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:32,818:INFO:Initializing create_model()
2024-12-28 11:44:32,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:32,818:INFO:Checking exceptions
2024-12-28 11:44:32,818:INFO:Importing libraries
2024-12-28 11:44:32,818:INFO:Copying training dataset
2024-12-28 11:44:32,821:INFO:Defining folds
2024-12-28 11:44:32,821:INFO:Declaring metric variables
2024-12-28 11:44:32,825:INFO:Importing untrained model
2024-12-28 11:44:32,829:INFO:SVM - Linear Kernel Imported successfully
2024-12-28 11:44:32,834:INFO:Starting cross validation
2024-12-28 11:44:32,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:32,888:INFO:Calculating mean and std
2024-12-28 11:44:32,888:INFO:Creating metrics dataframe
2024-12-28 11:44:32,890:INFO:Uploading results into container
2024-12-28 11:44:32,890:INFO:Uploading model into container now
2024-12-28 11:44:32,890:INFO:_master_model_container: 5
2024-12-28 11:44:32,890:INFO:_display_container: 2
2024-12-28 11:44:32,891:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5449, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-28 11:44:32,891:INFO:create_model() successfully completed......................................
2024-12-28 11:44:33,018:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:33,018:INFO:Creating metrics dataframe
2024-12-28 11:44:33,024:INFO:Initializing Ridge Classifier
2024-12-28 11:44:33,025:INFO:Total runtime is 0.10518099069595337 minutes
2024-12-28 11:44:33,028:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:33,028:INFO:Initializing create_model()
2024-12-28 11:44:33,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:33,029:INFO:Checking exceptions
2024-12-28 11:44:33,029:INFO:Importing libraries
2024-12-28 11:44:33,029:INFO:Copying training dataset
2024-12-28 11:44:33,033:INFO:Defining folds
2024-12-28 11:44:33,033:INFO:Declaring metric variables
2024-12-28 11:44:33,035:INFO:Importing untrained model
2024-12-28 11:44:33,039:INFO:Ridge Classifier Imported successfully
2024-12-28 11:44:33,045:INFO:Starting cross validation
2024-12-28 11:44:33,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:33,139:INFO:Calculating mean and std
2024-12-28 11:44:33,140:INFO:Creating metrics dataframe
2024-12-28 11:44:33,142:INFO:Uploading results into container
2024-12-28 11:44:33,142:INFO:Uploading model into container now
2024-12-28 11:44:33,143:INFO:_master_model_container: 6
2024-12-28 11:44:33,143:INFO:_display_container: 2
2024-12-28 11:44:33,143:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5449, solver='auto',
                tol=0.0001)
2024-12-28 11:44:33,143:INFO:create_model() successfully completed......................................
2024-12-28 11:44:33,270:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:33,271:INFO:Creating metrics dataframe
2024-12-28 11:44:33,278:INFO:Initializing Random Forest Classifier
2024-12-28 11:44:33,279:INFO:Total runtime is 0.10941200653711955 minutes
2024-12-28 11:44:33,281:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:33,282:INFO:Initializing create_model()
2024-12-28 11:44:33,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:33,282:INFO:Checking exceptions
2024-12-28 11:44:33,282:INFO:Importing libraries
2024-12-28 11:44:33,282:INFO:Copying training dataset
2024-12-28 11:44:33,285:INFO:Defining folds
2024-12-28 11:44:33,285:INFO:Declaring metric variables
2024-12-28 11:44:33,288:INFO:Importing untrained model
2024-12-28 11:44:33,292:INFO:Random Forest Classifier Imported successfully
2024-12-28 11:44:33,296:INFO:Starting cross validation
2024-12-28 11:44:33,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:33,586:INFO:Calculating mean and std
2024-12-28 11:44:33,588:INFO:Creating metrics dataframe
2024-12-28 11:44:33,590:INFO:Uploading results into container
2024-12-28 11:44:33,591:INFO:Uploading model into container now
2024-12-28 11:44:33,591:INFO:_master_model_container: 7
2024-12-28 11:44:33,591:INFO:_display_container: 2
2024-12-28 11:44:33,591:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5449, verbose=0,
                       warm_start=False)
2024-12-28 11:44:33,592:INFO:create_model() successfully completed......................................
2024-12-28 11:44:33,719:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:33,719:INFO:Creating metrics dataframe
2024-12-28 11:44:33,726:INFO:Initializing Quadratic Discriminant Analysis
2024-12-28 11:44:33,726:INFO:Total runtime is 0.11686378717422485 minutes
2024-12-28 11:44:33,730:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:33,730:INFO:Initializing create_model()
2024-12-28 11:44:33,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:33,730:INFO:Checking exceptions
2024-12-28 11:44:33,731:INFO:Importing libraries
2024-12-28 11:44:33,731:INFO:Copying training dataset
2024-12-28 11:44:33,734:INFO:Defining folds
2024-12-28 11:44:33,734:INFO:Declaring metric variables
2024-12-28 11:44:33,736:INFO:Importing untrained model
2024-12-28 11:44:33,740:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-28 11:44:33,745:INFO:Starting cross validation
2024-12-28 11:44:33,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:33,818:INFO:Calculating mean and std
2024-12-28 11:44:33,818:INFO:Creating metrics dataframe
2024-12-28 11:44:33,819:INFO:Uploading results into container
2024-12-28 11:44:33,819:INFO:Uploading model into container now
2024-12-28 11:44:33,820:INFO:_master_model_container: 8
2024-12-28 11:44:33,820:INFO:_display_container: 2
2024-12-28 11:44:33,820:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-28 11:44:33,820:INFO:create_model() successfully completed......................................
2024-12-28 11:44:33,947:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:33,947:INFO:Creating metrics dataframe
2024-12-28 11:44:33,954:INFO:Initializing Ada Boost Classifier
2024-12-28 11:44:33,954:INFO:Total runtime is 0.12065266370773316 minutes
2024-12-28 11:44:33,957:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:33,957:INFO:Initializing create_model()
2024-12-28 11:44:33,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:33,957:INFO:Checking exceptions
2024-12-28 11:44:33,957:INFO:Importing libraries
2024-12-28 11:44:33,958:INFO:Copying training dataset
2024-12-28 11:44:33,960:INFO:Defining folds
2024-12-28 11:44:33,961:INFO:Declaring metric variables
2024-12-28 11:44:33,963:INFO:Importing untrained model
2024-12-28 11:44:33,966:INFO:Ada Boost Classifier Imported successfully
2024-12-28 11:44:33,971:INFO:Starting cross validation
2024-12-28 11:44:33,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:34,003:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,003:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,009:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,009:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,012:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,020:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,026:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,031:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,031:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,033:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:44:34,168:INFO:Calculating mean and std
2024-12-28 11:44:34,168:INFO:Creating metrics dataframe
2024-12-28 11:44:34,170:INFO:Uploading results into container
2024-12-28 11:44:34,170:INFO:Uploading model into container now
2024-12-28 11:44:34,172:INFO:_master_model_container: 9
2024-12-28 11:44:34,172:INFO:_display_container: 2
2024-12-28 11:44:34,172:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5449)
2024-12-28 11:44:34,172:INFO:create_model() successfully completed......................................
2024-12-28 11:44:34,300:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:34,301:INFO:Creating metrics dataframe
2024-12-28 11:44:34,306:INFO:Initializing Gradient Boosting Classifier
2024-12-28 11:44:34,308:INFO:Total runtime is 0.12655253012975057 minutes
2024-12-28 11:44:34,310:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:34,310:INFO:Initializing create_model()
2024-12-28 11:44:34,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:34,310:INFO:Checking exceptions
2024-12-28 11:44:34,311:INFO:Importing libraries
2024-12-28 11:44:34,311:INFO:Copying training dataset
2024-12-28 11:44:34,314:INFO:Defining folds
2024-12-28 11:44:34,314:INFO:Declaring metric variables
2024-12-28 11:44:34,316:INFO:Importing untrained model
2024-12-28 11:44:34,321:INFO:Gradient Boosting Classifier Imported successfully
2024-12-28 11:44:34,325:INFO:Starting cross validation
2024-12-28 11:44:34,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:34,520:INFO:Calculating mean and std
2024-12-28 11:44:34,521:INFO:Creating metrics dataframe
2024-12-28 11:44:34,523:INFO:Uploading results into container
2024-12-28 11:44:34,525:INFO:Uploading model into container now
2024-12-28 11:44:34,525:INFO:_master_model_container: 10
2024-12-28 11:44:34,525:INFO:_display_container: 2
2024-12-28 11:44:34,526:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:44:34,526:INFO:create_model() successfully completed......................................
2024-12-28 11:44:34,654:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:34,654:INFO:Creating metrics dataframe
2024-12-28 11:44:34,662:INFO:Initializing Linear Discriminant Analysis
2024-12-28 11:44:34,662:INFO:Total runtime is 0.13244874477386476 minutes
2024-12-28 11:44:34,665:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:34,665:INFO:Initializing create_model()
2024-12-28 11:44:34,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:34,666:INFO:Checking exceptions
2024-12-28 11:44:34,666:INFO:Importing libraries
2024-12-28 11:44:34,666:INFO:Copying training dataset
2024-12-28 11:44:34,668:INFO:Defining folds
2024-12-28 11:44:34,669:INFO:Declaring metric variables
2024-12-28 11:44:34,672:INFO:Importing untrained model
2024-12-28 11:44:34,676:INFO:Linear Discriminant Analysis Imported successfully
2024-12-28 11:44:34,682:INFO:Starting cross validation
2024-12-28 11:44:34,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:34,741:INFO:Calculating mean and std
2024-12-28 11:44:34,742:INFO:Creating metrics dataframe
2024-12-28 11:44:34,743:INFO:Uploading results into container
2024-12-28 11:44:34,743:INFO:Uploading model into container now
2024-12-28 11:44:34,744:INFO:_master_model_container: 11
2024-12-28 11:44:34,744:INFO:_display_container: 2
2024-12-28 11:44:34,744:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-28 11:44:34,744:INFO:create_model() successfully completed......................................
2024-12-28 11:44:34,873:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:34,873:INFO:Creating metrics dataframe
2024-12-28 11:44:34,881:INFO:Initializing Extra Trees Classifier
2024-12-28 11:44:34,881:INFO:Total runtime is 0.13610725402832033 minutes
2024-12-28 11:44:34,883:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:34,885:INFO:Initializing create_model()
2024-12-28 11:44:34,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:34,885:INFO:Checking exceptions
2024-12-28 11:44:34,885:INFO:Importing libraries
2024-12-28 11:44:34,885:INFO:Copying training dataset
2024-12-28 11:44:34,888:INFO:Defining folds
2024-12-28 11:44:34,888:INFO:Declaring metric variables
2024-12-28 11:44:34,893:INFO:Importing untrained model
2024-12-28 11:44:34,897:INFO:Extra Trees Classifier Imported successfully
2024-12-28 11:44:34,903:INFO:Starting cross validation
2024-12-28 11:44:34,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:35,154:INFO:Calculating mean and std
2024-12-28 11:44:35,156:INFO:Creating metrics dataframe
2024-12-28 11:44:35,158:INFO:Uploading results into container
2024-12-28 11:44:35,158:INFO:Uploading model into container now
2024-12-28 11:44:35,158:INFO:_master_model_container: 12
2024-12-28 11:44:35,158:INFO:_display_container: 2
2024-12-28 11:44:35,159:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5449, verbose=0,
                     warm_start=False)
2024-12-28 11:44:35,159:INFO:create_model() successfully completed......................................
2024-12-28 11:44:35,288:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:35,288:INFO:Creating metrics dataframe
2024-12-28 11:44:35,296:INFO:Initializing Extreme Gradient Boosting
2024-12-28 11:44:35,296:INFO:Total runtime is 0.1430163105328878 minutes
2024-12-28 11:44:35,299:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:35,299:INFO:Initializing create_model()
2024-12-28 11:44:35,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:35,299:INFO:Checking exceptions
2024-12-28 11:44:35,299:INFO:Importing libraries
2024-12-28 11:44:35,299:INFO:Copying training dataset
2024-12-28 11:44:35,302:INFO:Defining folds
2024-12-28 11:44:35,302:INFO:Declaring metric variables
2024-12-28 11:44:35,305:INFO:Importing untrained model
2024-12-28 11:44:35,310:INFO:Extreme Gradient Boosting Imported successfully
2024-12-28 11:44:35,315:INFO:Starting cross validation
2024-12-28 11:44:35,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:40,366:INFO:Calculating mean and std
2024-12-28 11:44:40,368:INFO:Creating metrics dataframe
2024-12-28 11:44:40,370:INFO:Uploading results into container
2024-12-28 11:44:40,371:INFO:Uploading model into container now
2024-12-28 11:44:40,371:INFO:_master_model_container: 13
2024-12-28 11:44:40,371:INFO:_display_container: 2
2024-12-28 11:44:40,372:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-28 11:44:40,372:INFO:create_model() successfully completed......................................
2024-12-28 11:44:40,539:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:40,539:INFO:Creating metrics dataframe
2024-12-28 11:44:40,552:INFO:Initializing Light Gradient Boosting Machine
2024-12-28 11:44:40,552:INFO:Total runtime is 0.23063072760899864 minutes
2024-12-28 11:44:40,556:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:40,556:INFO:Initializing create_model()
2024-12-28 11:44:40,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:40,557:INFO:Checking exceptions
2024-12-28 11:44:40,557:INFO:Importing libraries
2024-12-28 11:44:40,557:INFO:Copying training dataset
2024-12-28 11:44:40,560:INFO:Defining folds
2024-12-28 11:44:40,560:INFO:Declaring metric variables
2024-12-28 11:44:40,564:INFO:Importing untrained model
2024-12-28 11:44:40,569:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-28 11:44:40,576:INFO:Starting cross validation
2024-12-28 11:44:40,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:44,982:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-28 11:44:49,009:INFO:Calculating mean and std
2024-12-28 11:44:49,011:INFO:Creating metrics dataframe
2024-12-28 11:44:49,013:INFO:Uploading results into container
2024-12-28 11:44:49,014:INFO:Uploading model into container now
2024-12-28 11:44:49,014:INFO:_master_model_container: 14
2024-12-28 11:44:49,014:INFO:_display_container: 2
2024-12-28 11:44:49,015:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5449, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-28 11:44:49,015:INFO:create_model() successfully completed......................................
2024-12-28 11:44:49,214:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:49,214:INFO:Creating metrics dataframe
2024-12-28 11:44:49,223:INFO:Initializing CatBoost Classifier
2024-12-28 11:44:49,223:INFO:Total runtime is 0.37514665921529133 minutes
2024-12-28 11:44:49,228:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:49,228:INFO:Initializing create_model()
2024-12-28 11:44:49,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:49,228:INFO:Checking exceptions
2024-12-28 11:44:49,228:INFO:Importing libraries
2024-12-28 11:44:49,228:INFO:Copying training dataset
2024-12-28 11:44:49,235:INFO:Defining folds
2024-12-28 11:44:49,235:INFO:Declaring metric variables
2024-12-28 11:44:49,241:INFO:Importing untrained model
2024-12-28 11:44:49,248:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:44:49,256:INFO:Starting cross validation
2024-12-28 11:44:49,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:53,534:INFO:Calculating mean and std
2024-12-28 11:44:53,535:INFO:Creating metrics dataframe
2024-12-28 11:44:53,538:INFO:Uploading results into container
2024-12-28 11:44:53,539:INFO:Uploading model into container now
2024-12-28 11:44:53,540:INFO:_master_model_container: 15
2024-12-28 11:44:53,540:INFO:_display_container: 2
2024-12-28 11:44:53,540:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCD185810>
2024-12-28 11:44:53,540:INFO:create_model() successfully completed......................................
2024-12-28 11:44:53,702:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:53,703:INFO:Creating metrics dataframe
2024-12-28 11:44:53,714:INFO:Initializing Dummy Classifier
2024-12-28 11:44:53,714:INFO:Total runtime is 0.44998620748519896 minutes
2024-12-28 11:44:53,717:INFO:SubProcess create_model() called ==================================
2024-12-28 11:44:53,718:INFO:Initializing create_model()
2024-12-28 11:44:53,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD9AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:53,718:INFO:Checking exceptions
2024-12-28 11:44:53,718:INFO:Importing libraries
2024-12-28 11:44:53,718:INFO:Copying training dataset
2024-12-28 11:44:53,722:INFO:Defining folds
2024-12-28 11:44:53,722:INFO:Declaring metric variables
2024-12-28 11:44:53,727:INFO:Importing untrained model
2024-12-28 11:44:53,731:INFO:Dummy Classifier Imported successfully
2024-12-28 11:44:53,738:INFO:Starting cross validation
2024-12-28 11:44:53,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:53,784:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,785:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,787:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,790:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,790:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,791:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,791:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:53,798:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:55,707:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:55,718:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:44:55,724:INFO:Calculating mean and std
2024-12-28 11:44:55,726:INFO:Creating metrics dataframe
2024-12-28 11:44:55,730:INFO:Uploading results into container
2024-12-28 11:44:55,731:INFO:Uploading model into container now
2024-12-28 11:44:55,731:INFO:_master_model_container: 16
2024-12-28 11:44:55,731:INFO:_display_container: 2
2024-12-28 11:44:55,732:INFO:DummyClassifier(constant=None, random_state=5449, strategy='prior')
2024-12-28 11:44:55,732:INFO:create_model() successfully completed......................................
2024-12-28 11:44:55,892:INFO:SubProcess create_model() end ==================================
2024-12-28 11:44:55,892:INFO:Creating metrics dataframe
2024-12-28 11:44:55,908:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-28 11:44:55,918:INFO:Initializing create_model()
2024-12-28 11:44:55,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:55,918:INFO:Checking exceptions
2024-12-28 11:44:55,920:INFO:Importing libraries
2024-12-28 11:44:55,920:INFO:Copying training dataset
2024-12-28 11:44:55,924:INFO:Defining folds
2024-12-28 11:44:55,924:INFO:Declaring metric variables
2024-12-28 11:44:55,924:INFO:Importing untrained model
2024-12-28 11:44:55,924:INFO:Declaring custom model
2024-12-28 11:44:55,925:INFO:Gradient Boosting Classifier Imported successfully
2024-12-28 11:44:55,926:INFO:Cross validation set to False
2024-12-28 11:44:55,926:INFO:Fitting Model
2024-12-28 11:44:56,053:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:44:56,055:INFO:create_model() successfully completed......................................
2024-12-28 11:44:56,235:INFO:_master_model_container: 16
2024-12-28 11:44:56,235:INFO:_display_container: 2
2024-12-28 11:44:56,237:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:44:56,237:INFO:compare_models() successfully completed......................................
2024-12-28 11:44:56,238:INFO:Initializing create_model()
2024-12-28 11:44:56,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:44:56,238:INFO:Checking exceptions
2024-12-28 11:44:56,257:INFO:Importing libraries
2024-12-28 11:44:56,257:INFO:Copying training dataset
2024-12-28 11:44:56,265:INFO:Defining folds
2024-12-28 11:44:56,265:INFO:Declaring metric variables
2024-12-28 11:44:56,269:INFO:Importing untrained model
2024-12-28 11:44:56,269:INFO:Declaring custom model
2024-12-28 11:44:56,275:INFO:Gradient Boosting Classifier Imported successfully
2024-12-28 11:44:56,284:INFO:Starting cross validation
2024-12-28 11:44:56,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:44:56,578:INFO:Calculating mean and std
2024-12-28 11:44:56,579:INFO:Creating metrics dataframe
2024-12-28 11:44:56,583:INFO:Finalizing model
2024-12-28 11:44:56,706:INFO:Uploading results into container
2024-12-28 11:44:56,706:INFO:Uploading model into container now
2024-12-28 11:44:56,716:INFO:_master_model_container: 17
2024-12-28 11:44:56,716:INFO:_display_container: 3
2024-12-28 11:44:56,718:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:44:56,718:INFO:create_model() successfully completed......................................
2024-12-28 11:44:56,884:INFO:Initializing tune_model()
2024-12-28 11:44:56,884:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>)
2024-12-28 11:44:56,884:INFO:Checking exceptions
2024-12-28 11:44:56,901:INFO:Copying training dataset
2024-12-28 11:44:56,906:INFO:Checking base model
2024-12-28 11:44:56,906:INFO:Base model : Gradient Boosting Classifier
2024-12-28 11:44:56,911:INFO:Declaring metric variables
2024-12-28 11:44:56,915:INFO:Defining Hyperparameters
2024-12-28 11:44:57,076:INFO:Tuning with n_jobs=-1
2024-12-28 11:44:57,076:INFO:Initializing RandomizedSearchCV
2024-12-28 11:45:01,194:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-12-28 11:45:01,194:INFO:Hyperparameter search completed
2024-12-28 11:45:01,194:INFO:SubProcess create_model() called ==================================
2024-12-28 11:45:01,195:INFO:Initializing create_model()
2024-12-28 11:45:01,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCD06D1E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'n_estimators': 300, 'min_samples_split': 9, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.15})
2024-12-28 11:45:01,195:INFO:Checking exceptions
2024-12-28 11:45:01,195:INFO:Importing libraries
2024-12-28 11:45:01,195:INFO:Copying training dataset
2024-12-28 11:45:01,199:INFO:Defining folds
2024-12-28 11:45:01,199:INFO:Declaring metric variables
2024-12-28 11:45:01,202:INFO:Importing untrained model
2024-12-28 11:45:01,202:INFO:Declaring custom model
2024-12-28 11:45:01,205:INFO:Gradient Boosting Classifier Imported successfully
2024-12-28 11:45:01,211:INFO:Starting cross validation
2024-12-28 11:45:01,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:45:01,676:INFO:Calculating mean and std
2024-12-28 11:45:01,679:INFO:Creating metrics dataframe
2024-12-28 11:45:01,683:INFO:Finalizing model
2024-12-28 11:45:01,874:INFO:Uploading results into container
2024-12-28 11:45:01,876:INFO:Uploading model into container now
2024-12-28 11:45:01,876:INFO:_master_model_container: 18
2024-12-28 11:45:01,877:INFO:_display_container: 4
2024-12-28 11:45:01,877:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=300, n_iter_no_change=None,
                           random_state=5449, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:45:01,878:INFO:create_model() successfully completed......................................
2024-12-28 11:45:02,016:INFO:SubProcess create_model() end ==================================
2024-12-28 11:45:02,017:INFO:choose_better activated
2024-12-28 11:45:02,019:INFO:SubProcess create_model() called ==================================
2024-12-28 11:45:02,020:INFO:Initializing create_model()
2024-12-28 11:45:02,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:45:02,020:INFO:Checking exceptions
2024-12-28 11:45:02,021:INFO:Importing libraries
2024-12-28 11:45:02,021:INFO:Copying training dataset
2024-12-28 11:45:02,025:INFO:Defining folds
2024-12-28 11:45:02,026:INFO:Declaring metric variables
2024-12-28 11:45:02,026:INFO:Importing untrained model
2024-12-28 11:45:02,026:INFO:Declaring custom model
2024-12-28 11:45:02,026:INFO:Gradient Boosting Classifier Imported successfully
2024-12-28 11:45:02,027:INFO:Starting cross validation
2024-12-28 11:45:02,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:45:02,251:INFO:Calculating mean and std
2024-12-28 11:45:02,252:INFO:Creating metrics dataframe
2024-12-28 11:45:02,254:INFO:Finalizing model
2024-12-28 11:45:02,350:INFO:Uploading results into container
2024-12-28 11:45:02,351:INFO:Uploading model into container now
2024-12-28 11:45:02,351:INFO:_master_model_container: 19
2024-12-28 11:45:02,351:INFO:_display_container: 5
2024-12-28 11:45:02,352:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:45:02,352:INFO:create_model() successfully completed......................................
2024-12-28 11:45:02,488:INFO:SubProcess create_model() end ==================================
2024-12-28 11:45:02,489:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8186
2024-12-28 11:45:02,489:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=300, n_iter_no_change=None,
                           random_state=5449, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.817
2024-12-28 11:45:02,490:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-12-28 11:45:02,490:INFO:choose_better completed
2024-12-28 11:45:02,490:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-28 11:45:02,499:INFO:_master_model_container: 19
2024-12-28 11:45:02,499:INFO:_display_container: 4
2024-12-28 11:45:02,500:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:45:02,500:INFO:tune_model() successfully completed......................................
2024-12-28 11:46:15,458:INFO:Initializing evaluate_model()
2024-12-28 11:46:15,458:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-12-28 11:46:15,472:INFO:Initializing plot_model()
2024-12-28 11:46:15,472:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:15,472:INFO:Checking exceptions
2024-12-28 11:46:15,475:INFO:Preloading libraries
2024-12-28 11:46:15,485:INFO:Copying training dataset
2024-12-28 11:46:15,485:INFO:Plot type: pipeline
2024-12-28 11:46:15,637:INFO:Visual Rendered Successfully
2024-12-28 11:46:15,773:INFO:plot_model() successfully completed......................................
2024-12-28 11:46:23,567:INFO:Initializing plot_model()
2024-12-28 11:46:23,567:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:23,567:INFO:Checking exceptions
2024-12-28 11:46:23,569:INFO:Preloading libraries
2024-12-28 11:46:23,576:INFO:Copying training dataset
2024-12-28 11:46:23,576:INFO:Plot type: pr
2024-12-28 11:46:23,631:INFO:Fitting Model
2024-12-28 11:46:23,633:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-12-28 11:46:23,633:INFO:Scoring test/hold-out set
2024-12-28 11:46:23,759:INFO:Visual Rendered Successfully
2024-12-28 11:46:23,891:INFO:plot_model() successfully completed......................................
2024-12-28 11:46:26,538:INFO:Initializing plot_model()
2024-12-28 11:46:26,538:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:26,538:INFO:Checking exceptions
2024-12-28 11:46:26,541:INFO:Preloading libraries
2024-12-28 11:46:26,548:INFO:Copying training dataset
2024-12-28 11:46:26,548:INFO:Plot type: manifold
2024-12-28 11:46:26,649:INFO:Fitting & Transforming Model
2024-12-28 11:46:28,048:INFO:Visual Rendered Successfully
2024-12-28 11:46:28,183:INFO:plot_model() successfully completed......................................
2024-12-28 11:46:28,228:INFO:Initializing plot_model()
2024-12-28 11:46:28,228:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:28,229:INFO:Checking exceptions
2024-12-28 11:46:28,232:INFO:Preloading libraries
2024-12-28 11:46:28,239:INFO:Copying training dataset
2024-12-28 11:46:28,239:INFO:Plot type: lift
2024-12-28 11:46:28,239:INFO:Generating predictions / predict_proba on X_test
2024-12-28 11:46:28,409:INFO:Visual Rendered Successfully
2024-12-28 11:46:28,545:INFO:plot_model() successfully completed......................................
2024-12-28 11:46:28,552:INFO:Initializing plot_model()
2024-12-28 11:46:28,553:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:28,553:INFO:Checking exceptions
2024-12-28 11:46:28,554:INFO:Preloading libraries
2024-12-28 11:46:28,561:INFO:Copying training dataset
2024-12-28 11:46:28,561:INFO:Plot type: dimension
2024-12-28 11:46:28,573:INFO:Fitting StandardScaler()
2024-12-28 11:46:28,585:INFO:Fitting PCA()
2024-12-28 11:46:28,642:INFO:Fitting & Transforming Model
2024-12-28 11:46:28,757:INFO:Visual Rendered Successfully
2024-12-28 11:46:28,896:INFO:plot_model() successfully completed......................................
2024-12-28 11:46:29,254:INFO:Initializing plot_model()
2024-12-28 11:46:29,254:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:29,254:INFO:Checking exceptions
2024-12-28 11:46:29,257:INFO:Preloading libraries
2024-12-28 11:46:29,263:INFO:Copying training dataset
2024-12-28 11:46:29,264:INFO:Plot type: lift
2024-12-28 11:46:29,264:INFO:Generating predictions / predict_proba on X_test
2024-12-28 11:46:29,404:INFO:Visual Rendered Successfully
2024-12-28 11:46:29,533:INFO:plot_model() successfully completed......................................
2024-12-28 11:46:33,194:INFO:Initializing plot_model()
2024-12-28 11:46:33,194:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5449, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCD156920>, system=True)
2024-12-28 11:46:33,195:INFO:Checking exceptions
2024-12-28 11:49:29,300:INFO:PyCaret ClassificationExperiment
2024-12-28 11:49:29,300:INFO:Logging name: clf-default-name
2024-12-28 11:49:29,300:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-28 11:49:29,300:INFO:version 3.3.1
2024-12-28 11:49:29,300:INFO:Initializing setup()
2024-12-28 11:49:29,300:INFO:self.USI: c09e
2024-12-28 11:49:29,300:INFO:self._variable_keys: {'fix_imbalance', 'gpu_n_jobs_param', 'y', 'data', 'log_plots_param', 'USI', '_available_plots', 'pipeline', 'idx', 'X_test', 'html_param', '_ml_usecase', 'X', 'n_jobs_param', 'target_param', 'fold_generator', 'memory', 'is_multiclass', 'exp_id', 'logging_param', 'exp_name_log', 'fold_groups_param', 'y_test', 'X_train', 'seed', 'gpu_param', 'y_train', 'fold_shuffle_param'}
2024-12-28 11:49:29,300:INFO:Checking environment
2024-12-28 11:49:29,300:INFO:python_version: 3.10.15
2024-12-28 11:49:29,300:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-28 11:49:29,300:INFO:machine: AMD64
2024-12-28 11:49:29,300:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-28 11:49:29,300:INFO:Memory: svmem(total=16312721408, available=4391342080, percent=73.1, used=11921379328, free=4391342080)
2024-12-28 11:49:29,301:INFO:Physical Core: 6
2024-12-28 11:49:29,301:INFO:Logical Core: 12
2024-12-28 11:49:29,301:INFO:Checking libraries
2024-12-28 11:49:29,301:INFO:System:
2024-12-28 11:49:29,301:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-28 11:49:29,301:INFO:executable: d:\Anaconda\python.exe
2024-12-28 11:49:29,301:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-28 11:49:29,301:INFO:PyCaret required dependencies:
2024-12-28 11:49:29,301:INFO:                 pip: 24.2
2024-12-28 11:49:29,301:INFO:          setuptools: 75.1.0
2024-12-28 11:49:29,301:INFO:             pycaret: 3.3.1
2024-12-28 11:49:29,301:INFO:             IPython: 8.27.0
2024-12-28 11:49:29,301:INFO:          ipywidgets: 8.1.2
2024-12-28 11:49:29,301:INFO:                tqdm: 4.66.5
2024-12-28 11:49:29,301:INFO:               numpy: 1.26.4
2024-12-28 11:49:29,301:INFO:              pandas: 2.1.4
2024-12-28 11:49:29,301:INFO:              jinja2: 3.1.4
2024-12-28 11:49:29,301:INFO:               scipy: 1.11.4
2024-12-28 11:49:29,301:INFO:              joblib: 1.2.0
2024-12-28 11:49:29,301:INFO:             sklearn: 1.4.2
2024-12-28 11:49:29,301:INFO:                pyod: 2.0.2
2024-12-28 11:49:29,301:INFO:            imblearn: 0.12.3
2024-12-28 11:49:29,302:INFO:   category_encoders: 2.6.3
2024-12-28 11:49:29,302:INFO:            lightgbm: 4.5.0
2024-12-28 11:49:29,302:INFO:               numba: 0.60.0
2024-12-28 11:49:29,302:INFO:            requests: 2.32.3
2024-12-28 11:49:29,302:INFO:          matplotlib: 3.9.2
2024-12-28 11:49:29,302:INFO:          scikitplot: 0.3.7
2024-12-28 11:49:29,302:INFO:         yellowbrick: 1.5
2024-12-28 11:49:29,302:INFO:              plotly: 5.24.1
2024-12-28 11:49:29,302:INFO:    plotly-resampler: Not installed
2024-12-28 11:49:29,302:INFO:             kaleido: 0.2.1
2024-12-28 11:49:29,302:INFO:           schemdraw: 0.15
2024-12-28 11:49:29,302:INFO:         statsmodels: 0.14.2
2024-12-28 11:49:29,302:INFO:              sktime: 0.26.0
2024-12-28 11:49:29,302:INFO:               tbats: 1.1.3
2024-12-28 11:49:29,302:INFO:            pmdarima: 2.0.4
2024-12-28 11:49:29,303:INFO:              psutil: 5.9.0
2024-12-28 11:49:29,303:INFO:          markupsafe: 2.1.3
2024-12-28 11:49:29,303:INFO:             pickle5: Not installed
2024-12-28 11:49:29,303:INFO:         cloudpickle: 3.0.0
2024-12-28 11:49:29,303:INFO:         deprecation: 2.1.0
2024-12-28 11:49:29,303:INFO:              xxhash: 2.0.2
2024-12-28 11:49:29,303:INFO:           wurlitzer: 3.1.1
2024-12-28 11:49:29,303:INFO:PyCaret optional dependencies:
2024-12-28 11:49:29,303:INFO:                shap: Not installed
2024-12-28 11:49:29,303:INFO:           interpret: Not installed
2024-12-28 11:49:29,303:INFO:                umap: 0.5.3
2024-12-28 11:49:29,303:INFO:     ydata_profiling: Not installed
2024-12-28 11:49:29,303:INFO:  explainerdashboard: Not installed
2024-12-28 11:49:29,303:INFO:             autoviz: Not installed
2024-12-28 11:49:29,303:INFO:           fairlearn: Not installed
2024-12-28 11:49:29,303:INFO:          deepchecks: Not installed
2024-12-28 11:49:29,303:INFO:             xgboost: 2.1.2
2024-12-28 11:49:29,303:INFO:            catboost: 1.2.3
2024-12-28 11:49:29,303:INFO:              kmodes: 0.12.2
2024-12-28 11:49:29,303:INFO:             mlxtend: 0.23.1
2024-12-28 11:49:29,303:INFO:       statsforecast: Not installed
2024-12-28 11:49:29,303:INFO:        tune_sklearn: Not installed
2024-12-28 11:49:29,304:INFO:                 ray: Not installed
2024-12-28 11:49:29,304:INFO:            hyperopt: Not installed
2024-12-28 11:49:29,304:INFO:              optuna: Not installed
2024-12-28 11:49:29,304:INFO:               skopt: Not installed
2024-12-28 11:49:29,304:INFO:              mlflow: 2.16.2
2024-12-28 11:49:29,304:INFO:              gradio: Not installed
2024-12-28 11:49:29,304:INFO:             fastapi: Not installed
2024-12-28 11:49:29,304:INFO:             uvicorn: Not installed
2024-12-28 11:49:29,304:INFO:              m2cgen: Not installed
2024-12-28 11:49:29,304:INFO:           evidently: Not installed
2024-12-28 11:49:29,304:INFO:               fugue: Not installed
2024-12-28 11:49:29,304:INFO:           streamlit: Not installed
2024-12-28 11:49:29,304:INFO:             prophet: Not installed
2024-12-28 11:49:29,304:INFO:None
2024-12-28 11:49:29,304:INFO:Set up data.
2024-12-28 11:49:29,308:INFO:Set up folding strategy.
2024-12-28 11:49:29,308:INFO:Set up train/test split.
2024-12-28 11:49:29,311:INFO:Set up index.
2024-12-28 11:49:29,311:INFO:Assigning column types.
2024-12-28 11:49:29,314:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-28 11:49:29,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-28 11:49:29,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:49:29,382:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,384:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-28 11:49:29,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:49:29,451:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,454:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,454:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-28 11:49:29,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:49:29,523:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,525:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,563:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-28 11:49:29,585:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,587:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,588:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-28 11:49:29,642:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,645:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,701:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,703:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,704:INFO:Preparing preprocessing pipeline...
2024-12-28 11:49:29,705:INFO:Set up simple imputation.
2024-12-28 11:49:29,720:INFO:Finished creating preprocessing pipeline.
2024-12-28 11:49:29,722:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-28 11:49:29,722:INFO:Creating final display dataframe.
2024-12-28 11:49:29,770:INFO:Setup _display_container:                     Description             Value
0                    Session id              3910
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 7)
4        Transformed data shape          (891, 7)
5   Transformed train set shape          (623, 7)
6    Transformed test set shape          (268, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c09e
2024-12-28 11:49:29,833:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,836:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,895:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-28 11:49:29,897:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-28 11:49:29,898:INFO:setup() successfully completed in 0.6s...............
2024-12-28 11:49:29,899:INFO:Initializing compare_models()
2024-12-28 11:49:29,899:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-28 11:49:29,899:INFO:Checking exceptions
2024-12-28 11:49:29,901:INFO:Preparing display monitor
2024-12-28 11:49:29,922:INFO:Initializing Logistic Regression
2024-12-28 11:49:29,922:INFO:Total runtime is 0.0 minutes
2024-12-28 11:49:29,925:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:29,925:INFO:Initializing create_model()
2024-12-28 11:49:29,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:29,927:INFO:Checking exceptions
2024-12-28 11:49:29,927:INFO:Importing libraries
2024-12-28 11:49:29,927:INFO:Copying training dataset
2024-12-28 11:49:29,931:INFO:Defining folds
2024-12-28 11:49:29,931:INFO:Declaring metric variables
2024-12-28 11:49:29,935:INFO:Importing untrained model
2024-12-28 11:49:29,938:INFO:Logistic Regression Imported successfully
2024-12-28 11:49:29,945:INFO:Starting cross validation
2024-12-28 11:49:29,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:30,049:INFO:Calculating mean and std
2024-12-28 11:49:30,050:INFO:Creating metrics dataframe
2024-12-28 11:49:30,052:INFO:Uploading results into container
2024-12-28 11:49:30,052:INFO:Uploading model into container now
2024-12-28 11:49:30,052:INFO:_master_model_container: 1
2024-12-28 11:49:30,052:INFO:_display_container: 2
2024-12-28 11:49:30,052:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3910, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-28 11:49:30,054:INFO:create_model() successfully completed......................................
2024-12-28 11:49:30,214:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:30,214:INFO:Creating metrics dataframe
2024-12-28 11:49:30,220:INFO:Initializing K Neighbors Classifier
2024-12-28 11:49:30,220:INFO:Total runtime is 0.00495604674021403 minutes
2024-12-28 11:49:30,222:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:30,223:INFO:Initializing create_model()
2024-12-28 11:49:30,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:30,223:INFO:Checking exceptions
2024-12-28 11:49:30,223:INFO:Importing libraries
2024-12-28 11:49:30,223:INFO:Copying training dataset
2024-12-28 11:49:30,226:INFO:Defining folds
2024-12-28 11:49:30,227:INFO:Declaring metric variables
2024-12-28 11:49:30,229:INFO:Importing untrained model
2024-12-28 11:49:30,232:INFO:K Neighbors Classifier Imported successfully
2024-12-28 11:49:30,239:INFO:Starting cross validation
2024-12-28 11:49:30,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:30,404:INFO:Calculating mean and std
2024-12-28 11:49:30,405:INFO:Creating metrics dataframe
2024-12-28 11:49:30,406:INFO:Uploading results into container
2024-12-28 11:49:30,406:INFO:Uploading model into container now
2024-12-28 11:49:30,406:INFO:_master_model_container: 2
2024-12-28 11:49:30,406:INFO:_display_container: 2
2024-12-28 11:49:30,408:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-28 11:49:30,408:INFO:create_model() successfully completed......................................
2024-12-28 11:49:30,563:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:30,563:INFO:Creating metrics dataframe
2024-12-28 11:49:30,569:INFO:Initializing Naive Bayes
2024-12-28 11:49:30,570:INFO:Total runtime is 0.010790661970774332 minutes
2024-12-28 11:49:30,572:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:30,573:INFO:Initializing create_model()
2024-12-28 11:49:30,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:30,573:INFO:Checking exceptions
2024-12-28 11:49:30,573:INFO:Importing libraries
2024-12-28 11:49:30,573:INFO:Copying training dataset
2024-12-28 11:49:30,576:INFO:Defining folds
2024-12-28 11:49:30,576:INFO:Declaring metric variables
2024-12-28 11:49:30,580:INFO:Importing untrained model
2024-12-28 11:49:30,583:INFO:Naive Bayes Imported successfully
2024-12-28 11:49:30,591:INFO:Starting cross validation
2024-12-28 11:49:30,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:30,647:INFO:Calculating mean and std
2024-12-28 11:49:30,647:INFO:Creating metrics dataframe
2024-12-28 11:49:30,649:INFO:Uploading results into container
2024-12-28 11:49:30,650:INFO:Uploading model into container now
2024-12-28 11:49:30,650:INFO:_master_model_container: 3
2024-12-28 11:49:30,650:INFO:_display_container: 2
2024-12-28 11:49:30,650:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-28 11:49:30,650:INFO:create_model() successfully completed......................................
2024-12-28 11:49:30,795:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:30,796:INFO:Creating metrics dataframe
2024-12-28 11:49:30,802:INFO:Initializing Decision Tree Classifier
2024-12-28 11:49:30,802:INFO:Total runtime is 0.014660330613454182 minutes
2024-12-28 11:49:30,805:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:30,805:INFO:Initializing create_model()
2024-12-28 11:49:30,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:30,805:INFO:Checking exceptions
2024-12-28 11:49:30,805:INFO:Importing libraries
2024-12-28 11:49:30,805:INFO:Copying training dataset
2024-12-28 11:49:30,809:INFO:Defining folds
2024-12-28 11:49:30,809:INFO:Declaring metric variables
2024-12-28 11:49:30,811:INFO:Importing untrained model
2024-12-28 11:49:30,814:INFO:Decision Tree Classifier Imported successfully
2024-12-28 11:49:30,819:INFO:Starting cross validation
2024-12-28 11:49:30,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:30,873:INFO:Calculating mean and std
2024-12-28 11:49:30,874:INFO:Creating metrics dataframe
2024-12-28 11:49:30,875:INFO:Uploading results into container
2024-12-28 11:49:30,875:INFO:Uploading model into container now
2024-12-28 11:49:30,876:INFO:_master_model_container: 4
2024-12-28 11:49:30,876:INFO:_display_container: 2
2024-12-28 11:49:30,876:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3910, splitter='best')
2024-12-28 11:49:30,876:INFO:create_model() successfully completed......................................
2024-12-28 11:49:31,020:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:31,020:INFO:Creating metrics dataframe
2024-12-28 11:49:31,028:INFO:Initializing SVM - Linear Kernel
2024-12-28 11:49:31,028:INFO:Total runtime is 0.018423108259836833 minutes
2024-12-28 11:49:31,032:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:31,032:INFO:Initializing create_model()
2024-12-28 11:49:31,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:31,032:INFO:Checking exceptions
2024-12-28 11:49:31,033:INFO:Importing libraries
2024-12-28 11:49:31,033:INFO:Copying training dataset
2024-12-28 11:49:31,036:INFO:Defining folds
2024-12-28 11:49:31,036:INFO:Declaring metric variables
2024-12-28 11:49:31,038:INFO:Importing untrained model
2024-12-28 11:49:31,043:INFO:SVM - Linear Kernel Imported successfully
2024-12-28 11:49:31,051:INFO:Starting cross validation
2024-12-28 11:49:31,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:31,098:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:31,108:INFO:Calculating mean and std
2024-12-28 11:49:31,108:INFO:Creating metrics dataframe
2024-12-28 11:49:31,110:INFO:Uploading results into container
2024-12-28 11:49:31,110:INFO:Uploading model into container now
2024-12-28 11:49:31,111:INFO:_master_model_container: 5
2024-12-28 11:49:31,111:INFO:_display_container: 2
2024-12-28 11:49:31,111:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3910, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-28 11:49:31,111:INFO:create_model() successfully completed......................................
2024-12-28 11:49:31,258:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:31,258:INFO:Creating metrics dataframe
2024-12-28 11:49:31,264:INFO:Initializing Ridge Classifier
2024-12-28 11:49:31,264:INFO:Total runtime is 0.0223586638768514 minutes
2024-12-28 11:49:31,266:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:31,268:INFO:Initializing create_model()
2024-12-28 11:49:31,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:31,268:INFO:Checking exceptions
2024-12-28 11:49:31,268:INFO:Importing libraries
2024-12-28 11:49:31,268:INFO:Copying training dataset
2024-12-28 11:49:31,272:INFO:Defining folds
2024-12-28 11:49:31,272:INFO:Declaring metric variables
2024-12-28 11:49:31,275:INFO:Importing untrained model
2024-12-28 11:49:31,279:INFO:Ridge Classifier Imported successfully
2024-12-28 11:49:31,285:INFO:Starting cross validation
2024-12-28 11:49:31,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:31,344:INFO:Calculating mean and std
2024-12-28 11:49:31,346:INFO:Creating metrics dataframe
2024-12-28 11:49:31,347:INFO:Uploading results into container
2024-12-28 11:49:31,348:INFO:Uploading model into container now
2024-12-28 11:49:31,348:INFO:_master_model_container: 6
2024-12-28 11:49:31,348:INFO:_display_container: 2
2024-12-28 11:49:31,348:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3910, solver='auto',
                tol=0.0001)
2024-12-28 11:49:31,348:INFO:create_model() successfully completed......................................
2024-12-28 11:49:31,496:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:31,496:INFO:Creating metrics dataframe
2024-12-28 11:49:31,504:INFO:Initializing Random Forest Classifier
2024-12-28 11:49:31,504:INFO:Total runtime is 0.026355870564778647 minutes
2024-12-28 11:49:31,508:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:31,508:INFO:Initializing create_model()
2024-12-28 11:49:31,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:31,508:INFO:Checking exceptions
2024-12-28 11:49:31,508:INFO:Importing libraries
2024-12-28 11:49:31,508:INFO:Copying training dataset
2024-12-28 11:49:31,511:INFO:Defining folds
2024-12-28 11:49:31,511:INFO:Declaring metric variables
2024-12-28 11:49:31,514:INFO:Importing untrained model
2024-12-28 11:49:31,518:INFO:Random Forest Classifier Imported successfully
2024-12-28 11:49:31,525:INFO:Starting cross validation
2024-12-28 11:49:31,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:32,001:INFO:Calculating mean and std
2024-12-28 11:49:32,003:INFO:Creating metrics dataframe
2024-12-28 11:49:32,004:INFO:Uploading results into container
2024-12-28 11:49:32,005:INFO:Uploading model into container now
2024-12-28 11:49:32,005:INFO:_master_model_container: 7
2024-12-28 11:49:32,005:INFO:_display_container: 2
2024-12-28 11:49:32,007:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3910, verbose=0,
                       warm_start=False)
2024-12-28 11:49:32,007:INFO:create_model() successfully completed......................................
2024-12-28 11:49:32,151:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:32,151:INFO:Creating metrics dataframe
2024-12-28 11:49:32,158:INFO:Initializing Quadratic Discriminant Analysis
2024-12-28 11:49:32,158:INFO:Total runtime is 0.037253812948862715 minutes
2024-12-28 11:49:32,161:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:32,161:INFO:Initializing create_model()
2024-12-28 11:49:32,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:32,161:INFO:Checking exceptions
2024-12-28 11:49:32,162:INFO:Importing libraries
2024-12-28 11:49:32,162:INFO:Copying training dataset
2024-12-28 11:49:32,166:INFO:Defining folds
2024-12-28 11:49:32,166:INFO:Declaring metric variables
2024-12-28 11:49:32,168:INFO:Importing untrained model
2024-12-28 11:49:32,172:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-28 11:49:32,176:INFO:Starting cross validation
2024-12-28 11:49:32,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:32,233:INFO:Calculating mean and std
2024-12-28 11:49:32,233:INFO:Creating metrics dataframe
2024-12-28 11:49:32,235:INFO:Uploading results into container
2024-12-28 11:49:32,235:INFO:Uploading model into container now
2024-12-28 11:49:32,235:INFO:_master_model_container: 8
2024-12-28 11:49:32,235:INFO:_display_container: 2
2024-12-28 11:49:32,235:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-28 11:49:32,235:INFO:create_model() successfully completed......................................
2024-12-28 11:49:32,381:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:32,381:INFO:Creating metrics dataframe
2024-12-28 11:49:32,389:INFO:Initializing Ada Boost Classifier
2024-12-28 11:49:32,389:INFO:Total runtime is 0.0411104162534078 minutes
2024-12-28 11:49:32,391:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:32,392:INFO:Initializing create_model()
2024-12-28 11:49:32,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:32,392:INFO:Checking exceptions
2024-12-28 11:49:32,392:INFO:Importing libraries
2024-12-28 11:49:32,392:INFO:Copying training dataset
2024-12-28 11:49:32,396:INFO:Defining folds
2024-12-28 11:49:32,396:INFO:Declaring metric variables
2024-12-28 11:49:32,399:INFO:Importing untrained model
2024-12-28 11:49:32,402:INFO:Ada Boost Classifier Imported successfully
2024-12-28 11:49:32,408:INFO:Starting cross validation
2024-12-28 11:49:32,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:32,428:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,428:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,429:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,430:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,432:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,433:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,434:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,436:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,436:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,439:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-28 11:49:32,575:INFO:Calculating mean and std
2024-12-28 11:49:32,576:INFO:Creating metrics dataframe
2024-12-28 11:49:32,578:INFO:Uploading results into container
2024-12-28 11:49:32,578:INFO:Uploading model into container now
2024-12-28 11:49:32,580:INFO:_master_model_container: 9
2024-12-28 11:49:32,580:INFO:_display_container: 2
2024-12-28 11:49:32,580:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3910)
2024-12-28 11:49:32,580:INFO:create_model() successfully completed......................................
2024-12-28 11:49:32,724:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:32,725:INFO:Creating metrics dataframe
2024-12-28 11:49:32,733:INFO:Initializing Gradient Boosting Classifier
2024-12-28 11:49:32,733:INFO:Total runtime is 0.0468408465385437 minutes
2024-12-28 11:49:32,736:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:32,736:INFO:Initializing create_model()
2024-12-28 11:49:32,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:32,737:INFO:Checking exceptions
2024-12-28 11:49:32,737:INFO:Importing libraries
2024-12-28 11:49:32,737:INFO:Copying training dataset
2024-12-28 11:49:32,740:INFO:Defining folds
2024-12-28 11:49:32,740:INFO:Declaring metric variables
2024-12-28 11:49:32,744:INFO:Importing untrained model
2024-12-28 11:49:32,747:INFO:Gradient Boosting Classifier Imported successfully
2024-12-28 11:49:32,754:INFO:Starting cross validation
2024-12-28 11:49:32,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:32,935:INFO:Calculating mean and std
2024-12-28 11:49:32,936:INFO:Creating metrics dataframe
2024-12-28 11:49:32,938:INFO:Uploading results into container
2024-12-28 11:49:32,939:INFO:Uploading model into container now
2024-12-28 11:49:32,939:INFO:_master_model_container: 10
2024-12-28 11:49:32,939:INFO:_display_container: 2
2024-12-28 11:49:32,939:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3910, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-28 11:49:32,941:INFO:create_model() successfully completed......................................
2024-12-28 11:49:33,084:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:33,084:INFO:Creating metrics dataframe
2024-12-28 11:49:33,091:INFO:Initializing Linear Discriminant Analysis
2024-12-28 11:49:33,092:INFO:Total runtime is 0.05282445351282755 minutes
2024-12-28 11:49:33,095:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:33,095:INFO:Initializing create_model()
2024-12-28 11:49:33,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:33,095:INFO:Checking exceptions
2024-12-28 11:49:33,096:INFO:Importing libraries
2024-12-28 11:49:33,096:INFO:Copying training dataset
2024-12-28 11:49:33,099:INFO:Defining folds
2024-12-28 11:49:33,099:INFO:Declaring metric variables
2024-12-28 11:49:33,102:INFO:Importing untrained model
2024-12-28 11:49:33,106:INFO:Linear Discriminant Analysis Imported successfully
2024-12-28 11:49:33,112:INFO:Starting cross validation
2024-12-28 11:49:33,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:33,174:INFO:Calculating mean and std
2024-12-28 11:49:33,174:INFO:Creating metrics dataframe
2024-12-28 11:49:33,177:INFO:Uploading results into container
2024-12-28 11:49:33,177:INFO:Uploading model into container now
2024-12-28 11:49:33,177:INFO:_master_model_container: 11
2024-12-28 11:49:33,178:INFO:_display_container: 2
2024-12-28 11:49:33,178:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-28 11:49:33,178:INFO:create_model() successfully completed......................................
2024-12-28 11:49:33,330:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:33,330:INFO:Creating metrics dataframe
2024-12-28 11:49:33,338:INFO:Initializing Extra Trees Classifier
2024-12-28 11:49:33,339:INFO:Total runtime is 0.05694434642791748 minutes
2024-12-28 11:49:33,342:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:33,342:INFO:Initializing create_model()
2024-12-28 11:49:33,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:33,342:INFO:Checking exceptions
2024-12-28 11:49:33,342:INFO:Importing libraries
2024-12-28 11:49:33,342:INFO:Copying training dataset
2024-12-28 11:49:33,346:INFO:Defining folds
2024-12-28 11:49:33,346:INFO:Declaring metric variables
2024-12-28 11:49:33,349:INFO:Importing untrained model
2024-12-28 11:49:33,352:INFO:Extra Trees Classifier Imported successfully
2024-12-28 11:49:33,358:INFO:Starting cross validation
2024-12-28 11:49:33,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:33,622:INFO:Calculating mean and std
2024-12-28 11:49:33,623:INFO:Creating metrics dataframe
2024-12-28 11:49:33,626:INFO:Uploading results into container
2024-12-28 11:49:33,626:INFO:Uploading model into container now
2024-12-28 11:49:33,626:INFO:_master_model_container: 12
2024-12-28 11:49:33,626:INFO:_display_container: 2
2024-12-28 11:49:33,628:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3910, verbose=0,
                     warm_start=False)
2024-12-28 11:49:33,628:INFO:create_model() successfully completed......................................
2024-12-28 11:49:33,769:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:33,769:INFO:Creating metrics dataframe
2024-12-28 11:49:33,777:INFO:Initializing Extreme Gradient Boosting
2024-12-28 11:49:33,778:INFO:Total runtime is 0.0642559250195821 minutes
2024-12-28 11:49:33,780:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:33,780:INFO:Initializing create_model()
2024-12-28 11:49:33,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:33,780:INFO:Checking exceptions
2024-12-28 11:49:33,781:INFO:Importing libraries
2024-12-28 11:49:33,781:INFO:Copying training dataset
2024-12-28 11:49:33,784:INFO:Defining folds
2024-12-28 11:49:33,784:INFO:Declaring metric variables
2024-12-28 11:49:33,788:INFO:Importing untrained model
2024-12-28 11:49:33,792:INFO:Extreme Gradient Boosting Imported successfully
2024-12-28 11:49:33,800:INFO:Starting cross validation
2024-12-28 11:49:33,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:38,434:INFO:Calculating mean and std
2024-12-28 11:49:38,435:INFO:Creating metrics dataframe
2024-12-28 11:49:38,438:INFO:Uploading results into container
2024-12-28 11:49:38,438:INFO:Uploading model into container now
2024-12-28 11:49:38,439:INFO:_master_model_container: 13
2024-12-28 11:49:38,439:INFO:_display_container: 2
2024-12-28 11:49:38,440:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-28 11:49:38,440:INFO:create_model() successfully completed......................................
2024-12-28 11:49:38,626:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:38,628:INFO:Creating metrics dataframe
2024-12-28 11:49:38,636:INFO:Initializing Light Gradient Boosting Machine
2024-12-28 11:49:38,638:INFO:Total runtime is 0.14525916179021198 minutes
2024-12-28 11:49:38,642:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:38,642:INFO:Initializing create_model()
2024-12-28 11:49:38,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:38,642:INFO:Checking exceptions
2024-12-28 11:49:38,643:INFO:Importing libraries
2024-12-28 11:49:38,643:INFO:Copying training dataset
2024-12-28 11:49:38,646:INFO:Defining folds
2024-12-28 11:49:38,646:INFO:Declaring metric variables
2024-12-28 11:49:38,650:INFO:Importing untrained model
2024-12-28 11:49:38,658:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-28 11:49:38,668:INFO:Starting cross validation
2024-12-28 11:49:38,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:44,421:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-28 11:49:47,238:INFO:Calculating mean and std
2024-12-28 11:49:47,239:INFO:Creating metrics dataframe
2024-12-28 11:49:47,241:INFO:Uploading results into container
2024-12-28 11:49:47,242:INFO:Uploading model into container now
2024-12-28 11:49:47,243:INFO:_master_model_container: 14
2024-12-28 11:49:47,243:INFO:_display_container: 2
2024-12-28 11:49:47,243:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3910, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-28 11:49:47,244:INFO:create_model() successfully completed......................................
2024-12-28 11:49:47,428:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:47,428:INFO:Creating metrics dataframe
2024-12-28 11:49:47,440:INFO:Initializing CatBoost Classifier
2024-12-28 11:49:47,440:INFO:Total runtime is 0.2919575850168864 minutes
2024-12-28 11:49:47,443:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:47,443:INFO:Initializing create_model()
2024-12-28 11:49:47,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:47,443:INFO:Checking exceptions
2024-12-28 11:49:47,443:INFO:Importing libraries
2024-12-28 11:49:47,444:INFO:Copying training dataset
2024-12-28 11:49:47,448:INFO:Defining folds
2024-12-28 11:49:47,448:INFO:Declaring metric variables
2024-12-28 11:49:47,451:INFO:Importing untrained model
2024-12-28 11:49:47,456:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:49:47,462:INFO:Starting cross validation
2024-12-28 11:49:47,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:52,065:INFO:Calculating mean and std
2024-12-28 11:49:52,066:INFO:Creating metrics dataframe
2024-12-28 11:49:52,069:INFO:Uploading results into container
2024-12-28 11:49:52,069:INFO:Uploading model into container now
2024-12-28 11:49:52,069:INFO:_master_model_container: 15
2024-12-28 11:49:52,069:INFO:_display_container: 2
2024-12-28 11:49:52,069:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FD01C9060>
2024-12-28 11:49:52,069:INFO:create_model() successfully completed......................................
2024-12-28 11:49:52,220:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:52,220:INFO:Creating metrics dataframe
2024-12-28 11:49:52,229:INFO:Initializing Dummy Classifier
2024-12-28 11:49:52,229:INFO:Total runtime is 0.3717817465464274 minutes
2024-12-28 11:49:52,231:INFO:SubProcess create_model() called ==================================
2024-12-28 11:49:52,233:INFO:Initializing create_model()
2024-12-28 11:49:52,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FD01CBAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:52,233:INFO:Checking exceptions
2024-12-28 11:49:52,233:INFO:Importing libraries
2024-12-28 11:49:52,233:INFO:Copying training dataset
2024-12-28 11:49:52,236:INFO:Defining folds
2024-12-28 11:49:52,236:INFO:Declaring metric variables
2024-12-28 11:49:52,240:INFO:Importing untrained model
2024-12-28 11:49:52,243:INFO:Dummy Classifier Imported successfully
2024-12-28 11:49:52,249:INFO:Starting cross validation
2024-12-28 11:49:52,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:52,288:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,288:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,291:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,292:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,296:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,296:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,296:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,296:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:52,302:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:53,794:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-28 11:49:53,798:INFO:Calculating mean and std
2024-12-28 11:49:53,799:INFO:Creating metrics dataframe
2024-12-28 11:49:53,801:INFO:Uploading results into container
2024-12-28 11:49:53,802:INFO:Uploading model into container now
2024-12-28 11:49:53,802:INFO:_master_model_container: 16
2024-12-28 11:49:53,802:INFO:_display_container: 2
2024-12-28 11:49:53,802:INFO:DummyClassifier(constant=None, random_state=3910, strategy='prior')
2024-12-28 11:49:53,802:INFO:create_model() successfully completed......................................
2024-12-28 11:49:53,950:INFO:SubProcess create_model() end ==================================
2024-12-28 11:49:53,950:INFO:Creating metrics dataframe
2024-12-28 11:49:53,960:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-28 11:49:53,968:INFO:Initializing create_model()
2024-12-28 11:49:53,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=<catboost.core.CatBoostClassifier object at 0x0000014FD01C9060>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:53,968:INFO:Checking exceptions
2024-12-28 11:49:53,970:INFO:Importing libraries
2024-12-28 11:49:53,970:INFO:Copying training dataset
2024-12-28 11:49:53,972:INFO:Defining folds
2024-12-28 11:49:53,973:INFO:Declaring metric variables
2024-12-28 11:49:53,973:INFO:Importing untrained model
2024-12-28 11:49:53,973:INFO:Declaring custom model
2024-12-28 11:49:53,973:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:49:53,973:INFO:Cross validation set to False
2024-12-28 11:49:53,973:INFO:Fitting Model
2024-12-28 11:49:55,276:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCF794A30>
2024-12-28 11:49:55,276:INFO:create_model() successfully completed......................................
2024-12-28 11:49:55,451:INFO:_master_model_container: 16
2024-12-28 11:49:55,451:INFO:_display_container: 2
2024-12-28 11:49:55,451:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCF794A30>
2024-12-28 11:49:55,451:INFO:compare_models() successfully completed......................................
2024-12-28 11:49:55,452:INFO:Initializing create_model()
2024-12-28 11:49:55,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=<catboost.core.CatBoostClassifier object at 0x0000014FCF794A30>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:49:55,452:INFO:Checking exceptions
2024-12-28 11:49:55,465:INFO:Importing libraries
2024-12-28 11:49:55,465:INFO:Copying training dataset
2024-12-28 11:49:55,470:INFO:Defining folds
2024-12-28 11:49:55,470:INFO:Declaring metric variables
2024-12-28 11:49:55,472:INFO:Importing untrained model
2024-12-28 11:49:55,472:INFO:Declaring custom model
2024-12-28 11:49:55,476:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:49:55,483:INFO:Starting cross validation
2024-12-28 11:49:55,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:49:58,960:INFO:Calculating mean and std
2024-12-28 11:49:58,961:INFO:Creating metrics dataframe
2024-12-28 11:49:58,965:INFO:Finalizing model
2024-12-28 11:50:00,186:INFO:Uploading results into container
2024-12-28 11:50:00,188:INFO:Uploading model into container now
2024-12-28 11:50:00,196:INFO:_master_model_container: 17
2024-12-28 11:50:00,196:INFO:_display_container: 3
2024-12-28 11:50:00,196:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCD919B40>
2024-12-28 11:50:00,196:INFO:create_model() successfully completed......................................
2024-12-28 11:50:00,355:INFO:Initializing tune_model()
2024-12-28 11:50:00,355:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000014FCD919B40>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>)
2024-12-28 11:50:00,355:INFO:Checking exceptions
2024-12-28 11:50:00,370:INFO:Copying training dataset
2024-12-28 11:50:00,373:INFO:Checking base model
2024-12-28 11:50:00,374:INFO:Base model : CatBoost Classifier
2024-12-28 11:50:00,378:INFO:Declaring metric variables
2024-12-28 11:50:00,381:INFO:Defining Hyperparameters
2024-12-28 11:50:00,551:INFO:Tuning with n_jobs=-1
2024-12-28 11:50:00,551:INFO:Initializing RandomizedSearchCV
2024-12-28 11:50:09,844:INFO:best_params: {'actual_estimator__random_strength': 0.7, 'actual_estimator__n_estimators': 160, 'actual_estimator__l2_leaf_reg': 30, 'actual_estimator__eta': 0.2, 'actual_estimator__depth': 6}
2024-12-28 11:50:09,845:INFO:Hyperparameter search completed
2024-12-28 11:50:09,845:INFO:SubProcess create_model() called ==================================
2024-12-28 11:50:09,845:INFO:Initializing create_model()
2024-12-28 11:50:09,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=<catboost.core.CatBoostClassifier object at 0x0000014FCF6AB370>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014FCAE06F20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.7, 'n_estimators': 160, 'l2_leaf_reg': 30, 'eta': 0.2, 'depth': 6})
2024-12-28 11:50:09,846:INFO:Checking exceptions
2024-12-28 11:50:09,846:INFO:Importing libraries
2024-12-28 11:50:09,846:INFO:Copying training dataset
2024-12-28 11:50:09,850:INFO:Defining folds
2024-12-28 11:50:09,850:INFO:Declaring metric variables
2024-12-28 11:50:09,853:INFO:Importing untrained model
2024-12-28 11:50:09,855:INFO:Declaring custom model
2024-12-28 11:50:09,857:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:50:09,862:INFO:Starting cross validation
2024-12-28 11:50:09,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:50:10,332:INFO:Calculating mean and std
2024-12-28 11:50:10,333:INFO:Creating metrics dataframe
2024-12-28 11:50:10,337:INFO:Finalizing model
2024-12-28 11:50:10,487:INFO:Uploading results into container
2024-12-28 11:50:10,489:INFO:Uploading model into container now
2024-12-28 11:50:10,489:INFO:_master_model_container: 18
2024-12-28 11:50:10,489:INFO:_display_container: 4
2024-12-28 11:50:10,491:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FD01CA8C0>
2024-12-28 11:50:10,491:INFO:create_model() successfully completed......................................
2024-12-28 11:50:10,649:INFO:SubProcess create_model() end ==================================
2024-12-28 11:50:10,649:INFO:choose_better activated
2024-12-28 11:50:10,652:INFO:SubProcess create_model() called ==================================
2024-12-28 11:50:10,652:INFO:Initializing create_model()
2024-12-28 11:50:10,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=<catboost.core.CatBoostClassifier object at 0x0000014FCD919B40>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:50:10,653:INFO:Checking exceptions
2024-12-28 11:50:10,654:INFO:Importing libraries
2024-12-28 11:50:10,655:INFO:Copying training dataset
2024-12-28 11:50:10,657:INFO:Defining folds
2024-12-28 11:50:10,658:INFO:Declaring metric variables
2024-12-28 11:50:10,658:INFO:Importing untrained model
2024-12-28 11:50:10,658:INFO:Declaring custom model
2024-12-28 11:50:10,658:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:50:10,658:INFO:Starting cross validation
2024-12-28 11:50:10,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-28 11:50:13,308:INFO:Calculating mean and std
2024-12-28 11:50:13,309:INFO:Creating metrics dataframe
2024-12-28 11:50:13,311:INFO:Finalizing model
2024-12-28 11:50:14,516:INFO:Uploading results into container
2024-12-28 11:50:14,516:INFO:Uploading model into container now
2024-12-28 11:50:14,518:INFO:_master_model_container: 19
2024-12-28 11:50:14,518:INFO:_display_container: 5
2024-12-28 11:50:14,518:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0>
2024-12-28 11:50:14,518:INFO:create_model() successfully completed......................................
2024-12-28 11:50:14,662:INFO:SubProcess create_model() end ==================================
2024-12-28 11:50:14,663:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0> result for Accuracy is 0.8299
2024-12-28 11:50:14,663:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FD01CA8C0> result for Accuracy is 0.8283
2024-12-28 11:50:14,663:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0> is best model
2024-12-28 11:50:14,663:INFO:choose_better completed
2024-12-28 11:50:14,663:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-28 11:50:14,672:INFO:_master_model_container: 19
2024-12-28 11:50:14,672:INFO:_display_container: 4
2024-12-28 11:50:14,672:INFO:<catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0>
2024-12-28 11:50:14,672:INFO:tune_model() successfully completed......................................
2024-12-28 11:50:14,817:INFO:Initializing finalize_model()
2024-12-28 11:50:14,818:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=<catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-28 11:50:14,818:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0>
2024-12-28 11:50:14,820:INFO:Initializing create_model()
2024-12-28 11:50:14,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014FCF8D7D30>, estimator=<catboost.core.CatBoostClassifier object at 0x0000014FCF4F2CE0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-28 11:50:14,820:INFO:Checking exceptions
2024-12-28 11:50:14,822:INFO:Importing libraries
2024-12-28 11:50:14,822:INFO:Copying training dataset
2024-12-28 11:50:14,822:INFO:Defining folds
2024-12-28 11:50:14,822:INFO:Declaring metric variables
2024-12-28 11:50:14,822:INFO:Importing untrained model
2024-12-28 11:50:14,822:INFO:Declaring custom model
2024-12-28 11:50:14,823:INFO:CatBoost Classifier Imported successfully
2024-12-28 11:50:14,823:INFO:Cross validation set to False
2024-12-28 11:50:14,823:INFO:Fitting Model
2024-12-28 11:50:16,171:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000014FCD919930>)],
         verbose=False)
2024-12-28 11:50:16,171:INFO:create_model() successfully completed......................................
2024-12-28 11:50:16,314:INFO:_master_model_container: 19
2024-12-28 11:50:16,314:INFO:_display_container: 4
2024-12-28 11:50:16,316:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'SibSp', 'Parch',
                                             'Fare', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000014FCD919930>)],
         verbose=False)
2024-12-28 11:50:16,316:INFO:finalize_model() successfully completed......................................
2024-12-29 10:46:23,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 10:46:23,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 10:46:23,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 10:46:23,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 10:46:25,429:INFO:PyCaret ClassificationExperiment
2024-12-29 10:46:25,429:INFO:Logging name: clf-default-name
2024-12-29 10:46:25,430:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-29 10:46:25,430:INFO:version 3.3.1
2024-12-29 10:46:25,430:INFO:Initializing setup()
2024-12-29 10:46:25,430:INFO:self.USI: fba1
2024-12-29 10:46:25,430:INFO:self._variable_keys: {'USI', '_ml_usecase', 'y_train', 'X_train', 'X', 'is_multiclass', 'pipeline', 'X_test', 'fold_groups_param', 'data', 'fix_imbalance', 'idx', 'gpu_param', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', '_available_plots', 'y_test', 'log_plots_param', 'logging_param', 'memory', 'seed', 'fold_shuffle_param', 'y', 'html_param', 'target_param', 'n_jobs_param', 'exp_name_log'}
2024-12-29 10:46:25,430:INFO:Checking environment
2024-12-29 10:46:25,430:INFO:python_version: 3.10.15
2024-12-29 10:46:25,430:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-29 10:46:25,430:INFO:machine: AMD64
2024-12-29 10:46:25,430:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-29 10:46:25,430:INFO:Memory: svmem(total=16312721408, available=5789925376, percent=64.5, used=10522796032, free=5789925376)
2024-12-29 10:46:25,430:INFO:Physical Core: 6
2024-12-29 10:46:25,431:INFO:Logical Core: 12
2024-12-29 10:46:25,431:INFO:Checking libraries
2024-12-29 10:46:25,431:INFO:System:
2024-12-29 10:46:25,431:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-29 10:46:25,431:INFO:executable: d:\Anaconda\python.exe
2024-12-29 10:46:25,431:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-29 10:46:25,431:INFO:PyCaret required dependencies:
2024-12-29 10:46:25,536:INFO:                 pip: 24.2
2024-12-29 10:46:25,536:INFO:          setuptools: 75.1.0
2024-12-29 10:46:25,536:INFO:             pycaret: 3.3.1
2024-12-29 10:46:25,536:INFO:             IPython: 8.27.0
2024-12-29 10:46:25,536:INFO:          ipywidgets: 8.1.2
2024-12-29 10:46:25,536:INFO:                tqdm: 4.66.5
2024-12-29 10:46:25,536:INFO:               numpy: 1.26.4
2024-12-29 10:46:25,536:INFO:              pandas: 2.1.4
2024-12-29 10:46:25,536:INFO:              jinja2: 3.1.4
2024-12-29 10:46:25,536:INFO:               scipy: 1.11.4
2024-12-29 10:46:25,536:INFO:              joblib: 1.2.0
2024-12-29 10:46:25,536:INFO:             sklearn: 1.4.2
2024-12-29 10:46:25,536:INFO:                pyod: 2.0.2
2024-12-29 10:46:25,536:INFO:            imblearn: 0.12.3
2024-12-29 10:46:25,536:INFO:   category_encoders: 2.6.3
2024-12-29 10:46:25,536:INFO:            lightgbm: 4.5.0
2024-12-29 10:46:25,536:INFO:               numba: 0.60.0
2024-12-29 10:46:25,536:INFO:            requests: 2.32.3
2024-12-29 10:46:25,536:INFO:          matplotlib: 3.9.2
2024-12-29 10:46:25,536:INFO:          scikitplot: 0.3.7
2024-12-29 10:46:25,536:INFO:         yellowbrick: 1.5
2024-12-29 10:46:25,536:INFO:              plotly: 5.24.1
2024-12-29 10:46:25,536:INFO:    plotly-resampler: Not installed
2024-12-29 10:46:25,536:INFO:             kaleido: 0.2.1
2024-12-29 10:46:25,537:INFO:           schemdraw: 0.15
2024-12-29 10:46:25,537:INFO:         statsmodels: 0.14.2
2024-12-29 10:46:25,537:INFO:              sktime: 0.26.0
2024-12-29 10:46:25,537:INFO:               tbats: 1.1.3
2024-12-29 10:46:25,537:INFO:            pmdarima: 2.0.4
2024-12-29 10:46:25,537:INFO:              psutil: 5.9.0
2024-12-29 10:46:25,537:INFO:          markupsafe: 2.1.3
2024-12-29 10:46:25,537:INFO:             pickle5: Not installed
2024-12-29 10:46:25,537:INFO:         cloudpickle: 3.0.0
2024-12-29 10:46:25,537:INFO:         deprecation: 2.1.0
2024-12-29 10:46:25,537:INFO:              xxhash: 2.0.2
2024-12-29 10:46:25,537:INFO:           wurlitzer: 3.1.1
2024-12-29 10:46:25,537:INFO:PyCaret optional dependencies:
2024-12-29 10:46:25,611:INFO:                shap: Not installed
2024-12-29 10:46:25,611:INFO:           interpret: Not installed
2024-12-29 10:46:25,611:INFO:                umap: 0.5.3
2024-12-29 10:46:25,611:INFO:     ydata_profiling: Not installed
2024-12-29 10:46:25,611:INFO:  explainerdashboard: Not installed
2024-12-29 10:46:25,611:INFO:             autoviz: Not installed
2024-12-29 10:46:25,611:INFO:           fairlearn: Not installed
2024-12-29 10:46:25,611:INFO:          deepchecks: Not installed
2024-12-29 10:46:25,611:INFO:             xgboost: 2.1.2
2024-12-29 10:46:25,611:INFO:            catboost: 1.2.3
2024-12-29 10:46:25,611:INFO:              kmodes: 0.12.2
2024-12-29 10:46:25,611:INFO:             mlxtend: 0.23.1
2024-12-29 10:46:25,611:INFO:       statsforecast: Not installed
2024-12-29 10:46:25,611:INFO:        tune_sklearn: Not installed
2024-12-29 10:46:25,611:INFO:                 ray: Not installed
2024-12-29 10:46:25,611:INFO:            hyperopt: Not installed
2024-12-29 10:46:25,611:INFO:              optuna: Not installed
2024-12-29 10:46:25,611:INFO:               skopt: Not installed
2024-12-29 10:46:25,611:INFO:              mlflow: 2.16.2
2024-12-29 10:46:25,611:INFO:              gradio: Not installed
2024-12-29 10:46:25,611:INFO:             fastapi: Not installed
2024-12-29 10:46:25,611:INFO:             uvicorn: Not installed
2024-12-29 10:46:25,611:INFO:              m2cgen: Not installed
2024-12-29 10:46:25,611:INFO:           evidently: Not installed
2024-12-29 10:46:25,611:INFO:               fugue: Not installed
2024-12-29 10:46:25,611:INFO:           streamlit: Not installed
2024-12-29 10:46:25,612:INFO:             prophet: Not installed
2024-12-29 10:46:25,612:INFO:None
2024-12-29 10:46:25,612:INFO:Set up data.
2024-12-29 10:46:25,616:INFO:Set up folding strategy.
2024-12-29 10:46:25,616:INFO:Set up train/test split.
2024-12-29 10:46:25,621:INFO:Set up index.
2024-12-29 10:46:25,622:INFO:Assigning column types.
2024-12-29 10:46:25,624:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-29 10:46:25,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 10:46:25,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:46:25,698:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:25,700:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:25,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 10:46:25,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:46:25,886:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:25,888:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:25,889:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-29 10:46:25,924:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:46:25,947:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:25,948:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:25,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:46:26,007:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:26,009:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:26,010:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-29 10:46:26,067:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:26,069:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:26,126:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:26,128:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:26,130:INFO:Preparing preprocessing pipeline...
2024-12-29 10:46:26,131:INFO:Set up simple imputation.
2024-12-29 10:46:26,147:INFO:Finished creating preprocessing pipeline.
2024-12-29 10:46:26,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-29 10:46:26,150:INFO:Creating final display dataframe.
2024-12-29 10:46:26,194:INFO:Setup _display_container:                     Description             Value
0                    Session id              7606
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 4)
4        Transformed data shape          (891, 4)
5   Transformed train set shape          (623, 4)
6    Transformed test set shape          (268, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              fba1
2024-12-29 10:46:26,259:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:26,262:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:26,320:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:46:26,323:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:46:26,325:INFO:setup() successfully completed in 0.9s...............
2024-12-29 10:46:26,325:INFO:Initializing compare_models()
2024-12-29 10:46:26,325:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-29 10:46:26,325:INFO:Checking exceptions
2024-12-29 10:46:26,327:INFO:Preparing display monitor
2024-12-29 10:46:26,346:INFO:Initializing Logistic Regression
2024-12-29 10:46:26,347:INFO:Total runtime is 2.0710627237955728e-05 minutes
2024-12-29 10:46:26,350:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:26,350:INFO:Initializing create_model()
2024-12-29 10:46:26,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:26,350:INFO:Checking exceptions
2024-12-29 10:46:26,350:INFO:Importing libraries
2024-12-29 10:46:26,350:INFO:Copying training dataset
2024-12-29 10:46:26,355:INFO:Defining folds
2024-12-29 10:46:26,356:INFO:Declaring metric variables
2024-12-29 10:46:26,359:INFO:Importing untrained model
2024-12-29 10:46:26,363:INFO:Logistic Regression Imported successfully
2024-12-29 10:46:26,368:INFO:Starting cross validation
2024-12-29 10:46:26,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:29,911:INFO:Calculating mean and std
2024-12-29 10:46:29,913:INFO:Creating metrics dataframe
2024-12-29 10:46:29,917:INFO:Uploading results into container
2024-12-29 10:46:29,918:INFO:Uploading model into container now
2024-12-29 10:46:29,918:INFO:_master_model_container: 1
2024-12-29 10:46:29,918:INFO:_display_container: 2
2024-12-29 10:46:29,919:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7606, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 10:46:29,919:INFO:create_model() successfully completed......................................
2024-12-29 10:46:30,127:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:30,127:INFO:Creating metrics dataframe
2024-12-29 10:46:30,134:INFO:Initializing K Neighbors Classifier
2024-12-29 10:46:30,134:INFO:Total runtime is 0.06313058932622273 minutes
2024-12-29 10:46:30,137:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:30,137:INFO:Initializing create_model()
2024-12-29 10:46:30,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:30,137:INFO:Checking exceptions
2024-12-29 10:46:30,137:INFO:Importing libraries
2024-12-29 10:46:30,137:INFO:Copying training dataset
2024-12-29 10:46:30,140:INFO:Defining folds
2024-12-29 10:46:30,140:INFO:Declaring metric variables
2024-12-29 10:46:30,143:INFO:Importing untrained model
2024-12-29 10:46:30,147:INFO:K Neighbors Classifier Imported successfully
2024-12-29 10:46:30,152:INFO:Starting cross validation
2024-12-29 10:46:30,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:31,822:INFO:Calculating mean and std
2024-12-29 10:46:31,823:INFO:Creating metrics dataframe
2024-12-29 10:46:31,825:INFO:Uploading results into container
2024-12-29 10:46:31,826:INFO:Uploading model into container now
2024-12-29 10:46:31,826:INFO:_master_model_container: 2
2024-12-29 10:46:31,826:INFO:_display_container: 2
2024-12-29 10:46:31,826:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 10:46:31,826:INFO:create_model() successfully completed......................................
2024-12-29 10:46:32,006:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:32,006:INFO:Creating metrics dataframe
2024-12-29 10:46:32,012:INFO:Initializing Naive Bayes
2024-12-29 10:46:32,013:INFO:Total runtime is 0.09446062246958414 minutes
2024-12-29 10:46:32,016:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:32,016:INFO:Initializing create_model()
2024-12-29 10:46:32,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:32,017:INFO:Checking exceptions
2024-12-29 10:46:32,017:INFO:Importing libraries
2024-12-29 10:46:32,017:INFO:Copying training dataset
2024-12-29 10:46:32,020:INFO:Defining folds
2024-12-29 10:46:32,021:INFO:Declaring metric variables
2024-12-29 10:46:32,023:INFO:Importing untrained model
2024-12-29 10:46:32,027:INFO:Naive Bayes Imported successfully
2024-12-29 10:46:32,032:INFO:Starting cross validation
2024-12-29 10:46:32,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:32,084:INFO:Calculating mean and std
2024-12-29 10:46:32,085:INFO:Creating metrics dataframe
2024-12-29 10:46:32,086:INFO:Uploading results into container
2024-12-29 10:46:32,086:INFO:Uploading model into container now
2024-12-29 10:46:32,087:INFO:_master_model_container: 3
2024-12-29 10:46:32,087:INFO:_display_container: 2
2024-12-29 10:46:32,087:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-29 10:46:32,087:INFO:create_model() successfully completed......................................
2024-12-29 10:46:32,253:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:32,253:INFO:Creating metrics dataframe
2024-12-29 10:46:32,260:INFO:Initializing Decision Tree Classifier
2024-12-29 10:46:32,260:INFO:Total runtime is 0.09856789906819662 minutes
2024-12-29 10:46:32,263:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:32,263:INFO:Initializing create_model()
2024-12-29 10:46:32,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:32,264:INFO:Checking exceptions
2024-12-29 10:46:32,264:INFO:Importing libraries
2024-12-29 10:46:32,264:INFO:Copying training dataset
2024-12-29 10:46:32,267:INFO:Defining folds
2024-12-29 10:46:32,267:INFO:Declaring metric variables
2024-12-29 10:46:32,271:INFO:Importing untrained model
2024-12-29 10:46:32,274:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:46:32,279:INFO:Starting cross validation
2024-12-29 10:46:32,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:32,327:INFO:Calculating mean and std
2024-12-29 10:46:32,328:INFO:Creating metrics dataframe
2024-12-29 10:46:32,330:INFO:Uploading results into container
2024-12-29 10:46:32,330:INFO:Uploading model into container now
2024-12-29 10:46:32,330:INFO:_master_model_container: 4
2024-12-29 10:46:32,331:INFO:_display_container: 2
2024-12-29 10:46:32,331:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:32,331:INFO:create_model() successfully completed......................................
2024-12-29 10:46:32,500:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:32,500:INFO:Creating metrics dataframe
2024-12-29 10:46:32,507:INFO:Initializing SVM - Linear Kernel
2024-12-29 10:46:32,507:INFO:Total runtime is 0.1026901404062907 minutes
2024-12-29 10:46:32,510:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:32,510:INFO:Initializing create_model()
2024-12-29 10:46:32,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:32,510:INFO:Checking exceptions
2024-12-29 10:46:32,511:INFO:Importing libraries
2024-12-29 10:46:32,511:INFO:Copying training dataset
2024-12-29 10:46:32,514:INFO:Defining folds
2024-12-29 10:46:32,514:INFO:Declaring metric variables
2024-12-29 10:46:32,517:INFO:Importing untrained model
2024-12-29 10:46:32,519:INFO:SVM - Linear Kernel Imported successfully
2024-12-29 10:46:32,525:INFO:Starting cross validation
2024-12-29 10:46:32,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:32,572:INFO:Calculating mean and std
2024-12-29 10:46:32,572:INFO:Creating metrics dataframe
2024-12-29 10:46:32,574:INFO:Uploading results into container
2024-12-29 10:46:32,574:INFO:Uploading model into container now
2024-12-29 10:46:32,575:INFO:_master_model_container: 5
2024-12-29 10:46:32,575:INFO:_display_container: 2
2024-12-29 10:46:32,575:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7606, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-29 10:46:32,575:INFO:create_model() successfully completed......................................
2024-12-29 10:46:32,741:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:32,742:INFO:Creating metrics dataframe
2024-12-29 10:46:32,749:INFO:Initializing Ridge Classifier
2024-12-29 10:46:32,749:INFO:Total runtime is 0.1067132592201233 minutes
2024-12-29 10:46:32,752:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:32,752:INFO:Initializing create_model()
2024-12-29 10:46:32,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:32,752:INFO:Checking exceptions
2024-12-29 10:46:32,752:INFO:Importing libraries
2024-12-29 10:46:32,752:INFO:Copying training dataset
2024-12-29 10:46:32,755:INFO:Defining folds
2024-12-29 10:46:32,755:INFO:Declaring metric variables
2024-12-29 10:46:32,758:INFO:Importing untrained model
2024-12-29 10:46:32,762:INFO:Ridge Classifier Imported successfully
2024-12-29 10:46:32,768:INFO:Starting cross validation
2024-12-29 10:46:32,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:32,870:INFO:Calculating mean and std
2024-12-29 10:46:32,871:INFO:Creating metrics dataframe
2024-12-29 10:46:32,872:INFO:Uploading results into container
2024-12-29 10:46:32,872:INFO:Uploading model into container now
2024-12-29 10:46:32,874:INFO:_master_model_container: 6
2024-12-29 10:46:32,874:INFO:_display_container: 2
2024-12-29 10:46:32,874:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7606, solver='auto',
                tol=0.0001)
2024-12-29 10:46:32,874:INFO:create_model() successfully completed......................................
2024-12-29 10:46:33,038:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:33,039:INFO:Creating metrics dataframe
2024-12-29 10:46:33,045:INFO:Initializing Random Forest Classifier
2024-12-29 10:46:33,045:INFO:Total runtime is 0.11165426969528199 minutes
2024-12-29 10:46:33,047:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:33,049:INFO:Initializing create_model()
2024-12-29 10:46:33,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:33,049:INFO:Checking exceptions
2024-12-29 10:46:33,049:INFO:Importing libraries
2024-12-29 10:46:33,049:INFO:Copying training dataset
2024-12-29 10:46:33,052:INFO:Defining folds
2024-12-29 10:46:33,052:INFO:Declaring metric variables
2024-12-29 10:46:33,055:INFO:Importing untrained model
2024-12-29 10:46:33,058:INFO:Random Forest Classifier Imported successfully
2024-12-29 10:46:33,064:INFO:Starting cross validation
2024-12-29 10:46:33,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:33,327:INFO:Calculating mean and std
2024-12-29 10:46:33,330:INFO:Creating metrics dataframe
2024-12-29 10:46:33,331:INFO:Uploading results into container
2024-12-29 10:46:33,332:INFO:Uploading model into container now
2024-12-29 10:46:33,332:INFO:_master_model_container: 7
2024-12-29 10:46:33,332:INFO:_display_container: 2
2024-12-29 10:46:33,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7606, verbose=0,
                       warm_start=False)
2024-12-29 10:46:33,333:INFO:create_model() successfully completed......................................
2024-12-29 10:46:33,504:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:33,505:INFO:Creating metrics dataframe
2024-12-29 10:46:33,511:INFO:Initializing Quadratic Discriminant Analysis
2024-12-29 10:46:33,512:INFO:Total runtime is 0.1194198727607727 minutes
2024-12-29 10:46:33,515:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:33,515:INFO:Initializing create_model()
2024-12-29 10:46:33,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:33,516:INFO:Checking exceptions
2024-12-29 10:46:33,516:INFO:Importing libraries
2024-12-29 10:46:33,516:INFO:Copying training dataset
2024-12-29 10:46:33,519:INFO:Defining folds
2024-12-29 10:46:33,520:INFO:Declaring metric variables
2024-12-29 10:46:33,522:INFO:Importing untrained model
2024-12-29 10:46:33,525:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-29 10:46:33,530:INFO:Starting cross validation
2024-12-29 10:46:33,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:33,590:INFO:Calculating mean and std
2024-12-29 10:46:33,590:INFO:Creating metrics dataframe
2024-12-29 10:46:33,592:INFO:Uploading results into container
2024-12-29 10:46:33,593:INFO:Uploading model into container now
2024-12-29 10:46:33,593:INFO:_master_model_container: 8
2024-12-29 10:46:33,593:INFO:_display_container: 2
2024-12-29 10:46:33,593:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-29 10:46:33,593:INFO:create_model() successfully completed......................................
2024-12-29 10:46:33,759:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:33,759:INFO:Creating metrics dataframe
2024-12-29 10:46:33,766:INFO:Initializing Ada Boost Classifier
2024-12-29 10:46:33,766:INFO:Total runtime is 0.12367518345514933 minutes
2024-12-29 10:46:33,769:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:33,769:INFO:Initializing create_model()
2024-12-29 10:46:33,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:33,769:INFO:Checking exceptions
2024-12-29 10:46:33,770:INFO:Importing libraries
2024-12-29 10:46:33,770:INFO:Copying training dataset
2024-12-29 10:46:33,772:INFO:Defining folds
2024-12-29 10:46:33,773:INFO:Declaring metric variables
2024-12-29 10:46:33,778:INFO:Importing untrained model
2024-12-29 10:46:33,782:INFO:Ada Boost Classifier Imported successfully
2024-12-29 10:46:33,789:INFO:Starting cross validation
2024-12-29 10:46:33,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:33,813:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,813:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,813:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,814:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,815:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,816:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,817:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,819:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,820:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,821:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:46:33,962:INFO:Calculating mean and std
2024-12-29 10:46:33,964:INFO:Creating metrics dataframe
2024-12-29 10:46:33,965:INFO:Uploading results into container
2024-12-29 10:46:33,966:INFO:Uploading model into container now
2024-12-29 10:46:33,966:INFO:_master_model_container: 9
2024-12-29 10:46:33,966:INFO:_display_container: 2
2024-12-29 10:46:33,966:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7606)
2024-12-29 10:46:33,966:INFO:create_model() successfully completed......................................
2024-12-29 10:46:34,143:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:34,144:INFO:Creating metrics dataframe
2024-12-29 10:46:34,151:INFO:Initializing Gradient Boosting Classifier
2024-12-29 10:46:34,152:INFO:Total runtime is 0.13009595076243083 minutes
2024-12-29 10:46:34,154:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:34,155:INFO:Initializing create_model()
2024-12-29 10:46:34,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:34,155:INFO:Checking exceptions
2024-12-29 10:46:34,155:INFO:Importing libraries
2024-12-29 10:46:34,155:INFO:Copying training dataset
2024-12-29 10:46:34,158:INFO:Defining folds
2024-12-29 10:46:34,158:INFO:Declaring metric variables
2024-12-29 10:46:34,161:INFO:Importing untrained model
2024-12-29 10:46:34,165:INFO:Gradient Boosting Classifier Imported successfully
2024-12-29 10:46:34,172:INFO:Starting cross validation
2024-12-29 10:46:34,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:34,335:INFO:Calculating mean and std
2024-12-29 10:46:34,336:INFO:Creating metrics dataframe
2024-12-29 10:46:34,338:INFO:Uploading results into container
2024-12-29 10:46:34,338:INFO:Uploading model into container now
2024-12-29 10:46:34,339:INFO:_master_model_container: 10
2024-12-29 10:46:34,339:INFO:_display_container: 2
2024-12-29 10:46:34,339:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7606, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-29 10:46:34,339:INFO:create_model() successfully completed......................................
2024-12-29 10:46:34,513:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:34,514:INFO:Creating metrics dataframe
2024-12-29 10:46:34,522:INFO:Initializing Linear Discriminant Analysis
2024-12-29 10:46:34,522:INFO:Total runtime is 0.13626644611358643 minutes
2024-12-29 10:46:34,525:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:34,525:INFO:Initializing create_model()
2024-12-29 10:46:34,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:34,525:INFO:Checking exceptions
2024-12-29 10:46:34,525:INFO:Importing libraries
2024-12-29 10:46:34,525:INFO:Copying training dataset
2024-12-29 10:46:34,528:INFO:Defining folds
2024-12-29 10:46:34,528:INFO:Declaring metric variables
2024-12-29 10:46:34,531:INFO:Importing untrained model
2024-12-29 10:46:34,535:INFO:Linear Discriminant Analysis Imported successfully
2024-12-29 10:46:34,541:INFO:Starting cross validation
2024-12-29 10:46:34,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:34,603:INFO:Calculating mean and std
2024-12-29 10:46:34,603:INFO:Creating metrics dataframe
2024-12-29 10:46:34,605:INFO:Uploading results into container
2024-12-29 10:46:34,605:INFO:Uploading model into container now
2024-12-29 10:46:34,606:INFO:_master_model_container: 11
2024-12-29 10:46:34,606:INFO:_display_container: 2
2024-12-29 10:46:34,606:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-29 10:46:34,606:INFO:create_model() successfully completed......................................
2024-12-29 10:46:34,779:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:34,779:INFO:Creating metrics dataframe
2024-12-29 10:46:34,788:INFO:Initializing Extra Trees Classifier
2024-12-29 10:46:34,788:INFO:Total runtime is 0.14070409536361694 minutes
2024-12-29 10:46:34,791:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:34,791:INFO:Initializing create_model()
2024-12-29 10:46:34,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:34,791:INFO:Checking exceptions
2024-12-29 10:46:34,792:INFO:Importing libraries
2024-12-29 10:46:34,792:INFO:Copying training dataset
2024-12-29 10:46:34,795:INFO:Defining folds
2024-12-29 10:46:34,795:INFO:Declaring metric variables
2024-12-29 10:46:34,797:INFO:Importing untrained model
2024-12-29 10:46:34,801:INFO:Extra Trees Classifier Imported successfully
2024-12-29 10:46:34,807:INFO:Starting cross validation
2024-12-29 10:46:34,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:35,057:INFO:Calculating mean and std
2024-12-29 10:46:35,059:INFO:Creating metrics dataframe
2024-12-29 10:46:35,061:INFO:Uploading results into container
2024-12-29 10:46:35,062:INFO:Uploading model into container now
2024-12-29 10:46:35,062:INFO:_master_model_container: 12
2024-12-29 10:46:35,062:INFO:_display_container: 2
2024-12-29 10:46:35,062:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7606, verbose=0,
                     warm_start=False)
2024-12-29 10:46:35,063:INFO:create_model() successfully completed......................................
2024-12-29 10:46:35,235:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:35,235:INFO:Creating metrics dataframe
2024-12-29 10:46:35,244:INFO:Initializing Extreme Gradient Boosting
2024-12-29 10:46:35,244:INFO:Total runtime is 0.14830317497253417 minutes
2024-12-29 10:46:35,247:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:35,247:INFO:Initializing create_model()
2024-12-29 10:46:35,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:35,248:INFO:Checking exceptions
2024-12-29 10:46:35,248:INFO:Importing libraries
2024-12-29 10:46:35,248:INFO:Copying training dataset
2024-12-29 10:46:35,250:INFO:Defining folds
2024-12-29 10:46:35,250:INFO:Declaring metric variables
2024-12-29 10:46:35,253:INFO:Importing untrained model
2024-12-29 10:46:35,258:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 10:46:35,263:INFO:Starting cross validation
2024-12-29 10:46:35,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:39,442:INFO:Calculating mean and std
2024-12-29 10:46:39,443:INFO:Creating metrics dataframe
2024-12-29 10:46:39,445:INFO:Uploading results into container
2024-12-29 10:46:39,445:INFO:Uploading model into container now
2024-12-29 10:46:39,446:INFO:_master_model_container: 13
2024-12-29 10:46:39,446:INFO:_display_container: 2
2024-12-29 10:46:39,446:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 10:46:39,446:INFO:create_model() successfully completed......................................
2024-12-29 10:46:39,636:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:39,636:INFO:Creating metrics dataframe
2024-12-29 10:46:39,645:INFO:Initializing Light Gradient Boosting Machine
2024-12-29 10:46:39,646:INFO:Total runtime is 0.2216772715250651 minutes
2024-12-29 10:46:39,649:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:39,649:INFO:Initializing create_model()
2024-12-29 10:46:39,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:39,650:INFO:Checking exceptions
2024-12-29 10:46:39,650:INFO:Importing libraries
2024-12-29 10:46:39,650:INFO:Copying training dataset
2024-12-29 10:46:39,653:INFO:Defining folds
2024-12-29 10:46:39,653:INFO:Declaring metric variables
2024-12-29 10:46:39,657:INFO:Importing untrained model
2024-12-29 10:46:39,660:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-29 10:46:39,667:INFO:Starting cross validation
2024-12-29 10:46:39,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:42,290:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-29 10:46:46,725:INFO:Calculating mean and std
2024-12-29 10:46:46,728:INFO:Creating metrics dataframe
2024-12-29 10:46:46,730:INFO:Uploading results into container
2024-12-29 10:46:46,731:INFO:Uploading model into container now
2024-12-29 10:46:46,731:INFO:_master_model_container: 14
2024-12-29 10:46:46,731:INFO:_display_container: 2
2024-12-29 10:46:46,732:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7606, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-29 10:46:46,732:INFO:create_model() successfully completed......................................
2024-12-29 10:46:46,939:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:46,940:INFO:Creating metrics dataframe
2024-12-29 10:46:46,948:INFO:Initializing CatBoost Classifier
2024-12-29 10:46:46,949:INFO:Total runtime is 0.3433873017628988 minutes
2024-12-29 10:46:46,952:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:46,952:INFO:Initializing create_model()
2024-12-29 10:46:46,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:46,952:INFO:Checking exceptions
2024-12-29 10:46:46,952:INFO:Importing libraries
2024-12-29 10:46:46,952:INFO:Copying training dataset
2024-12-29 10:46:46,955:INFO:Defining folds
2024-12-29 10:46:46,956:INFO:Declaring metric variables
2024-12-29 10:46:46,958:INFO:Importing untrained model
2024-12-29 10:46:46,963:INFO:CatBoost Classifier Imported successfully
2024-12-29 10:46:46,970:INFO:Starting cross validation
2024-12-29 10:46:46,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:49,666:INFO:Calculating mean and std
2024-12-29 10:46:49,667:INFO:Creating metrics dataframe
2024-12-29 10:46:49,669:INFO:Uploading results into container
2024-12-29 10:46:49,669:INFO:Uploading model into container now
2024-12-29 10:46:49,670:INFO:_master_model_container: 15
2024-12-29 10:46:49,670:INFO:_display_container: 2
2024-12-29 10:46:49,670:INFO:<catboost.core.CatBoostClassifier object at 0x0000020539859240>
2024-12-29 10:46:49,670:INFO:create_model() successfully completed......................................
2024-12-29 10:46:49,855:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:49,855:INFO:Creating metrics dataframe
2024-12-29 10:46:49,864:INFO:Initializing Dummy Classifier
2024-12-29 10:46:49,864:INFO:Total runtime is 0.39196884632110596 minutes
2024-12-29 10:46:49,867:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:49,868:INFO:Initializing create_model()
2024-12-29 10:46:49,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053969DEA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:49,868:INFO:Checking exceptions
2024-12-29 10:46:49,868:INFO:Importing libraries
2024-12-29 10:46:49,868:INFO:Copying training dataset
2024-12-29 10:46:49,871:INFO:Defining folds
2024-12-29 10:46:49,871:INFO:Declaring metric variables
2024-12-29 10:46:49,875:INFO:Importing untrained model
2024-12-29 10:46:49,877:INFO:Dummy Classifier Imported successfully
2024-12-29 10:46:49,884:INFO:Starting cross validation
2024-12-29 10:46:49,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:49,926:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:49,926:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:49,927:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:49,928:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:49,928:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:49,928:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:49,931:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:51,485:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:51,493:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:46:51,499:INFO:Calculating mean and std
2024-12-29 10:46:51,500:INFO:Creating metrics dataframe
2024-12-29 10:46:51,503:INFO:Uploading results into container
2024-12-29 10:46:51,503:INFO:Uploading model into container now
2024-12-29 10:46:51,504:INFO:_master_model_container: 16
2024-12-29 10:46:51,504:INFO:_display_container: 2
2024-12-29 10:46:51,504:INFO:DummyClassifier(constant=None, random_state=7606, strategy='prior')
2024-12-29 10:46:51,504:INFO:create_model() successfully completed......................................
2024-12-29 10:46:51,683:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:51,683:INFO:Creating metrics dataframe
2024-12-29 10:46:51,695:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-29 10:46:51,705:INFO:Initializing create_model()
2024-12-29 10:46:51,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:51,706:INFO:Checking exceptions
2024-12-29 10:46:51,707:INFO:Importing libraries
2024-12-29 10:46:51,707:INFO:Copying training dataset
2024-12-29 10:46:51,709:INFO:Defining folds
2024-12-29 10:46:51,709:INFO:Declaring metric variables
2024-12-29 10:46:51,709:INFO:Importing untrained model
2024-12-29 10:46:51,709:INFO:Declaring custom model
2024-12-29 10:46:51,711:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:46:51,711:INFO:Cross validation set to False
2024-12-29 10:46:51,711:INFO:Fitting Model
2024-12-29 10:46:51,717:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:51,717:INFO:create_model() successfully completed......................................
2024-12-29 10:46:51,909:INFO:_master_model_container: 16
2024-12-29 10:46:51,909:INFO:_display_container: 2
2024-12-29 10:46:51,910:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:51,910:INFO:compare_models() successfully completed......................................
2024-12-29 10:46:51,910:INFO:Initializing create_model()
2024-12-29 10:46:51,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:51,910:INFO:Checking exceptions
2024-12-29 10:46:51,920:INFO:Importing libraries
2024-12-29 10:46:51,920:INFO:Copying training dataset
2024-12-29 10:46:51,925:INFO:Defining folds
2024-12-29 10:46:51,925:INFO:Declaring metric variables
2024-12-29 10:46:51,928:INFO:Importing untrained model
2024-12-29 10:46:51,928:INFO:Declaring custom model
2024-12-29 10:46:51,932:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:46:51,937:INFO:Starting cross validation
2024-12-29 10:46:51,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:51,998:INFO:Calculating mean and std
2024-12-29 10:46:51,998:INFO:Creating metrics dataframe
2024-12-29 10:46:52,002:INFO:Finalizing model
2024-12-29 10:46:52,012:INFO:Uploading results into container
2024-12-29 10:46:52,012:INFO:Uploading model into container now
2024-12-29 10:46:52,020:INFO:_master_model_container: 17
2024-12-29 10:46:52,021:INFO:_display_container: 3
2024-12-29 10:46:52,021:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:52,021:INFO:create_model() successfully completed......................................
2024-12-29 10:46:52,198:INFO:Initializing tune_model()
2024-12-29 10:46:52,200:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>)
2024-12-29 10:46:52,200:INFO:Checking exceptions
2024-12-29 10:46:52,212:INFO:Copying training dataset
2024-12-29 10:46:52,215:INFO:Checking base model
2024-12-29 10:46:52,215:INFO:Base model : Decision Tree Classifier
2024-12-29 10:46:52,218:INFO:Declaring metric variables
2024-12-29 10:46:52,225:INFO:Defining Hyperparameters
2024-12-29 10:46:52,418:INFO:Tuning with n_jobs=-1
2024-12-29 10:46:52,418:INFO:Initializing RandomizedSearchCV
2024-12-29 10:46:52,625:INFO:best_params: {'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'gini'}
2024-12-29 10:46:52,625:INFO:Hyperparameter search completed
2024-12-29 10:46:52,625:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:52,626:INFO:Initializing create_model()
2024-12-29 10:46:52,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020539858A30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 7, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 4, 'criterion': 'gini'})
2024-12-29 10:46:52,626:INFO:Checking exceptions
2024-12-29 10:46:52,626:INFO:Importing libraries
2024-12-29 10:46:52,626:INFO:Copying training dataset
2024-12-29 10:46:52,628:INFO:Defining folds
2024-12-29 10:46:52,628:INFO:Declaring metric variables
2024-12-29 10:46:52,632:INFO:Importing untrained model
2024-12-29 10:46:52,632:INFO:Declaring custom model
2024-12-29 10:46:52,634:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:46:52,640:INFO:Starting cross validation
2024-12-29 10:46:52,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:52,698:INFO:Calculating mean and std
2024-12-29 10:46:52,699:INFO:Creating metrics dataframe
2024-12-29 10:46:52,703:INFO:Finalizing model
2024-12-29 10:46:52,712:INFO:Uploading results into container
2024-12-29 10:46:52,713:INFO:Uploading model into container now
2024-12-29 10:46:52,713:INFO:_master_model_container: 18
2024-12-29 10:46:52,713:INFO:_display_container: 4
2024-12-29 10:46:52,714:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=4, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:52,714:INFO:create_model() successfully completed......................................
2024-12-29 10:46:52,894:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:52,894:INFO:choose_better activated
2024-12-29 10:46:52,897:INFO:SubProcess create_model() called ==================================
2024-12-29 10:46:52,897:INFO:Initializing create_model()
2024-12-29 10:46:52,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:52,898:INFO:Checking exceptions
2024-12-29 10:46:52,899:INFO:Importing libraries
2024-12-29 10:46:52,899:INFO:Copying training dataset
2024-12-29 10:46:52,901:INFO:Defining folds
2024-12-29 10:46:52,901:INFO:Declaring metric variables
2024-12-29 10:46:52,901:INFO:Importing untrained model
2024-12-29 10:46:52,901:INFO:Declaring custom model
2024-12-29 10:46:52,903:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:46:52,903:INFO:Starting cross validation
2024-12-29 10:46:52,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:46:52,958:INFO:Calculating mean and std
2024-12-29 10:46:52,958:INFO:Creating metrics dataframe
2024-12-29 10:46:52,959:INFO:Finalizing model
2024-12-29 10:46:52,964:INFO:Uploading results into container
2024-12-29 10:46:52,965:INFO:Uploading model into container now
2024-12-29 10:46:52,965:INFO:_master_model_container: 19
2024-12-29 10:46:52,965:INFO:_display_container: 5
2024-12-29 10:46:52,965:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:52,965:INFO:create_model() successfully completed......................................
2024-12-29 10:46:53,135:INFO:SubProcess create_model() end ==================================
2024-12-29 10:46:53,135:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best') result for Accuracy is 0.8184
2024-12-29 10:46:53,135:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=4, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best') result for Accuracy is 0.8184
2024-12-29 10:46:53,136:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best') is best model
2024-12-29 10:46:53,136:INFO:choose_better completed
2024-12-29 10:46:53,136:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-29 10:46:53,145:INFO:_master_model_container: 19
2024-12-29 10:46:53,145:INFO:_display_container: 4
2024-12-29 10:46:53,146:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:53,146:INFO:tune_model() successfully completed......................................
2024-12-29 10:46:53,317:INFO:Initializing finalize_model()
2024-12-29 10:46:53,317:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 10:46:53,317:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best')
2024-12-29 10:46:53,319:INFO:Initializing create_model()
2024-12-29 10:46:53,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002052D6E5D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7606, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:46:53,319:INFO:Checking exceptions
2024-12-29 10:46:53,321:INFO:Importing libraries
2024-12-29 10:46:53,321:INFO:Copying training dataset
2024-12-29 10:46:53,321:INFO:Defining folds
2024-12-29 10:46:53,321:INFO:Declaring metric variables
2024-12-29 10:46:53,321:INFO:Importing untrained model
2024-12-29 10:46:53,321:INFO:Declaring custom model
2024-12-29 10:46:53,322:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:46:53,322:INFO:Cross validation set to False
2024-12-29 10:46:53,322:INFO:Fitting Model
2024-12-29 10:46:53,330:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=7606,
                                        splitter='best'))],
         verbose=False)
2024-12-29 10:46:53,330:INFO:create_model() successfully completed......................................
2024-12-29 10:46:53,498:INFO:_master_model_container: 19
2024-12-29 10:46:53,498:INFO:_display_container: 4
2024-12-29 10:46:53,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=7606,
                                        splitter='best'))],
         verbose=False)
2024-12-29 10:46:53,501:INFO:finalize_model() successfully completed......................................
2024-12-29 10:52:06,912:INFO:PyCaret ClassificationExperiment
2024-12-29 10:52:06,912:INFO:Logging name: clf-default-name
2024-12-29 10:52:06,912:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-29 10:52:06,912:INFO:version 3.3.1
2024-12-29 10:52:06,913:INFO:Initializing setup()
2024-12-29 10:52:06,913:INFO:self.USI: cdc0
2024-12-29 10:52:06,913:INFO:self._variable_keys: {'USI', '_ml_usecase', 'y_train', 'X_train', 'X', 'is_multiclass', 'pipeline', 'X_test', 'fold_groups_param', 'data', 'fix_imbalance', 'idx', 'gpu_param', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', '_available_plots', 'y_test', 'log_plots_param', 'logging_param', 'memory', 'seed', 'fold_shuffle_param', 'y', 'html_param', 'target_param', 'n_jobs_param', 'exp_name_log'}
2024-12-29 10:52:06,913:INFO:Checking environment
2024-12-29 10:52:06,913:INFO:python_version: 3.10.15
2024-12-29 10:52:06,913:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-29 10:52:06,913:INFO:machine: AMD64
2024-12-29 10:52:06,913:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-29 10:52:06,913:INFO:Memory: svmem(total=16312721408, available=6692446208, percent=59.0, used=9620275200, free=6692446208)
2024-12-29 10:52:06,913:INFO:Physical Core: 6
2024-12-29 10:52:06,913:INFO:Logical Core: 12
2024-12-29 10:52:06,913:INFO:Checking libraries
2024-12-29 10:52:06,913:INFO:System:
2024-12-29 10:52:06,913:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-29 10:52:06,913:INFO:executable: d:\Anaconda\python.exe
2024-12-29 10:52:06,913:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-29 10:52:06,913:INFO:PyCaret required dependencies:
2024-12-29 10:52:06,913:INFO:                 pip: 24.2
2024-12-29 10:52:06,913:INFO:          setuptools: 75.1.0
2024-12-29 10:52:06,913:INFO:             pycaret: 3.3.1
2024-12-29 10:52:06,913:INFO:             IPython: 8.27.0
2024-12-29 10:52:06,913:INFO:          ipywidgets: 8.1.2
2024-12-29 10:52:06,914:INFO:                tqdm: 4.66.5
2024-12-29 10:52:06,914:INFO:               numpy: 1.26.4
2024-12-29 10:52:06,914:INFO:              pandas: 2.1.4
2024-12-29 10:52:06,914:INFO:              jinja2: 3.1.4
2024-12-29 10:52:06,914:INFO:               scipy: 1.11.4
2024-12-29 10:52:06,914:INFO:              joblib: 1.2.0
2024-12-29 10:52:06,914:INFO:             sklearn: 1.4.2
2024-12-29 10:52:06,914:INFO:                pyod: 2.0.2
2024-12-29 10:52:06,914:INFO:            imblearn: 0.12.3
2024-12-29 10:52:06,914:INFO:   category_encoders: 2.6.3
2024-12-29 10:52:06,914:INFO:            lightgbm: 4.5.0
2024-12-29 10:52:06,914:INFO:               numba: 0.60.0
2024-12-29 10:52:06,914:INFO:            requests: 2.32.3
2024-12-29 10:52:06,914:INFO:          matplotlib: 3.9.2
2024-12-29 10:52:06,914:INFO:          scikitplot: 0.3.7
2024-12-29 10:52:06,914:INFO:         yellowbrick: 1.5
2024-12-29 10:52:06,914:INFO:              plotly: 5.24.1
2024-12-29 10:52:06,914:INFO:    plotly-resampler: Not installed
2024-12-29 10:52:06,914:INFO:             kaleido: 0.2.1
2024-12-29 10:52:06,914:INFO:           schemdraw: 0.15
2024-12-29 10:52:06,914:INFO:         statsmodels: 0.14.2
2024-12-29 10:52:06,914:INFO:              sktime: 0.26.0
2024-12-29 10:52:06,914:INFO:               tbats: 1.1.3
2024-12-29 10:52:06,914:INFO:            pmdarima: 2.0.4
2024-12-29 10:52:06,914:INFO:              psutil: 5.9.0
2024-12-29 10:52:06,914:INFO:          markupsafe: 2.1.3
2024-12-29 10:52:06,914:INFO:             pickle5: Not installed
2024-12-29 10:52:06,914:INFO:         cloudpickle: 3.0.0
2024-12-29 10:52:06,914:INFO:         deprecation: 2.1.0
2024-12-29 10:52:06,914:INFO:              xxhash: 2.0.2
2024-12-29 10:52:06,914:INFO:           wurlitzer: 3.1.1
2024-12-29 10:52:06,914:INFO:PyCaret optional dependencies:
2024-12-29 10:52:06,914:INFO:                shap: Not installed
2024-12-29 10:52:06,914:INFO:           interpret: Not installed
2024-12-29 10:52:06,914:INFO:                umap: 0.5.3
2024-12-29 10:52:06,914:INFO:     ydata_profiling: Not installed
2024-12-29 10:52:06,915:INFO:  explainerdashboard: Not installed
2024-12-29 10:52:06,915:INFO:             autoviz: Not installed
2024-12-29 10:52:06,915:INFO:           fairlearn: Not installed
2024-12-29 10:52:06,915:INFO:          deepchecks: Not installed
2024-12-29 10:52:06,915:INFO:             xgboost: 2.1.2
2024-12-29 10:52:06,915:INFO:            catboost: 1.2.3
2024-12-29 10:52:06,915:INFO:              kmodes: 0.12.2
2024-12-29 10:52:06,915:INFO:             mlxtend: 0.23.1
2024-12-29 10:52:06,915:INFO:       statsforecast: Not installed
2024-12-29 10:52:06,915:INFO:        tune_sklearn: Not installed
2024-12-29 10:52:06,915:INFO:                 ray: Not installed
2024-12-29 10:52:06,915:INFO:            hyperopt: Not installed
2024-12-29 10:52:06,915:INFO:              optuna: Not installed
2024-12-29 10:52:06,915:INFO:               skopt: Not installed
2024-12-29 10:52:06,915:INFO:              mlflow: 2.16.2
2024-12-29 10:52:06,915:INFO:              gradio: Not installed
2024-12-29 10:52:06,915:INFO:             fastapi: Not installed
2024-12-29 10:52:06,915:INFO:             uvicorn: Not installed
2024-12-29 10:52:06,915:INFO:              m2cgen: Not installed
2024-12-29 10:52:06,915:INFO:           evidently: Not installed
2024-12-29 10:52:06,915:INFO:               fugue: Not installed
2024-12-29 10:52:06,915:INFO:           streamlit: Not installed
2024-12-29 10:52:06,915:INFO:             prophet: Not installed
2024-12-29 10:52:06,915:INFO:None
2024-12-29 10:52:06,915:INFO:Set up data.
2024-12-29 10:52:06,918:INFO:Set up folding strategy.
2024-12-29 10:52:06,918:INFO:Set up train/test split.
2024-12-29 10:52:06,922:INFO:Set up index.
2024-12-29 10:52:06,922:INFO:Assigning column types.
2024-12-29 10:52:06,924:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-29 10:52:06,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 10:52:06,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:52:06,991:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:06,994:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 10:52:07,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:52:07,061:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,063:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,064:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-29 10:52:07,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:52:07,125:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,128:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,166:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 10:52:07,187:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,189:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,189:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-29 10:52:07,246:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,248:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,306:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,308:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,309:INFO:Preparing preprocessing pipeline...
2024-12-29 10:52:07,310:INFO:Set up simple imputation.
2024-12-29 10:52:07,325:INFO:Finished creating preprocessing pipeline.
2024-12-29 10:52:07,328:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-29 10:52:07,328:INFO:Creating final display dataframe.
2024-12-29 10:52:07,369:INFO:Setup _display_container:                     Description             Value
0                    Session id              7209
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 4)
4        Transformed data shape          (891, 4)
5   Transformed train set shape          (623, 4)
6    Transformed test set shape          (268, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              cdc0
2024-12-29 10:52:07,432:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,434:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,493:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 10:52:07,495:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 10:52:07,496:INFO:setup() successfully completed in 0.59s...............
2024-12-29 10:52:07,497:INFO:Initializing compare_models()
2024-12-29 10:52:07,497:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-29 10:52:07,497:INFO:Checking exceptions
2024-12-29 10:52:07,499:INFO:Preparing display monitor
2024-12-29 10:52:07,517:INFO:Initializing Logistic Regression
2024-12-29 10:52:07,517:INFO:Total runtime is 0.0 minutes
2024-12-29 10:52:07,519:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:07,520:INFO:Initializing create_model()
2024-12-29 10:52:07,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:07,520:INFO:Checking exceptions
2024-12-29 10:52:07,520:INFO:Importing libraries
2024-12-29 10:52:07,520:INFO:Copying training dataset
2024-12-29 10:52:07,524:INFO:Defining folds
2024-12-29 10:52:07,524:INFO:Declaring metric variables
2024-12-29 10:52:07,526:INFO:Importing untrained model
2024-12-29 10:52:07,529:INFO:Logistic Regression Imported successfully
2024-12-29 10:52:07,534:INFO:Starting cross validation
2024-12-29 10:52:07,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:10,657:INFO:Calculating mean and std
2024-12-29 10:52:10,660:INFO:Creating metrics dataframe
2024-12-29 10:52:10,663:INFO:Uploading results into container
2024-12-29 10:52:10,664:INFO:Uploading model into container now
2024-12-29 10:52:10,664:INFO:_master_model_container: 1
2024-12-29 10:52:10,664:INFO:_display_container: 2
2024-12-29 10:52:10,665:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7209, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 10:52:10,665:INFO:create_model() successfully completed......................................
2024-12-29 10:52:10,905:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:10,905:INFO:Creating metrics dataframe
2024-12-29 10:52:10,911:INFO:Initializing K Neighbors Classifier
2024-12-29 10:52:10,911:INFO:Total runtime is 0.056573084990183514 minutes
2024-12-29 10:52:10,913:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:10,914:INFO:Initializing create_model()
2024-12-29 10:52:10,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:10,914:INFO:Checking exceptions
2024-12-29 10:52:10,914:INFO:Importing libraries
2024-12-29 10:52:10,914:INFO:Copying training dataset
2024-12-29 10:52:10,918:INFO:Defining folds
2024-12-29 10:52:10,918:INFO:Declaring metric variables
2024-12-29 10:52:10,921:INFO:Importing untrained model
2024-12-29 10:52:10,924:INFO:K Neighbors Classifier Imported successfully
2024-12-29 10:52:10,931:INFO:Starting cross validation
2024-12-29 10:52:10,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:12,516:INFO:Calculating mean and std
2024-12-29 10:52:12,517:INFO:Creating metrics dataframe
2024-12-29 10:52:12,520:INFO:Uploading results into container
2024-12-29 10:52:12,520:INFO:Uploading model into container now
2024-12-29 10:52:12,520:INFO:_master_model_container: 2
2024-12-29 10:52:12,522:INFO:_display_container: 2
2024-12-29 10:52:12,522:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 10:52:12,522:INFO:create_model() successfully completed......................................
2024-12-29 10:52:12,728:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:12,729:INFO:Creating metrics dataframe
2024-12-29 10:52:12,734:INFO:Initializing Naive Bayes
2024-12-29 10:52:12,734:INFO:Total runtime is 0.08696286678314209 minutes
2024-12-29 10:52:12,737:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:12,737:INFO:Initializing create_model()
2024-12-29 10:52:12,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:12,737:INFO:Checking exceptions
2024-12-29 10:52:12,737:INFO:Importing libraries
2024-12-29 10:52:12,737:INFO:Copying training dataset
2024-12-29 10:52:12,740:INFO:Defining folds
2024-12-29 10:52:12,741:INFO:Declaring metric variables
2024-12-29 10:52:12,744:INFO:Importing untrained model
2024-12-29 10:52:12,747:INFO:Naive Bayes Imported successfully
2024-12-29 10:52:12,753:INFO:Starting cross validation
2024-12-29 10:52:12,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:12,807:INFO:Calculating mean and std
2024-12-29 10:52:12,808:INFO:Creating metrics dataframe
2024-12-29 10:52:12,809:INFO:Uploading results into container
2024-12-29 10:52:12,810:INFO:Uploading model into container now
2024-12-29 10:52:12,810:INFO:_master_model_container: 3
2024-12-29 10:52:12,810:INFO:_display_container: 2
2024-12-29 10:52:12,810:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-29 10:52:12,810:INFO:create_model() successfully completed......................................
2024-12-29 10:52:13,015:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:13,015:INFO:Creating metrics dataframe
2024-12-29 10:52:13,021:INFO:Initializing Decision Tree Classifier
2024-12-29 10:52:13,021:INFO:Total runtime is 0.0917478879292806 minutes
2024-12-29 10:52:13,025:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:13,025:INFO:Initializing create_model()
2024-12-29 10:52:13,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:13,026:INFO:Checking exceptions
2024-12-29 10:52:13,026:INFO:Importing libraries
2024-12-29 10:52:13,026:INFO:Copying training dataset
2024-12-29 10:52:13,029:INFO:Defining folds
2024-12-29 10:52:13,029:INFO:Declaring metric variables
2024-12-29 10:52:13,032:INFO:Importing untrained model
2024-12-29 10:52:13,035:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:52:13,040:INFO:Starting cross validation
2024-12-29 10:52:13,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:13,097:INFO:Calculating mean and std
2024-12-29 10:52:13,097:INFO:Creating metrics dataframe
2024-12-29 10:52:13,099:INFO:Uploading results into container
2024-12-29 10:52:13,099:INFO:Uploading model into container now
2024-12-29 10:52:13,100:INFO:_master_model_container: 4
2024-12-29 10:52:13,100:INFO:_display_container: 2
2024-12-29 10:52:13,100:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:13,100:INFO:create_model() successfully completed......................................
2024-12-29 10:52:13,306:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:13,306:INFO:Creating metrics dataframe
2024-12-29 10:52:13,311:INFO:Initializing SVM - Linear Kernel
2024-12-29 10:52:13,311:INFO:Total runtime is 0.09657593170801798 minutes
2024-12-29 10:52:13,314:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:13,314:INFO:Initializing create_model()
2024-12-29 10:52:13,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:13,315:INFO:Checking exceptions
2024-12-29 10:52:13,315:INFO:Importing libraries
2024-12-29 10:52:13,315:INFO:Copying training dataset
2024-12-29 10:52:13,318:INFO:Defining folds
2024-12-29 10:52:13,318:INFO:Declaring metric variables
2024-12-29 10:52:13,321:INFO:Importing untrained model
2024-12-29 10:52:13,325:INFO:SVM - Linear Kernel Imported successfully
2024-12-29 10:52:13,331:INFO:Starting cross validation
2024-12-29 10:52:13,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:13,383:INFO:Calculating mean and std
2024-12-29 10:52:13,383:INFO:Creating metrics dataframe
2024-12-29 10:52:13,384:INFO:Uploading results into container
2024-12-29 10:52:13,385:INFO:Uploading model into container now
2024-12-29 10:52:13,385:INFO:_master_model_container: 5
2024-12-29 10:52:13,385:INFO:_display_container: 2
2024-12-29 10:52:13,385:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7209, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-29 10:52:13,385:INFO:create_model() successfully completed......................................
2024-12-29 10:52:13,586:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:13,586:INFO:Creating metrics dataframe
2024-12-29 10:52:13,593:INFO:Initializing Ridge Classifier
2024-12-29 10:52:13,593:INFO:Total runtime is 0.10126874049504597 minutes
2024-12-29 10:52:13,596:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:13,596:INFO:Initializing create_model()
2024-12-29 10:52:13,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:13,596:INFO:Checking exceptions
2024-12-29 10:52:13,596:INFO:Importing libraries
2024-12-29 10:52:13,596:INFO:Copying training dataset
2024-12-29 10:52:13,599:INFO:Defining folds
2024-12-29 10:52:13,599:INFO:Declaring metric variables
2024-12-29 10:52:13,602:INFO:Importing untrained model
2024-12-29 10:52:13,604:INFO:Ridge Classifier Imported successfully
2024-12-29 10:52:13,611:INFO:Starting cross validation
2024-12-29 10:52:13,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:13,672:INFO:Calculating mean and std
2024-12-29 10:52:13,673:INFO:Creating metrics dataframe
2024-12-29 10:52:13,674:INFO:Uploading results into container
2024-12-29 10:52:13,674:INFO:Uploading model into container now
2024-12-29 10:52:13,675:INFO:_master_model_container: 6
2024-12-29 10:52:13,675:INFO:_display_container: 2
2024-12-29 10:52:13,675:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7209, solver='auto',
                tol=0.0001)
2024-12-29 10:52:13,675:INFO:create_model() successfully completed......................................
2024-12-29 10:52:13,878:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:13,878:INFO:Creating metrics dataframe
2024-12-29 10:52:13,885:INFO:Initializing Random Forest Classifier
2024-12-29 10:52:13,885:INFO:Total runtime is 0.10613996982574463 minutes
2024-12-29 10:52:13,888:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:13,888:INFO:Initializing create_model()
2024-12-29 10:52:13,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:13,888:INFO:Checking exceptions
2024-12-29 10:52:13,888:INFO:Importing libraries
2024-12-29 10:52:13,888:INFO:Copying training dataset
2024-12-29 10:52:13,891:INFO:Defining folds
2024-12-29 10:52:13,891:INFO:Declaring metric variables
2024-12-29 10:52:13,895:INFO:Importing untrained model
2024-12-29 10:52:13,899:INFO:Random Forest Classifier Imported successfully
2024-12-29 10:52:13,905:INFO:Starting cross validation
2024-12-29 10:52:13,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:14,183:INFO:Calculating mean and std
2024-12-29 10:52:14,184:INFO:Creating metrics dataframe
2024-12-29 10:52:14,186:INFO:Uploading results into container
2024-12-29 10:52:14,186:INFO:Uploading model into container now
2024-12-29 10:52:14,187:INFO:_master_model_container: 7
2024-12-29 10:52:14,187:INFO:_display_container: 2
2024-12-29 10:52:14,188:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7209, verbose=0,
                       warm_start=False)
2024-12-29 10:52:14,188:INFO:create_model() successfully completed......................................
2024-12-29 10:52:14,391:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:14,392:INFO:Creating metrics dataframe
2024-12-29 10:52:14,399:INFO:Initializing Quadratic Discriminant Analysis
2024-12-29 10:52:14,399:INFO:Total runtime is 0.11469939152399698 minutes
2024-12-29 10:52:14,402:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:14,402:INFO:Initializing create_model()
2024-12-29 10:52:14,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:14,402:INFO:Checking exceptions
2024-12-29 10:52:14,403:INFO:Importing libraries
2024-12-29 10:52:14,403:INFO:Copying training dataset
2024-12-29 10:52:14,406:INFO:Defining folds
2024-12-29 10:52:14,406:INFO:Declaring metric variables
2024-12-29 10:52:14,409:INFO:Importing untrained model
2024-12-29 10:52:14,413:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-29 10:52:14,419:INFO:Starting cross validation
2024-12-29 10:52:14,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:14,502:INFO:Calculating mean and std
2024-12-29 10:52:14,503:INFO:Creating metrics dataframe
2024-12-29 10:52:14,504:INFO:Uploading results into container
2024-12-29 10:52:14,504:INFO:Uploading model into container now
2024-12-29 10:52:14,504:INFO:_master_model_container: 8
2024-12-29 10:52:14,505:INFO:_display_container: 2
2024-12-29 10:52:14,505:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-29 10:52:14,505:INFO:create_model() successfully completed......................................
2024-12-29 10:52:14,704:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:14,705:INFO:Creating metrics dataframe
2024-12-29 10:52:14,712:INFO:Initializing Ada Boost Classifier
2024-12-29 10:52:14,712:INFO:Total runtime is 0.11991750001907348 minutes
2024-12-29 10:52:14,715:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:14,715:INFO:Initializing create_model()
2024-12-29 10:52:14,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:14,715:INFO:Checking exceptions
2024-12-29 10:52:14,715:INFO:Importing libraries
2024-12-29 10:52:14,715:INFO:Copying training dataset
2024-12-29 10:52:14,719:INFO:Defining folds
2024-12-29 10:52:14,719:INFO:Declaring metric variables
2024-12-29 10:52:14,722:INFO:Importing untrained model
2024-12-29 10:52:14,726:INFO:Ada Boost Classifier Imported successfully
2024-12-29 10:52:14,732:INFO:Starting cross validation
2024-12-29 10:52:14,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:14,752:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,752:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,753:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,753:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,754:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,755:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,757:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,758:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,761:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 10:52:14,894:INFO:Calculating mean and std
2024-12-29 10:52:14,896:INFO:Creating metrics dataframe
2024-12-29 10:52:14,897:INFO:Uploading results into container
2024-12-29 10:52:14,898:INFO:Uploading model into container now
2024-12-29 10:52:14,898:INFO:_master_model_container: 9
2024-12-29 10:52:14,898:INFO:_display_container: 2
2024-12-29 10:52:14,900:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7209)
2024-12-29 10:52:14,900:INFO:create_model() successfully completed......................................
2024-12-29 10:52:15,101:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:15,102:INFO:Creating metrics dataframe
2024-12-29 10:52:15,109:INFO:Initializing Gradient Boosting Classifier
2024-12-29 10:52:15,109:INFO:Total runtime is 0.12653311093648273 minutes
2024-12-29 10:52:15,112:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:15,112:INFO:Initializing create_model()
2024-12-29 10:52:15,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:15,112:INFO:Checking exceptions
2024-12-29 10:52:15,112:INFO:Importing libraries
2024-12-29 10:52:15,112:INFO:Copying training dataset
2024-12-29 10:52:15,115:INFO:Defining folds
2024-12-29 10:52:15,115:INFO:Declaring metric variables
2024-12-29 10:52:15,119:INFO:Importing untrained model
2024-12-29 10:52:15,123:INFO:Gradient Boosting Classifier Imported successfully
2024-12-29 10:52:15,127:INFO:Starting cross validation
2024-12-29 10:52:15,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:15,296:INFO:Calculating mean and std
2024-12-29 10:52:15,297:INFO:Creating metrics dataframe
2024-12-29 10:52:15,300:INFO:Uploading results into container
2024-12-29 10:52:15,300:INFO:Uploading model into container now
2024-12-29 10:52:15,300:INFO:_master_model_container: 10
2024-12-29 10:52:15,300:INFO:_display_container: 2
2024-12-29 10:52:15,301:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7209, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-29 10:52:15,301:INFO:create_model() successfully completed......................................
2024-12-29 10:52:15,503:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:15,504:INFO:Creating metrics dataframe
2024-12-29 10:52:15,511:INFO:Initializing Linear Discriminant Analysis
2024-12-29 10:52:15,511:INFO:Total runtime is 0.13323822418848671 minutes
2024-12-29 10:52:15,513:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:15,515:INFO:Initializing create_model()
2024-12-29 10:52:15,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:15,515:INFO:Checking exceptions
2024-12-29 10:52:15,515:INFO:Importing libraries
2024-12-29 10:52:15,515:INFO:Copying training dataset
2024-12-29 10:52:15,517:INFO:Defining folds
2024-12-29 10:52:15,517:INFO:Declaring metric variables
2024-12-29 10:52:15,521:INFO:Importing untrained model
2024-12-29 10:52:15,523:INFO:Linear Discriminant Analysis Imported successfully
2024-12-29 10:52:15,528:INFO:Starting cross validation
2024-12-29 10:52:15,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:15,577:INFO:Calculating mean and std
2024-12-29 10:52:15,578:INFO:Creating metrics dataframe
2024-12-29 10:52:15,579:INFO:Uploading results into container
2024-12-29 10:52:15,579:INFO:Uploading model into container now
2024-12-29 10:52:15,580:INFO:_master_model_container: 11
2024-12-29 10:52:15,580:INFO:_display_container: 2
2024-12-29 10:52:15,580:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-29 10:52:15,580:INFO:create_model() successfully completed......................................
2024-12-29 10:52:15,780:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:15,780:INFO:Creating metrics dataframe
2024-12-29 10:52:15,788:INFO:Initializing Extra Trees Classifier
2024-12-29 10:52:15,788:INFO:Total runtime is 0.1378505746523539 minutes
2024-12-29 10:52:15,790:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:15,791:INFO:Initializing create_model()
2024-12-29 10:52:15,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:15,791:INFO:Checking exceptions
2024-12-29 10:52:15,791:INFO:Importing libraries
2024-12-29 10:52:15,791:INFO:Copying training dataset
2024-12-29 10:52:15,794:INFO:Defining folds
2024-12-29 10:52:15,794:INFO:Declaring metric variables
2024-12-29 10:52:15,798:INFO:Importing untrained model
2024-12-29 10:52:15,801:INFO:Extra Trees Classifier Imported successfully
2024-12-29 10:52:15,807:INFO:Starting cross validation
2024-12-29 10:52:15,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:16,044:INFO:Calculating mean and std
2024-12-29 10:52:16,045:INFO:Creating metrics dataframe
2024-12-29 10:52:16,047:INFO:Uploading results into container
2024-12-29 10:52:16,047:INFO:Uploading model into container now
2024-12-29 10:52:16,048:INFO:_master_model_container: 12
2024-12-29 10:52:16,048:INFO:_display_container: 2
2024-12-29 10:52:16,048:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7209, verbose=0,
                     warm_start=False)
2024-12-29 10:52:16,048:INFO:create_model() successfully completed......................................
2024-12-29 10:52:16,250:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:16,250:INFO:Creating metrics dataframe
2024-12-29 10:52:16,258:INFO:Initializing Extreme Gradient Boosting
2024-12-29 10:52:16,258:INFO:Total runtime is 0.14569348891576128 minutes
2024-12-29 10:52:16,260:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:16,261:INFO:Initializing create_model()
2024-12-29 10:52:16,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:16,261:INFO:Checking exceptions
2024-12-29 10:52:16,261:INFO:Importing libraries
2024-12-29 10:52:16,261:INFO:Copying training dataset
2024-12-29 10:52:16,264:INFO:Defining folds
2024-12-29 10:52:16,264:INFO:Declaring metric variables
2024-12-29 10:52:16,268:INFO:Importing untrained model
2024-12-29 10:52:16,270:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 10:52:16,276:INFO:Starting cross validation
2024-12-29 10:52:16,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:20,306:INFO:Calculating mean and std
2024-12-29 10:52:20,307:INFO:Creating metrics dataframe
2024-12-29 10:52:20,309:INFO:Uploading results into container
2024-12-29 10:52:20,311:INFO:Uploading model into container now
2024-12-29 10:52:20,311:INFO:_master_model_container: 13
2024-12-29 10:52:20,311:INFO:_display_container: 2
2024-12-29 10:52:20,312:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 10:52:20,312:INFO:create_model() successfully completed......................................
2024-12-29 10:52:20,590:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:20,590:INFO:Creating metrics dataframe
2024-12-29 10:52:20,601:INFO:Initializing Light Gradient Boosting Machine
2024-12-29 10:52:20,601:INFO:Total runtime is 0.21807023286819455 minutes
2024-12-29 10:52:20,604:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:20,605:INFO:Initializing create_model()
2024-12-29 10:52:20,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:20,605:INFO:Checking exceptions
2024-12-29 10:52:20,605:INFO:Importing libraries
2024-12-29 10:52:20,605:INFO:Copying training dataset
2024-12-29 10:52:20,609:INFO:Defining folds
2024-12-29 10:52:20,609:INFO:Declaring metric variables
2024-12-29 10:52:20,613:INFO:Importing untrained model
2024-12-29 10:52:20,617:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-29 10:52:20,624:INFO:Starting cross validation
2024-12-29 10:52:20,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:25,672:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-29 10:52:26,243:INFO:Calculating mean and std
2024-12-29 10:52:26,244:INFO:Creating metrics dataframe
2024-12-29 10:52:26,247:INFO:Uploading results into container
2024-12-29 10:52:26,248:INFO:Uploading model into container now
2024-12-29 10:52:26,248:INFO:_master_model_container: 14
2024-12-29 10:52:26,249:INFO:_display_container: 2
2024-12-29 10:52:26,249:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7209, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-29 10:52:26,249:INFO:create_model() successfully completed......................................
2024-12-29 10:52:26,530:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:26,530:INFO:Creating metrics dataframe
2024-12-29 10:52:26,542:INFO:Initializing CatBoost Classifier
2024-12-29 10:52:26,542:INFO:Total runtime is 0.3170969367027282 minutes
2024-12-29 10:52:26,546:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:26,546:INFO:Initializing create_model()
2024-12-29 10:52:26,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:26,546:INFO:Checking exceptions
2024-12-29 10:52:26,546:INFO:Importing libraries
2024-12-29 10:52:26,546:INFO:Copying training dataset
2024-12-29 10:52:26,550:INFO:Defining folds
2024-12-29 10:52:26,550:INFO:Declaring metric variables
2024-12-29 10:52:26,553:INFO:Importing untrained model
2024-12-29 10:52:26,556:INFO:CatBoost Classifier Imported successfully
2024-12-29 10:52:26,564:INFO:Starting cross validation
2024-12-29 10:52:26,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:30,683:INFO:Calculating mean and std
2024-12-29 10:52:30,685:INFO:Creating metrics dataframe
2024-12-29 10:52:30,687:INFO:Uploading results into container
2024-12-29 10:52:30,687:INFO:Uploading model into container now
2024-12-29 10:52:30,688:INFO:_master_model_container: 15
2024-12-29 10:52:30,688:INFO:_display_container: 2
2024-12-29 10:52:30,688:INFO:<catboost.core.CatBoostClassifier object at 0x000002053CD6B190>
2024-12-29 10:52:30,688:INFO:create_model() successfully completed......................................
2024-12-29 10:52:30,895:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:30,896:INFO:Creating metrics dataframe
2024-12-29 10:52:30,903:INFO:Initializing Dummy Classifier
2024-12-29 10:52:30,903:INFO:Total runtime is 0.3897778113683064 minutes
2024-12-29 10:52:30,907:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:30,907:INFO:Initializing create_model()
2024-12-29 10:52:30,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA6FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:30,907:INFO:Checking exceptions
2024-12-29 10:52:30,907:INFO:Importing libraries
2024-12-29 10:52:30,907:INFO:Copying training dataset
2024-12-29 10:52:30,910:INFO:Defining folds
2024-12-29 10:52:30,910:INFO:Declaring metric variables
2024-12-29 10:52:30,914:INFO:Importing untrained model
2024-12-29 10:52:30,916:INFO:Dummy Classifier Imported successfully
2024-12-29 10:52:30,923:INFO:Starting cross validation
2024-12-29 10:52:30,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:30,957:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,957:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,959:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,960:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,962:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,963:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,965:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,966:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:30,968:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:32,409:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 10:52:32,414:INFO:Calculating mean and std
2024-12-29 10:52:32,415:INFO:Creating metrics dataframe
2024-12-29 10:52:32,418:INFO:Uploading results into container
2024-12-29 10:52:32,418:INFO:Uploading model into container now
2024-12-29 10:52:32,418:INFO:_master_model_container: 16
2024-12-29 10:52:32,418:INFO:_display_container: 2
2024-12-29 10:52:32,418:INFO:DummyClassifier(constant=None, random_state=7209, strategy='prior')
2024-12-29 10:52:32,418:INFO:create_model() successfully completed......................................
2024-12-29 10:52:32,622:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:32,622:INFO:Creating metrics dataframe
2024-12-29 10:52:32,633:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-29 10:52:32,641:INFO:Initializing create_model()
2024-12-29 10:52:32,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:32,641:INFO:Checking exceptions
2024-12-29 10:52:32,644:INFO:Importing libraries
2024-12-29 10:52:32,644:INFO:Copying training dataset
2024-12-29 10:52:32,646:INFO:Defining folds
2024-12-29 10:52:32,646:INFO:Declaring metric variables
2024-12-29 10:52:32,646:INFO:Importing untrained model
2024-12-29 10:52:32,646:INFO:Declaring custom model
2024-12-29 10:52:32,647:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:52:32,647:INFO:Cross validation set to False
2024-12-29 10:52:32,647:INFO:Fitting Model
2024-12-29 10:52:32,652:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:32,652:INFO:create_model() successfully completed......................................
2024-12-29 10:52:32,880:INFO:_master_model_container: 16
2024-12-29 10:52:32,880:INFO:_display_container: 2
2024-12-29 10:52:32,880:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:32,881:INFO:compare_models() successfully completed......................................
2024-12-29 10:52:32,881:INFO:Initializing create_model()
2024-12-29 10:52:32,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:32,881:INFO:Checking exceptions
2024-12-29 10:52:32,892:INFO:Importing libraries
2024-12-29 10:52:32,892:INFO:Copying training dataset
2024-12-29 10:52:32,896:INFO:Defining folds
2024-12-29 10:52:32,896:INFO:Declaring metric variables
2024-12-29 10:52:32,900:INFO:Importing untrained model
2024-12-29 10:52:32,900:INFO:Declaring custom model
2024-12-29 10:52:32,904:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:52:32,910:INFO:Starting cross validation
2024-12-29 10:52:32,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:33,001:INFO:Calculating mean and std
2024-12-29 10:52:33,001:INFO:Creating metrics dataframe
2024-12-29 10:52:33,006:INFO:Finalizing model
2024-12-29 10:52:33,015:INFO:Uploading results into container
2024-12-29 10:52:33,015:INFO:Uploading model into container now
2024-12-29 10:52:33,024:INFO:_master_model_container: 17
2024-12-29 10:52:33,024:INFO:_display_container: 3
2024-12-29 10:52:33,025:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:33,025:INFO:create_model() successfully completed......................................
2024-12-29 10:52:33,227:INFO:Initializing tune_model()
2024-12-29 10:52:33,227:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>)
2024-12-29 10:52:33,227:INFO:Checking exceptions
2024-12-29 10:52:33,240:INFO:Copying training dataset
2024-12-29 10:52:33,242:INFO:Checking base model
2024-12-29 10:52:33,243:INFO:Base model : Decision Tree Classifier
2024-12-29 10:52:33,247:INFO:Declaring metric variables
2024-12-29 10:52:33,250:INFO:Defining Hyperparameters
2024-12-29 10:52:33,453:INFO:Tuning with n_jobs=-1
2024-12-29 10:52:33,453:INFO:Initializing RandomizedSearchCV
2024-12-29 10:52:33,661:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'entropy'}
2024-12-29 10:52:33,661:INFO:Hyperparameter search completed
2024-12-29 10:52:33,661:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:33,661:INFO:Initializing create_model()
2024-12-29 10:52:33,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020538FCBF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'entropy'})
2024-12-29 10:52:33,661:INFO:Checking exceptions
2024-12-29 10:52:33,661:INFO:Importing libraries
2024-12-29 10:52:33,661:INFO:Copying training dataset
2024-12-29 10:52:33,665:INFO:Defining folds
2024-12-29 10:52:33,665:INFO:Declaring metric variables
2024-12-29 10:52:33,667:INFO:Importing untrained model
2024-12-29 10:52:33,667:INFO:Declaring custom model
2024-12-29 10:52:33,671:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:52:33,677:INFO:Starting cross validation
2024-12-29 10:52:33,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:33,727:INFO:Calculating mean and std
2024-12-29 10:52:33,728:INFO:Creating metrics dataframe
2024-12-29 10:52:33,731:INFO:Finalizing model
2024-12-29 10:52:33,741:INFO:Uploading results into container
2024-12-29 10:52:33,742:INFO:Uploading model into container now
2024-12-29 10:52:33,742:INFO:_master_model_container: 18
2024-12-29 10:52:33,742:INFO:_display_container: 4
2024-12-29 10:52:33,744:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=8, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.001, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:33,744:INFO:create_model() successfully completed......................................
2024-12-29 10:52:33,959:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:33,959:INFO:choose_better activated
2024-12-29 10:52:33,962:INFO:SubProcess create_model() called ==================================
2024-12-29 10:52:33,963:INFO:Initializing create_model()
2024-12-29 10:52:33,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:33,963:INFO:Checking exceptions
2024-12-29 10:52:33,965:INFO:Importing libraries
2024-12-29 10:52:33,965:INFO:Copying training dataset
2024-12-29 10:52:33,967:INFO:Defining folds
2024-12-29 10:52:33,967:INFO:Declaring metric variables
2024-12-29 10:52:33,967:INFO:Importing untrained model
2024-12-29 10:52:33,968:INFO:Declaring custom model
2024-12-29 10:52:33,968:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:52:33,968:INFO:Starting cross validation
2024-12-29 10:52:33,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 10:52:34,016:INFO:Calculating mean and std
2024-12-29 10:52:34,017:INFO:Creating metrics dataframe
2024-12-29 10:52:34,019:INFO:Finalizing model
2024-12-29 10:52:34,023:INFO:Uploading results into container
2024-12-29 10:52:34,024:INFO:Uploading model into container now
2024-12-29 10:52:34,024:INFO:_master_model_container: 19
2024-12-29 10:52:34,024:INFO:_display_container: 5
2024-12-29 10:52:34,024:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:34,024:INFO:create_model() successfully completed......................................
2024-12-29 10:52:34,226:INFO:SubProcess create_model() end ==================================
2024-12-29 10:52:34,226:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best') result for Accuracy is 0.8026
2024-12-29 10:52:34,226:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=8, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.001, min_samples_leaf=4,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best') result for Accuracy is 0.8026
2024-12-29 10:52:34,227:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best') is best model
2024-12-29 10:52:34,227:INFO:choose_better completed
2024-12-29 10:52:34,227:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-29 10:52:34,235:INFO:_master_model_container: 19
2024-12-29 10:52:34,236:INFO:_display_container: 4
2024-12-29 10:52:34,236:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:34,236:INFO:tune_model() successfully completed......................................
2024-12-29 10:52:34,438:INFO:Initializing finalize_model()
2024-12-29 10:52:34,438:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 10:52:34,439:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best')
2024-12-29 10:52:34,441:INFO:Initializing create_model()
2024-12-29 10:52:34,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053AA146A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7209, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 10:52:34,441:INFO:Checking exceptions
2024-12-29 10:52:34,442:INFO:Importing libraries
2024-12-29 10:52:34,442:INFO:Copying training dataset
2024-12-29 10:52:34,442:INFO:Defining folds
2024-12-29 10:52:34,442:INFO:Declaring metric variables
2024-12-29 10:52:34,442:INFO:Importing untrained model
2024-12-29 10:52:34,442:INFO:Declaring custom model
2024-12-29 10:52:34,443:INFO:Decision Tree Classifier Imported successfully
2024-12-29 10:52:34,443:INFO:Cross validation set to False
2024-12-29 10:52:34,443:INFO:Fitting Model
2024-12-29 10:52:34,451:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=7209,
                                        splitter='best'))],
         verbose=False)
2024-12-29 10:52:34,452:INFO:create_model() successfully completed......................................
2024-12-29 10:52:34,652:INFO:_master_model_container: 19
2024-12-29 10:52:34,652:INFO:_display_container: 4
2024-12-29 10:52:34,655:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=Si...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=7209,
                                        splitter='best'))],
         verbose=False)
2024-12-29 10:52:34,655:INFO:finalize_model() successfully completed......................................
2024-12-29 11:09:34,115:INFO:PyCaret ClassificationExperiment
2024-12-29 11:09:34,115:INFO:Logging name: clf-default-name
2024-12-29 11:09:34,115:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-29 11:09:34,115:INFO:version 3.3.1
2024-12-29 11:09:34,115:INFO:Initializing setup()
2024-12-29 11:09:34,116:INFO:self.USI: bc42
2024-12-29 11:09:34,116:INFO:self._variable_keys: {'USI', '_ml_usecase', 'y_train', 'X_train', 'X', 'is_multiclass', 'pipeline', 'X_test', 'fold_groups_param', 'data', 'fix_imbalance', 'idx', 'gpu_param', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', '_available_plots', 'y_test', 'log_plots_param', 'logging_param', 'memory', 'seed', 'fold_shuffle_param', 'y', 'html_param', 'target_param', 'n_jobs_param', 'exp_name_log'}
2024-12-29 11:09:34,116:INFO:Checking environment
2024-12-29 11:09:34,116:INFO:python_version: 3.10.15
2024-12-29 11:09:34,116:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-29 11:09:34,116:INFO:machine: AMD64
2024-12-29 11:09:34,116:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-29 11:09:34,116:INFO:Memory: svmem(total=16312721408, available=6977245184, percent=57.2, used=9335476224, free=6977245184)
2024-12-29 11:09:34,116:INFO:Physical Core: 6
2024-12-29 11:09:34,116:INFO:Logical Core: 12
2024-12-29 11:09:34,116:INFO:Checking libraries
2024-12-29 11:09:34,116:INFO:System:
2024-12-29 11:09:34,116:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-29 11:09:34,116:INFO:executable: d:\Anaconda\python.exe
2024-12-29 11:09:34,116:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-29 11:09:34,116:INFO:PyCaret required dependencies:
2024-12-29 11:09:34,116:INFO:                 pip: 24.2
2024-12-29 11:09:34,116:INFO:          setuptools: 75.1.0
2024-12-29 11:09:34,116:INFO:             pycaret: 3.3.1
2024-12-29 11:09:34,116:INFO:             IPython: 8.27.0
2024-12-29 11:09:34,116:INFO:          ipywidgets: 8.1.2
2024-12-29 11:09:34,117:INFO:                tqdm: 4.66.5
2024-12-29 11:09:34,117:INFO:               numpy: 1.26.4
2024-12-29 11:09:34,117:INFO:              pandas: 2.1.4
2024-12-29 11:09:34,117:INFO:              jinja2: 3.1.4
2024-12-29 11:09:34,117:INFO:               scipy: 1.11.4
2024-12-29 11:09:34,117:INFO:              joblib: 1.2.0
2024-12-29 11:09:34,117:INFO:             sklearn: 1.4.2
2024-12-29 11:09:34,117:INFO:                pyod: 2.0.2
2024-12-29 11:09:34,117:INFO:            imblearn: 0.12.3
2024-12-29 11:09:34,117:INFO:   category_encoders: 2.6.3
2024-12-29 11:09:34,117:INFO:            lightgbm: 4.5.0
2024-12-29 11:09:34,117:INFO:               numba: 0.60.0
2024-12-29 11:09:34,117:INFO:            requests: 2.32.3
2024-12-29 11:09:34,117:INFO:          matplotlib: 3.9.2
2024-12-29 11:09:34,117:INFO:          scikitplot: 0.3.7
2024-12-29 11:09:34,117:INFO:         yellowbrick: 1.5
2024-12-29 11:09:34,117:INFO:              plotly: 5.24.1
2024-12-29 11:09:34,117:INFO:    plotly-resampler: Not installed
2024-12-29 11:09:34,117:INFO:             kaleido: 0.2.1
2024-12-29 11:09:34,117:INFO:           schemdraw: 0.15
2024-12-29 11:09:34,117:INFO:         statsmodels: 0.14.2
2024-12-29 11:09:34,117:INFO:              sktime: 0.26.0
2024-12-29 11:09:34,117:INFO:               tbats: 1.1.3
2024-12-29 11:09:34,117:INFO:            pmdarima: 2.0.4
2024-12-29 11:09:34,117:INFO:              psutil: 5.9.0
2024-12-29 11:09:34,117:INFO:          markupsafe: 2.1.3
2024-12-29 11:09:34,117:INFO:             pickle5: Not installed
2024-12-29 11:09:34,117:INFO:         cloudpickle: 3.0.0
2024-12-29 11:09:34,117:INFO:         deprecation: 2.1.0
2024-12-29 11:09:34,117:INFO:              xxhash: 2.0.2
2024-12-29 11:09:34,117:INFO:           wurlitzer: 3.1.1
2024-12-29 11:09:34,117:INFO:PyCaret optional dependencies:
2024-12-29 11:09:34,118:INFO:                shap: Not installed
2024-12-29 11:09:34,118:INFO:           interpret: Not installed
2024-12-29 11:09:34,118:INFO:                umap: 0.5.3
2024-12-29 11:09:34,118:INFO:     ydata_profiling: Not installed
2024-12-29 11:09:34,118:INFO:  explainerdashboard: Not installed
2024-12-29 11:09:34,118:INFO:             autoviz: Not installed
2024-12-29 11:09:34,118:INFO:           fairlearn: Not installed
2024-12-29 11:09:34,118:INFO:          deepchecks: Not installed
2024-12-29 11:09:34,118:INFO:             xgboost: 2.1.2
2024-12-29 11:09:34,118:INFO:            catboost: 1.2.3
2024-12-29 11:09:34,118:INFO:              kmodes: 0.12.2
2024-12-29 11:09:34,118:INFO:             mlxtend: 0.23.1
2024-12-29 11:09:34,118:INFO:       statsforecast: Not installed
2024-12-29 11:09:34,118:INFO:        tune_sklearn: Not installed
2024-12-29 11:09:34,118:INFO:                 ray: Not installed
2024-12-29 11:09:34,118:INFO:            hyperopt: Not installed
2024-12-29 11:09:34,118:INFO:              optuna: Not installed
2024-12-29 11:09:34,118:INFO:               skopt: Not installed
2024-12-29 11:09:34,118:INFO:              mlflow: 2.16.2
2024-12-29 11:09:34,118:INFO:              gradio: Not installed
2024-12-29 11:09:34,118:INFO:             fastapi: Not installed
2024-12-29 11:09:34,118:INFO:             uvicorn: Not installed
2024-12-29 11:09:34,118:INFO:              m2cgen: Not installed
2024-12-29 11:09:34,118:INFO:           evidently: Not installed
2024-12-29 11:09:34,118:INFO:               fugue: Not installed
2024-12-29 11:09:34,118:INFO:           streamlit: Not installed
2024-12-29 11:09:34,118:INFO:             prophet: Not installed
2024-12-29 11:09:34,119:INFO:None
2024-12-29 11:09:34,119:INFO:Set up data.
2024-12-29 11:09:34,121:INFO:Set up folding strategy.
2024-12-29 11:09:34,121:INFO:Set up train/test split.
2024-12-29 11:09:34,127:INFO:Set up index.
2024-12-29 11:09:34,128:INFO:Assigning column types.
2024-12-29 11:09:34,130:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-29 11:09:34,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 11:09:34,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:09:34,197:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,200:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,241:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 11:09:34,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:09:34,267:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,269:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,270:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-29 11:09:34,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:09:34,334:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,336:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:09:34,393:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,395:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,395:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-29 11:09:34,454:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,456:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,513:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,516:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,518:INFO:Preparing preprocessing pipeline...
2024-12-29 11:09:34,518:INFO:Set up simple imputation.
2024-12-29 11:09:34,530:INFO:Finished creating preprocessing pipeline.
2024-12-29 11:09:34,532:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'Pclass',
                                             'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-29 11:09:34,532:INFO:Creating final display dataframe.
2024-12-29 11:09:34,577:INFO:Setup _display_container:                     Description             Value
0                    Session id              4763
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 5)
4        Transformed data shape          (891, 5)
5   Transformed train set shape          (623, 5)
6    Transformed test set shape          (268, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bc42
2024-12-29 11:09:34,641:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,643:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,710:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:09:34,712:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:09:34,713:INFO:setup() successfully completed in 0.6s...............
2024-12-29 11:09:34,715:INFO:Initializing compare_models()
2024-12-29 11:09:34,715:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-29 11:09:34,715:INFO:Checking exceptions
2024-12-29 11:09:34,717:INFO:Preparing display monitor
2024-12-29 11:09:34,736:INFO:Initializing Logistic Regression
2024-12-29 11:09:34,736:INFO:Total runtime is 0.0 minutes
2024-12-29 11:09:34,739:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:34,739:INFO:Initializing create_model()
2024-12-29 11:09:34,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:34,739:INFO:Checking exceptions
2024-12-29 11:09:34,740:INFO:Importing libraries
2024-12-29 11:09:34,740:INFO:Copying training dataset
2024-12-29 11:09:34,745:INFO:Defining folds
2024-12-29 11:09:34,745:INFO:Declaring metric variables
2024-12-29 11:09:34,747:INFO:Importing untrained model
2024-12-29 11:09:34,750:INFO:Logistic Regression Imported successfully
2024-12-29 11:09:34,756:INFO:Starting cross validation
2024-12-29 11:09:34,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:37,923:INFO:Calculating mean and std
2024-12-29 11:09:37,925:INFO:Creating metrics dataframe
2024-12-29 11:09:37,928:INFO:Uploading results into container
2024-12-29 11:09:37,929:INFO:Uploading model into container now
2024-12-29 11:09:37,929:INFO:_master_model_container: 1
2024-12-29 11:09:37,929:INFO:_display_container: 2
2024-12-29 11:09:37,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4763, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 11:09:37,930:INFO:create_model() successfully completed......................................
2024-12-29 11:09:38,156:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:38,157:INFO:Creating metrics dataframe
2024-12-29 11:09:38,161:INFO:Initializing K Neighbors Classifier
2024-12-29 11:09:38,162:INFO:Total runtime is 0.05710256497065226 minutes
2024-12-29 11:09:38,165:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:38,165:INFO:Initializing create_model()
2024-12-29 11:09:38,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:38,165:INFO:Checking exceptions
2024-12-29 11:09:38,165:INFO:Importing libraries
2024-12-29 11:09:38,165:INFO:Copying training dataset
2024-12-29 11:09:38,168:INFO:Defining folds
2024-12-29 11:09:38,168:INFO:Declaring metric variables
2024-12-29 11:09:38,172:INFO:Importing untrained model
2024-12-29 11:09:38,175:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:09:38,179:INFO:Starting cross validation
2024-12-29 11:09:38,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:39,774:INFO:Calculating mean and std
2024-12-29 11:09:39,776:INFO:Creating metrics dataframe
2024-12-29 11:09:39,778:INFO:Uploading results into container
2024-12-29 11:09:39,778:INFO:Uploading model into container now
2024-12-29 11:09:39,779:INFO:_master_model_container: 2
2024-12-29 11:09:39,779:INFO:_display_container: 2
2024-12-29 11:09:39,779:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:09:39,779:INFO:create_model() successfully completed......................................
2024-12-29 11:09:39,990:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:39,990:INFO:Creating metrics dataframe
2024-12-29 11:09:39,995:INFO:Initializing Naive Bayes
2024-12-29 11:09:39,996:INFO:Total runtime is 0.08766578435897827 minutes
2024-12-29 11:09:39,998:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:39,999:INFO:Initializing create_model()
2024-12-29 11:09:39,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:39,999:INFO:Checking exceptions
2024-12-29 11:09:39,999:INFO:Importing libraries
2024-12-29 11:09:39,999:INFO:Copying training dataset
2024-12-29 11:09:40,002:INFO:Defining folds
2024-12-29 11:09:40,002:INFO:Declaring metric variables
2024-12-29 11:09:40,005:INFO:Importing untrained model
2024-12-29 11:09:40,008:INFO:Naive Bayes Imported successfully
2024-12-29 11:09:40,015:INFO:Starting cross validation
2024-12-29 11:09:40,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:40,091:INFO:Calculating mean and std
2024-12-29 11:09:40,093:INFO:Creating metrics dataframe
2024-12-29 11:09:40,094:INFO:Uploading results into container
2024-12-29 11:09:40,094:INFO:Uploading model into container now
2024-12-29 11:09:40,095:INFO:_master_model_container: 3
2024-12-29 11:09:40,095:INFO:_display_container: 2
2024-12-29 11:09:40,095:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-29 11:09:40,095:INFO:create_model() successfully completed......................................
2024-12-29 11:09:40,301:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:40,301:INFO:Creating metrics dataframe
2024-12-29 11:09:40,307:INFO:Initializing Decision Tree Classifier
2024-12-29 11:09:40,307:INFO:Total runtime is 0.09285221894582113 minutes
2024-12-29 11:09:40,311:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:40,312:INFO:Initializing create_model()
2024-12-29 11:09:40,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:40,312:INFO:Checking exceptions
2024-12-29 11:09:40,312:INFO:Importing libraries
2024-12-29 11:09:40,312:INFO:Copying training dataset
2024-12-29 11:09:40,315:INFO:Defining folds
2024-12-29 11:09:40,315:INFO:Declaring metric variables
2024-12-29 11:09:40,319:INFO:Importing untrained model
2024-12-29 11:09:40,323:INFO:Decision Tree Classifier Imported successfully
2024-12-29 11:09:40,329:INFO:Starting cross validation
2024-12-29 11:09:40,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:40,379:INFO:Calculating mean and std
2024-12-29 11:09:40,380:INFO:Creating metrics dataframe
2024-12-29 11:09:40,381:INFO:Uploading results into container
2024-12-29 11:09:40,382:INFO:Uploading model into container now
2024-12-29 11:09:40,382:INFO:_master_model_container: 4
2024-12-29 11:09:40,382:INFO:_display_container: 2
2024-12-29 11:09:40,382:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4763, splitter='best')
2024-12-29 11:09:40,382:INFO:create_model() successfully completed......................................
2024-12-29 11:09:40,589:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:40,590:INFO:Creating metrics dataframe
2024-12-29 11:09:40,595:INFO:Initializing SVM - Linear Kernel
2024-12-29 11:09:40,595:INFO:Total runtime is 0.0976512869199117 minutes
2024-12-29 11:09:40,600:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:40,600:INFO:Initializing create_model()
2024-12-29 11:09:40,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:40,600:INFO:Checking exceptions
2024-12-29 11:09:40,600:INFO:Importing libraries
2024-12-29 11:09:40,600:INFO:Copying training dataset
2024-12-29 11:09:40,603:INFO:Defining folds
2024-12-29 11:09:40,603:INFO:Declaring metric variables
2024-12-29 11:09:40,606:INFO:Importing untrained model
2024-12-29 11:09:40,609:INFO:SVM - Linear Kernel Imported successfully
2024-12-29 11:09:40,615:INFO:Starting cross validation
2024-12-29 11:09:40,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:40,667:INFO:Calculating mean and std
2024-12-29 11:09:40,668:INFO:Creating metrics dataframe
2024-12-29 11:09:40,670:INFO:Uploading results into container
2024-12-29 11:09:40,670:INFO:Uploading model into container now
2024-12-29 11:09:40,670:INFO:_master_model_container: 5
2024-12-29 11:09:40,670:INFO:_display_container: 2
2024-12-29 11:09:40,671:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4763, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-29 11:09:40,671:INFO:create_model() successfully completed......................................
2024-12-29 11:09:40,877:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:40,877:INFO:Creating metrics dataframe
2024-12-29 11:09:40,883:INFO:Initializing Ridge Classifier
2024-12-29 11:09:40,883:INFO:Total runtime is 0.10244845549265544 minutes
2024-12-29 11:09:40,886:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:40,886:INFO:Initializing create_model()
2024-12-29 11:09:40,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:40,886:INFO:Checking exceptions
2024-12-29 11:09:40,886:INFO:Importing libraries
2024-12-29 11:09:40,886:INFO:Copying training dataset
2024-12-29 11:09:40,890:INFO:Defining folds
2024-12-29 11:09:40,890:INFO:Declaring metric variables
2024-12-29 11:09:40,892:INFO:Importing untrained model
2024-12-29 11:09:40,897:INFO:Ridge Classifier Imported successfully
2024-12-29 11:09:40,902:INFO:Starting cross validation
2024-12-29 11:09:40,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:40,966:INFO:Calculating mean and std
2024-12-29 11:09:40,968:INFO:Creating metrics dataframe
2024-12-29 11:09:40,969:INFO:Uploading results into container
2024-12-29 11:09:40,969:INFO:Uploading model into container now
2024-12-29 11:09:40,970:INFO:_master_model_container: 6
2024-12-29 11:09:40,970:INFO:_display_container: 2
2024-12-29 11:09:40,970:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4763, solver='auto',
                tol=0.0001)
2024-12-29 11:09:40,970:INFO:create_model() successfully completed......................................
2024-12-29 11:09:41,172:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:41,172:INFO:Creating metrics dataframe
2024-12-29 11:09:41,179:INFO:Initializing Random Forest Classifier
2024-12-29 11:09:41,180:INFO:Total runtime is 0.10739473899205526 minutes
2024-12-29 11:09:41,182:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:41,183:INFO:Initializing create_model()
2024-12-29 11:09:41,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:41,183:INFO:Checking exceptions
2024-12-29 11:09:41,183:INFO:Importing libraries
2024-12-29 11:09:41,184:INFO:Copying training dataset
2024-12-29 11:09:41,186:INFO:Defining folds
2024-12-29 11:09:41,187:INFO:Declaring metric variables
2024-12-29 11:09:41,190:INFO:Importing untrained model
2024-12-29 11:09:41,194:INFO:Random Forest Classifier Imported successfully
2024-12-29 11:09:41,200:INFO:Starting cross validation
2024-12-29 11:09:41,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:41,481:INFO:Calculating mean and std
2024-12-29 11:09:41,482:INFO:Creating metrics dataframe
2024-12-29 11:09:41,484:INFO:Uploading results into container
2024-12-29 11:09:41,484:INFO:Uploading model into container now
2024-12-29 11:09:41,485:INFO:_master_model_container: 7
2024-12-29 11:09:41,485:INFO:_display_container: 2
2024-12-29 11:09:41,485:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4763, verbose=0,
                       warm_start=False)
2024-12-29 11:09:41,485:INFO:create_model() successfully completed......................................
2024-12-29 11:09:41,693:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:41,693:INFO:Creating metrics dataframe
2024-12-29 11:09:41,701:INFO:Initializing Quadratic Discriminant Analysis
2024-12-29 11:09:41,701:INFO:Total runtime is 0.11607269048690796 minutes
2024-12-29 11:09:41,704:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:41,704:INFO:Initializing create_model()
2024-12-29 11:09:41,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:41,705:INFO:Checking exceptions
2024-12-29 11:09:41,705:INFO:Importing libraries
2024-12-29 11:09:41,705:INFO:Copying training dataset
2024-12-29 11:09:41,708:INFO:Defining folds
2024-12-29 11:09:41,708:INFO:Declaring metric variables
2024-12-29 11:09:41,710:INFO:Importing untrained model
2024-12-29 11:09:41,713:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-29 11:09:41,719:INFO:Starting cross validation
2024-12-29 11:09:41,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:41,772:INFO:Calculating mean and std
2024-12-29 11:09:41,772:INFO:Creating metrics dataframe
2024-12-29 11:09:41,774:INFO:Uploading results into container
2024-12-29 11:09:41,774:INFO:Uploading model into container now
2024-12-29 11:09:41,774:INFO:_master_model_container: 8
2024-12-29 11:09:41,775:INFO:_display_container: 2
2024-12-29 11:09:41,775:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-29 11:09:41,775:INFO:create_model() successfully completed......................................
2024-12-29 11:09:41,976:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:41,976:INFO:Creating metrics dataframe
2024-12-29 11:09:41,983:INFO:Initializing Ada Boost Classifier
2024-12-29 11:09:41,984:INFO:Total runtime is 0.12080001433690389 minutes
2024-12-29 11:09:41,987:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:41,987:INFO:Initializing create_model()
2024-12-29 11:09:41,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:41,987:INFO:Checking exceptions
2024-12-29 11:09:41,987:INFO:Importing libraries
2024-12-29 11:09:41,988:INFO:Copying training dataset
2024-12-29 11:09:41,991:INFO:Defining folds
2024-12-29 11:09:41,991:INFO:Declaring metric variables
2024-12-29 11:09:41,994:INFO:Importing untrained model
2024-12-29 11:09:41,997:INFO:Ada Boost Classifier Imported successfully
2024-12-29 11:09:42,004:INFO:Starting cross validation
2024-12-29 11:09:42,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:42,024:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,025:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,027:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,027:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,028:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,028:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,029:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,030:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,030:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,031:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:09:42,159:INFO:Calculating mean and std
2024-12-29 11:09:42,160:INFO:Creating metrics dataframe
2024-12-29 11:09:42,162:INFO:Uploading results into container
2024-12-29 11:09:42,162:INFO:Uploading model into container now
2024-12-29 11:09:42,163:INFO:_master_model_container: 9
2024-12-29 11:09:42,163:INFO:_display_container: 2
2024-12-29 11:09:42,163:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4763)
2024-12-29 11:09:42,163:INFO:create_model() successfully completed......................................
2024-12-29 11:09:42,367:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:42,367:INFO:Creating metrics dataframe
2024-12-29 11:09:42,375:INFO:Initializing Gradient Boosting Classifier
2024-12-29 11:09:42,375:INFO:Total runtime is 0.12730615536371867 minutes
2024-12-29 11:09:42,377:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:42,377:INFO:Initializing create_model()
2024-12-29 11:09:42,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:42,378:INFO:Checking exceptions
2024-12-29 11:09:42,378:INFO:Importing libraries
2024-12-29 11:09:42,378:INFO:Copying training dataset
2024-12-29 11:09:42,381:INFO:Defining folds
2024-12-29 11:09:42,381:INFO:Declaring metric variables
2024-12-29 11:09:42,384:INFO:Importing untrained model
2024-12-29 11:09:42,387:INFO:Gradient Boosting Classifier Imported successfully
2024-12-29 11:09:42,392:INFO:Starting cross validation
2024-12-29 11:09:42,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:42,573:INFO:Calculating mean and std
2024-12-29 11:09:42,573:INFO:Creating metrics dataframe
2024-12-29 11:09:42,575:INFO:Uploading results into container
2024-12-29 11:09:42,575:INFO:Uploading model into container now
2024-12-29 11:09:42,575:INFO:_master_model_container: 10
2024-12-29 11:09:42,575:INFO:_display_container: 2
2024-12-29 11:09:42,577:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4763, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-29 11:09:42,577:INFO:create_model() successfully completed......................................
2024-12-29 11:09:42,779:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:42,779:INFO:Creating metrics dataframe
2024-12-29 11:09:42,786:INFO:Initializing Linear Discriminant Analysis
2024-12-29 11:09:42,786:INFO:Total runtime is 0.1341694196065267 minutes
2024-12-29 11:09:42,789:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:42,789:INFO:Initializing create_model()
2024-12-29 11:09:42,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:42,789:INFO:Checking exceptions
2024-12-29 11:09:42,789:INFO:Importing libraries
2024-12-29 11:09:42,789:INFO:Copying training dataset
2024-12-29 11:09:42,792:INFO:Defining folds
2024-12-29 11:09:42,792:INFO:Declaring metric variables
2024-12-29 11:09:42,796:INFO:Importing untrained model
2024-12-29 11:09:42,799:INFO:Linear Discriminant Analysis Imported successfully
2024-12-29 11:09:42,803:INFO:Starting cross validation
2024-12-29 11:09:42,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:42,859:INFO:Calculating mean and std
2024-12-29 11:09:42,860:INFO:Creating metrics dataframe
2024-12-29 11:09:42,862:INFO:Uploading results into container
2024-12-29 11:09:42,862:INFO:Uploading model into container now
2024-12-29 11:09:42,862:INFO:_master_model_container: 11
2024-12-29 11:09:42,862:INFO:_display_container: 2
2024-12-29 11:09:42,863:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-29 11:09:42,863:INFO:create_model() successfully completed......................................
2024-12-29 11:09:43,064:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:43,064:INFO:Creating metrics dataframe
2024-12-29 11:09:43,072:INFO:Initializing Extra Trees Classifier
2024-12-29 11:09:43,072:INFO:Total runtime is 0.138928496837616 minutes
2024-12-29 11:09:43,075:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:43,075:INFO:Initializing create_model()
2024-12-29 11:09:43,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:43,075:INFO:Checking exceptions
2024-12-29 11:09:43,075:INFO:Importing libraries
2024-12-29 11:09:43,075:INFO:Copying training dataset
2024-12-29 11:09:43,078:INFO:Defining folds
2024-12-29 11:09:43,078:INFO:Declaring metric variables
2024-12-29 11:09:43,081:INFO:Importing untrained model
2024-12-29 11:09:43,085:INFO:Extra Trees Classifier Imported successfully
2024-12-29 11:09:43,091:INFO:Starting cross validation
2024-12-29 11:09:43,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:43,326:INFO:Calculating mean and std
2024-12-29 11:09:43,328:INFO:Creating metrics dataframe
2024-12-29 11:09:43,330:INFO:Uploading results into container
2024-12-29 11:09:43,330:INFO:Uploading model into container now
2024-12-29 11:09:43,330:INFO:_master_model_container: 12
2024-12-29 11:09:43,331:INFO:_display_container: 2
2024-12-29 11:09:43,331:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4763, verbose=0,
                     warm_start=False)
2024-12-29 11:09:43,331:INFO:create_model() successfully completed......................................
2024-12-29 11:09:43,537:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:43,537:INFO:Creating metrics dataframe
2024-12-29 11:09:43,545:INFO:Initializing Extreme Gradient Boosting
2024-12-29 11:09:43,545:INFO:Total runtime is 0.14681788285573324 minutes
2024-12-29 11:09:43,548:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:43,548:INFO:Initializing create_model()
2024-12-29 11:09:43,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:43,549:INFO:Checking exceptions
2024-12-29 11:09:43,549:INFO:Importing libraries
2024-12-29 11:09:43,549:INFO:Copying training dataset
2024-12-29 11:09:43,552:INFO:Defining folds
2024-12-29 11:09:43,552:INFO:Declaring metric variables
2024-12-29 11:09:43,556:INFO:Importing untrained model
2024-12-29 11:09:43,559:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:09:43,565:INFO:Starting cross validation
2024-12-29 11:09:43,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:45,919:INFO:Calculating mean and std
2024-12-29 11:09:45,921:INFO:Creating metrics dataframe
2024-12-29 11:09:45,924:INFO:Uploading results into container
2024-12-29 11:09:45,924:INFO:Uploading model into container now
2024-12-29 11:09:45,925:INFO:_master_model_container: 13
2024-12-29 11:09:45,925:INFO:_display_container: 2
2024-12-29 11:09:45,929:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:09:45,930:INFO:create_model() successfully completed......................................
2024-12-29 11:09:46,186:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:46,186:INFO:Creating metrics dataframe
2024-12-29 11:09:46,196:INFO:Initializing Light Gradient Boosting Machine
2024-12-29 11:09:46,196:INFO:Total runtime is 0.1909952203432719 minutes
2024-12-29 11:09:46,200:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:46,201:INFO:Initializing create_model()
2024-12-29 11:09:46,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:46,201:INFO:Checking exceptions
2024-12-29 11:09:46,201:INFO:Importing libraries
2024-12-29 11:09:46,201:INFO:Copying training dataset
2024-12-29 11:09:46,206:INFO:Defining folds
2024-12-29 11:09:46,206:INFO:Declaring metric variables
2024-12-29 11:09:46,210:INFO:Importing untrained model
2024-12-29 11:09:46,214:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-29 11:09:46,222:INFO:Starting cross validation
2024-12-29 11:09:46,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:47,492:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-29 11:09:49,542:INFO:Calculating mean and std
2024-12-29 11:09:49,543:INFO:Creating metrics dataframe
2024-12-29 11:09:49,545:INFO:Uploading results into container
2024-12-29 11:09:49,546:INFO:Uploading model into container now
2024-12-29 11:09:49,546:INFO:_master_model_container: 14
2024-12-29 11:09:49,546:INFO:_display_container: 2
2024-12-29 11:09:49,547:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4763, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-29 11:09:49,547:INFO:create_model() successfully completed......................................
2024-12-29 11:09:49,794:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:49,794:INFO:Creating metrics dataframe
2024-12-29 11:09:49,804:INFO:Initializing CatBoost Classifier
2024-12-29 11:09:49,804:INFO:Total runtime is 0.25112272103627525 minutes
2024-12-29 11:09:49,806:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:49,807:INFO:Initializing create_model()
2024-12-29 11:09:49,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:49,807:INFO:Checking exceptions
2024-12-29 11:09:49,807:INFO:Importing libraries
2024-12-29 11:09:49,807:INFO:Copying training dataset
2024-12-29 11:09:49,812:INFO:Defining folds
2024-12-29 11:09:49,814:INFO:Declaring metric variables
2024-12-29 11:09:49,817:INFO:Importing untrained model
2024-12-29 11:09:49,822:INFO:CatBoost Classifier Imported successfully
2024-12-29 11:09:49,829:INFO:Starting cross validation
2024-12-29 11:09:49,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:54,881:INFO:Calculating mean and std
2024-12-29 11:09:54,882:INFO:Creating metrics dataframe
2024-12-29 11:09:54,884:INFO:Uploading results into container
2024-12-29 11:09:54,885:INFO:Uploading model into container now
2024-12-29 11:09:54,885:INFO:_master_model_container: 15
2024-12-29 11:09:54,885:INFO:_display_container: 2
2024-12-29 11:09:54,885:INFO:<catboost.core.CatBoostClassifier object at 0x000002053969DCC0>
2024-12-29 11:09:54,885:INFO:create_model() successfully completed......................................
2024-12-29 11:09:55,106:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:55,106:INFO:Creating metrics dataframe
2024-12-29 11:09:55,115:INFO:Initializing Dummy Classifier
2024-12-29 11:09:55,115:INFO:Total runtime is 0.33965349594752 minutes
2024-12-29 11:09:55,119:INFO:SubProcess create_model() called ==================================
2024-12-29 11:09:55,119:INFO:Initializing create_model()
2024-12-29 11:09:55,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AB7CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:55,119:INFO:Checking exceptions
2024-12-29 11:09:55,119:INFO:Importing libraries
2024-12-29 11:09:55,119:INFO:Copying training dataset
2024-12-29 11:09:55,123:INFO:Defining folds
2024-12-29 11:09:55,123:INFO:Declaring metric variables
2024-12-29 11:09:55,127:INFO:Importing untrained model
2024-12-29 11:09:55,130:INFO:Dummy Classifier Imported successfully
2024-12-29 11:09:55,134:INFO:Starting cross validation
2024-12-29 11:09:55,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:09:55,173:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,175:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,177:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,179:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,180:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,181:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,181:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:55,181:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:56,683:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:56,684:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:09:56,688:INFO:Calculating mean and std
2024-12-29 11:09:56,691:INFO:Creating metrics dataframe
2024-12-29 11:09:56,692:INFO:Uploading results into container
2024-12-29 11:09:56,692:INFO:Uploading model into container now
2024-12-29 11:09:56,693:INFO:_master_model_container: 16
2024-12-29 11:09:56,693:INFO:_display_container: 2
2024-12-29 11:09:56,693:INFO:DummyClassifier(constant=None, random_state=4763, strategy='prior')
2024-12-29 11:09:56,693:INFO:create_model() successfully completed......................................
2024-12-29 11:09:56,906:INFO:SubProcess create_model() end ==================================
2024-12-29 11:09:56,906:INFO:Creating metrics dataframe
2024-12-29 11:09:56,916:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-29 11:09:56,925:INFO:Initializing create_model()
2024-12-29 11:09:56,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:56,925:INFO:Checking exceptions
2024-12-29 11:09:56,927:INFO:Importing libraries
2024-12-29 11:09:56,927:INFO:Copying training dataset
2024-12-29 11:09:56,931:INFO:Defining folds
2024-12-29 11:09:56,931:INFO:Declaring metric variables
2024-12-29 11:09:56,931:INFO:Importing untrained model
2024-12-29 11:09:56,931:INFO:Declaring custom model
2024-12-29 11:09:56,933:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:09:56,933:INFO:Cross validation set to False
2024-12-29 11:09:56,933:INFO:Fitting Model
2024-12-29 11:09:58,523:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:09:58,523:INFO:create_model() successfully completed......................................
2024-12-29 11:09:58,765:INFO:_master_model_container: 16
2024-12-29 11:09:58,765:INFO:_display_container: 2
2024-12-29 11:09:58,766:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:09:58,766:INFO:compare_models() successfully completed......................................
2024-12-29 11:09:58,767:INFO:Initializing create_model()
2024-12-29 11:09:58,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:09:58,768:INFO:Checking exceptions
2024-12-29 11:09:58,779:INFO:Importing libraries
2024-12-29 11:09:58,779:INFO:Copying training dataset
2024-12-29 11:09:58,783:INFO:Defining folds
2024-12-29 11:09:58,784:INFO:Declaring metric variables
2024-12-29 11:09:58,786:INFO:Importing untrained model
2024-12-29 11:09:58,787:INFO:Declaring custom model
2024-12-29 11:09:58,791:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:09:58,796:INFO:Starting cross validation
2024-12-29 11:09:58,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:10:00,756:INFO:Calculating mean and std
2024-12-29 11:10:00,757:INFO:Creating metrics dataframe
2024-12-29 11:10:00,763:INFO:Finalizing model
2024-12-29 11:10:00,814:INFO:Uploading results into container
2024-12-29 11:10:00,815:INFO:Uploading model into container now
2024-12-29 11:10:00,829:INFO:_master_model_container: 17
2024-12-29 11:10:00,829:INFO:_display_container: 3
2024-12-29 11:10:00,830:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:10:00,830:INFO:create_model() successfully completed......................................
2024-12-29 11:10:01,068:INFO:Initializing tune_model()
2024-12-29 11:10:01,068:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>)
2024-12-29 11:10:01,069:INFO:Checking exceptions
2024-12-29 11:10:01,082:INFO:Copying training dataset
2024-12-29 11:10:01,085:INFO:Checking base model
2024-12-29 11:10:01,086:INFO:Base model : Extreme Gradient Boosting
2024-12-29 11:10:01,089:INFO:Declaring metric variables
2024-12-29 11:10:01,092:INFO:Defining Hyperparameters
2024-12-29 11:10:01,324:INFO:Tuning with n_jobs=-1
2024-12-29 11:10:01,324:INFO:Initializing RandomizedSearchCV
2024-12-29 11:10:02,311:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-29 11:10:08,362:INFO:best_params: {'actual_estimator__subsample': 0.5, 'actual_estimator__scale_pos_weight': 19.3, 'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_child_weight': 2, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__colsample_bytree': 0.9}
2024-12-29 11:10:08,363:INFO:Hyperparameter search completed
2024-12-29 11:10:08,363:INFO:SubProcess create_model() called ==================================
2024-12-29 11:10:08,364:INFO:Initializing create_model()
2024-12-29 11:10:08,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020538FCB970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.5, 'scale_pos_weight': 19.3, 'reg_lambda': 0.05, 'reg_alpha': 0.0001, 'n_estimators': 250, 'min_child_weight': 2, 'max_depth': 10, 'learning_rate': 0.5, 'colsample_bytree': 0.9})
2024-12-29 11:10:08,364:INFO:Checking exceptions
2024-12-29 11:10:08,364:INFO:Importing libraries
2024-12-29 11:10:08,364:INFO:Copying training dataset
2024-12-29 11:10:08,367:INFO:Defining folds
2024-12-29 11:10:08,367:INFO:Declaring metric variables
2024-12-29 11:10:08,370:INFO:Importing untrained model
2024-12-29 11:10:08,370:INFO:Declaring custom model
2024-12-29 11:10:08,375:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:10:08,380:INFO:Starting cross validation
2024-12-29 11:10:08,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:10:08,556:INFO:Calculating mean and std
2024-12-29 11:10:08,557:INFO:Creating metrics dataframe
2024-12-29 11:10:08,561:INFO:Finalizing model
2024-12-29 11:10:08,684:INFO:Uploading results into container
2024-12-29 11:10:08,685:INFO:Uploading model into container now
2024-12-29 11:10:08,686:INFO:_master_model_container: 18
2024-12-29 11:10:08,686:INFO:_display_container: 4
2024-12-29 11:10:08,688:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.5, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=250, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:10:08,688:INFO:create_model() successfully completed......................................
2024-12-29 11:10:08,927:INFO:SubProcess create_model() end ==================================
2024-12-29 11:10:08,927:INFO:choose_better activated
2024-12-29 11:10:08,930:INFO:SubProcess create_model() called ==================================
2024-12-29 11:10:08,932:INFO:Initializing create_model()
2024-12-29 11:10:08,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:10:08,932:INFO:Checking exceptions
2024-12-29 11:10:08,934:INFO:Importing libraries
2024-12-29 11:10:08,934:INFO:Copying training dataset
2024-12-29 11:10:08,936:INFO:Defining folds
2024-12-29 11:10:08,936:INFO:Declaring metric variables
2024-12-29 11:10:08,936:INFO:Importing untrained model
2024-12-29 11:10:08,936:INFO:Declaring custom model
2024-12-29 11:10:08,937:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:10:08,937:INFO:Starting cross validation
2024-12-29 11:10:08,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:10:09,039:INFO:Calculating mean and std
2024-12-29 11:10:09,040:INFO:Creating metrics dataframe
2024-12-29 11:10:09,041:INFO:Finalizing model
2024-12-29 11:10:09,078:INFO:Uploading results into container
2024-12-29 11:10:09,079:INFO:Uploading model into container now
2024-12-29 11:10:09,079:INFO:_master_model_container: 19
2024-12-29 11:10:09,079:INFO:_display_container: 5
2024-12-29 11:10:09,080:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:10:09,080:INFO:create_model() successfully completed......................................
2024-12-29 11:10:09,301:INFO:SubProcess create_model() end ==================================
2024-12-29 11:10:09,301:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.825
2024-12-29 11:10:09,302:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.5, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=250, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.6259
2024-12-29 11:10:09,303:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2024-12-29 11:10:09,303:INFO:choose_better completed
2024-12-29 11:10:09,303:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-29 11:10:09,311:INFO:_master_model_container: 19
2024-12-29 11:10:09,311:INFO:_display_container: 4
2024-12-29 11:10:09,312:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:10:09,312:INFO:tune_model() successfully completed......................................
2024-12-29 11:10:09,516:INFO:Initializing finalize_model()
2024-12-29 11:10:09,516:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 11:10:09,516:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:10:09,519:INFO:Initializing create_model()
2024-12-29 11:10:09,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053BFF7F40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:10:09,519:INFO:Checking exceptions
2024-12-29 11:10:09,522:INFO:Importing libraries
2024-12-29 11:10:09,522:INFO:Copying training dataset
2024-12-29 11:10:09,522:INFO:Defining folds
2024-12-29 11:10:09,522:INFO:Declaring metric variables
2024-12-29 11:10:09,522:INFO:Importing untrained model
2024-12-29 11:10:09,522:INFO:Declaring custom model
2024-12-29 11:10:09,523:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:10:09,523:INFO:Cross validation set to False
2024-12-29 11:10:09,524:INFO:Fitting Model
2024-12-29 11:10:09,569:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'Pclass',
                                             'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transfor...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-12-29 11:10:09,569:INFO:create_model() successfully completed......................................
2024-12-29 11:10:09,786:INFO:_master_model_container: 19
2024-12-29 11:10:09,786:INFO:_display_container: 4
2024-12-29 11:10:09,792:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Age', 'Pclass',
                                             'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transfor...
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=-1,
                               num_parallel_tree=None,
                               objective='binary:logistic', ...))],
         verbose=False)
2024-12-29 11:10:09,792:INFO:finalize_model() successfully completed......................................
2024-12-29 11:13:28,169:INFO:PyCaret ClassificationExperiment
2024-12-29 11:13:28,169:INFO:Logging name: clf-default-name
2024-12-29 11:13:28,169:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-29 11:13:28,170:INFO:version 3.3.1
2024-12-29 11:13:28,170:INFO:Initializing setup()
2024-12-29 11:13:28,170:INFO:self.USI: 3fa8
2024-12-29 11:13:28,170:INFO:self._variable_keys: {'USI', '_ml_usecase', 'y_train', 'X_train', 'X', 'is_multiclass', 'pipeline', 'X_test', 'fold_groups_param', 'data', 'fix_imbalance', 'idx', 'gpu_param', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', '_available_plots', 'y_test', 'log_plots_param', 'logging_param', 'memory', 'seed', 'fold_shuffle_param', 'y', 'html_param', 'target_param', 'n_jobs_param', 'exp_name_log'}
2024-12-29 11:13:28,170:INFO:Checking environment
2024-12-29 11:13:28,170:INFO:python_version: 3.10.15
2024-12-29 11:13:28,170:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-29 11:13:28,170:INFO:machine: AMD64
2024-12-29 11:13:28,170:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-29 11:13:28,170:INFO:Memory: svmem(total=16312721408, available=901074944, percent=94.5, used=15411646464, free=901074944)
2024-12-29 11:13:28,170:INFO:Physical Core: 6
2024-12-29 11:13:28,170:INFO:Logical Core: 12
2024-12-29 11:13:28,170:INFO:Checking libraries
2024-12-29 11:13:28,170:INFO:System:
2024-12-29 11:13:28,170:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-29 11:13:28,170:INFO:executable: d:\Anaconda\python.exe
2024-12-29 11:13:28,170:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-29 11:13:28,170:INFO:PyCaret required dependencies:
2024-12-29 11:13:28,170:INFO:                 pip: 24.2
2024-12-29 11:13:28,170:INFO:          setuptools: 75.1.0
2024-12-29 11:13:28,170:INFO:             pycaret: 3.3.1
2024-12-29 11:13:28,170:INFO:             IPython: 8.27.0
2024-12-29 11:13:28,170:INFO:          ipywidgets: 8.1.2
2024-12-29 11:13:28,171:INFO:                tqdm: 4.66.5
2024-12-29 11:13:28,171:INFO:               numpy: 1.26.4
2024-12-29 11:13:28,171:INFO:              pandas: 2.1.4
2024-12-29 11:13:28,171:INFO:              jinja2: 3.1.4
2024-12-29 11:13:28,171:INFO:               scipy: 1.11.4
2024-12-29 11:13:28,171:INFO:              joblib: 1.2.0
2024-12-29 11:13:28,171:INFO:             sklearn: 1.4.2
2024-12-29 11:13:28,171:INFO:                pyod: 2.0.2
2024-12-29 11:13:28,171:INFO:            imblearn: 0.12.3
2024-12-29 11:13:28,171:INFO:   category_encoders: 2.6.3
2024-12-29 11:13:28,171:INFO:            lightgbm: 4.5.0
2024-12-29 11:13:28,171:INFO:               numba: 0.60.0
2024-12-29 11:13:28,171:INFO:            requests: 2.32.3
2024-12-29 11:13:28,171:INFO:          matplotlib: 3.9.2
2024-12-29 11:13:28,171:INFO:          scikitplot: 0.3.7
2024-12-29 11:13:28,171:INFO:         yellowbrick: 1.5
2024-12-29 11:13:28,171:INFO:              plotly: 5.24.1
2024-12-29 11:13:28,171:INFO:    plotly-resampler: Not installed
2024-12-29 11:13:28,171:INFO:             kaleido: 0.2.1
2024-12-29 11:13:28,171:INFO:           schemdraw: 0.15
2024-12-29 11:13:28,171:INFO:         statsmodels: 0.14.2
2024-12-29 11:13:28,171:INFO:              sktime: 0.26.0
2024-12-29 11:13:28,171:INFO:               tbats: 1.1.3
2024-12-29 11:13:28,171:INFO:            pmdarima: 2.0.4
2024-12-29 11:13:28,171:INFO:              psutil: 5.9.0
2024-12-29 11:13:28,171:INFO:          markupsafe: 2.1.3
2024-12-29 11:13:28,171:INFO:             pickle5: Not installed
2024-12-29 11:13:28,171:INFO:         cloudpickle: 3.0.0
2024-12-29 11:13:28,172:INFO:         deprecation: 2.1.0
2024-12-29 11:13:28,172:INFO:              xxhash: 2.0.2
2024-12-29 11:13:28,172:INFO:           wurlitzer: 3.1.1
2024-12-29 11:13:28,172:INFO:PyCaret optional dependencies:
2024-12-29 11:13:28,172:INFO:                shap: Not installed
2024-12-29 11:13:28,172:INFO:           interpret: Not installed
2024-12-29 11:13:28,172:INFO:                umap: 0.5.3
2024-12-29 11:13:28,172:INFO:     ydata_profiling: Not installed
2024-12-29 11:13:28,172:INFO:  explainerdashboard: Not installed
2024-12-29 11:13:28,172:INFO:             autoviz: Not installed
2024-12-29 11:13:28,172:INFO:           fairlearn: Not installed
2024-12-29 11:13:28,172:INFO:          deepchecks: Not installed
2024-12-29 11:13:28,172:INFO:             xgboost: 2.1.2
2024-12-29 11:13:28,172:INFO:            catboost: 1.2.3
2024-12-29 11:13:28,172:INFO:              kmodes: 0.12.2
2024-12-29 11:13:28,172:INFO:             mlxtend: 0.23.1
2024-12-29 11:13:28,172:INFO:       statsforecast: Not installed
2024-12-29 11:13:28,172:INFO:        tune_sklearn: Not installed
2024-12-29 11:13:28,172:INFO:                 ray: Not installed
2024-12-29 11:13:28,172:INFO:            hyperopt: Not installed
2024-12-29 11:13:28,172:INFO:              optuna: Not installed
2024-12-29 11:13:28,172:INFO:               skopt: Not installed
2024-12-29 11:13:28,172:INFO:              mlflow: 2.16.2
2024-12-29 11:13:28,172:INFO:              gradio: Not installed
2024-12-29 11:13:28,172:INFO:             fastapi: Not installed
2024-12-29 11:13:28,172:INFO:             uvicorn: Not installed
2024-12-29 11:13:28,172:INFO:              m2cgen: Not installed
2024-12-29 11:13:28,172:INFO:           evidently: Not installed
2024-12-29 11:13:28,173:INFO:               fugue: Not installed
2024-12-29 11:13:28,173:INFO:           streamlit: Not installed
2024-12-29 11:13:28,173:INFO:             prophet: Not installed
2024-12-29 11:13:28,173:INFO:None
2024-12-29 11:13:28,173:INFO:Set up data.
2024-12-29 11:13:28,176:INFO:Set up folding strategy.
2024-12-29 11:13:28,176:INFO:Set up train/test split.
2024-12-29 11:13:28,180:INFO:Set up index.
2024-12-29 11:13:28,180:INFO:Assigning column types.
2024-12-29 11:13:28,182:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-29 11:13:28,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 11:13:28,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:13:28,252:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,254:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 11:13:28,296:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:13:28,321:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,323:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,324:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-29 11:13:28,364:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:13:28,390:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,392:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,433:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 11:13:28,457:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,459:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,460:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-29 11:13:28,517:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,519:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,576:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,578:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,579:INFO:Preparing preprocessing pipeline...
2024-12-29 11:13:28,580:INFO:Set up simple imputation.
2024-12-29 11:13:28,594:INFO:Finished creating preprocessing pipeline.
2024-12-29 11:13:28,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-12-29 11:13:28,597:INFO:Creating final display dataframe.
2024-12-29 11:13:28,638:INFO:Setup _display_container:                     Description             Value
0                    Session id              8464
1                        Target          Survived
2                   Target type            Binary
3           Original data shape          (891, 4)
4        Transformed data shape          (891, 4)
5   Transformed train set shape          (623, 4)
6    Transformed test set shape          (268, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3fa8
2024-12-29 11:13:28,701:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,702:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,761:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 11:13:28,763:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 11:13:28,764:INFO:setup() successfully completed in 0.6s...............
2024-12-29 11:13:28,766:INFO:Initializing compare_models()
2024-12-29 11:13:28,766:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-29 11:13:28,766:INFO:Checking exceptions
2024-12-29 11:13:28,768:INFO:Preparing display monitor
2024-12-29 11:13:28,784:INFO:Initializing Logistic Regression
2024-12-29 11:13:28,784:INFO:Total runtime is 0.0 minutes
2024-12-29 11:13:28,787:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:28,787:INFO:Initializing create_model()
2024-12-29 11:13:28,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:28,788:INFO:Checking exceptions
2024-12-29 11:13:28,788:INFO:Importing libraries
2024-12-29 11:13:28,788:INFO:Copying training dataset
2024-12-29 11:13:28,792:INFO:Defining folds
2024-12-29 11:13:28,792:INFO:Declaring metric variables
2024-12-29 11:13:28,795:INFO:Importing untrained model
2024-12-29 11:13:28,798:INFO:Logistic Regression Imported successfully
2024-12-29 11:13:28,804:INFO:Starting cross validation
2024-12-29 11:13:28,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:28,864:INFO:Calculating mean and std
2024-12-29 11:13:28,864:INFO:Creating metrics dataframe
2024-12-29 11:13:28,867:INFO:Uploading results into container
2024-12-29 11:13:28,867:INFO:Uploading model into container now
2024-12-29 11:13:28,867:INFO:_master_model_container: 1
2024-12-29 11:13:28,867:INFO:_display_container: 2
2024-12-29 11:13:28,868:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8464, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 11:13:28,868:INFO:create_model() successfully completed......................................
2024-12-29 11:13:29,118:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:29,118:INFO:Creating metrics dataframe
2024-12-29 11:13:29,123:INFO:Initializing K Neighbors Classifier
2024-12-29 11:13:29,123:INFO:Total runtime is 0.005653011798858643 minutes
2024-12-29 11:13:29,126:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:29,126:INFO:Initializing create_model()
2024-12-29 11:13:29,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:29,126:INFO:Checking exceptions
2024-12-29 11:13:29,127:INFO:Importing libraries
2024-12-29 11:13:29,127:INFO:Copying training dataset
2024-12-29 11:13:29,129:INFO:Defining folds
2024-12-29 11:13:29,130:INFO:Declaring metric variables
2024-12-29 11:13:29,132:INFO:Importing untrained model
2024-12-29 11:13:29,134:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:13:29,140:INFO:Starting cross validation
2024-12-29 11:13:29,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:29,241:INFO:Calculating mean and std
2024-12-29 11:13:29,243:INFO:Creating metrics dataframe
2024-12-29 11:13:29,245:INFO:Uploading results into container
2024-12-29 11:13:29,245:INFO:Uploading model into container now
2024-12-29 11:13:29,245:INFO:_master_model_container: 2
2024-12-29 11:13:29,245:INFO:_display_container: 2
2024-12-29 11:13:29,246:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:29,246:INFO:create_model() successfully completed......................................
2024-12-29 11:13:29,454:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:29,455:INFO:Creating metrics dataframe
2024-12-29 11:13:29,460:INFO:Initializing Naive Bayes
2024-12-29 11:13:29,460:INFO:Total runtime is 0.01127392053604126 minutes
2024-12-29 11:13:29,464:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:29,464:INFO:Initializing create_model()
2024-12-29 11:13:29,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:29,465:INFO:Checking exceptions
2024-12-29 11:13:29,465:INFO:Importing libraries
2024-12-29 11:13:29,465:INFO:Copying training dataset
2024-12-29 11:13:29,468:INFO:Defining folds
2024-12-29 11:13:29,468:INFO:Declaring metric variables
2024-12-29 11:13:29,470:INFO:Importing untrained model
2024-12-29 11:13:29,473:INFO:Naive Bayes Imported successfully
2024-12-29 11:13:29,480:INFO:Starting cross validation
2024-12-29 11:13:29,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:29,532:INFO:Calculating mean and std
2024-12-29 11:13:29,533:INFO:Creating metrics dataframe
2024-12-29 11:13:29,534:INFO:Uploading results into container
2024-12-29 11:13:29,535:INFO:Uploading model into container now
2024-12-29 11:13:29,535:INFO:_master_model_container: 3
2024-12-29 11:13:29,535:INFO:_display_container: 2
2024-12-29 11:13:29,535:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-29 11:13:29,535:INFO:create_model() successfully completed......................................
2024-12-29 11:13:29,737:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:29,737:INFO:Creating metrics dataframe
2024-12-29 11:13:29,743:INFO:Initializing Decision Tree Classifier
2024-12-29 11:13:29,743:INFO:Total runtime is 0.01597918669382731 minutes
2024-12-29 11:13:29,746:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:29,746:INFO:Initializing create_model()
2024-12-29 11:13:29,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:29,746:INFO:Checking exceptions
2024-12-29 11:13:29,746:INFO:Importing libraries
2024-12-29 11:13:29,747:INFO:Copying training dataset
2024-12-29 11:13:29,750:INFO:Defining folds
2024-12-29 11:13:29,750:INFO:Declaring metric variables
2024-12-29 11:13:29,752:INFO:Importing untrained model
2024-12-29 11:13:29,756:INFO:Decision Tree Classifier Imported successfully
2024-12-29 11:13:29,762:INFO:Starting cross validation
2024-12-29 11:13:29,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:29,810:INFO:Calculating mean and std
2024-12-29 11:13:29,811:INFO:Creating metrics dataframe
2024-12-29 11:13:29,814:INFO:Uploading results into container
2024-12-29 11:13:29,814:INFO:Uploading model into container now
2024-12-29 11:13:29,814:INFO:_master_model_container: 4
2024-12-29 11:13:29,814:INFO:_display_container: 2
2024-12-29 11:13:29,814:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8464, splitter='best')
2024-12-29 11:13:29,815:INFO:create_model() successfully completed......................................
2024-12-29 11:13:30,020:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:30,020:INFO:Creating metrics dataframe
2024-12-29 11:13:30,027:INFO:Initializing SVM - Linear Kernel
2024-12-29 11:13:30,027:INFO:Total runtime is 0.020724034309387206 minutes
2024-12-29 11:13:30,031:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:30,031:INFO:Initializing create_model()
2024-12-29 11:13:30,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:30,031:INFO:Checking exceptions
2024-12-29 11:13:30,031:INFO:Importing libraries
2024-12-29 11:13:30,032:INFO:Copying training dataset
2024-12-29 11:13:30,034:INFO:Defining folds
2024-12-29 11:13:30,034:INFO:Declaring metric variables
2024-12-29 11:13:30,038:INFO:Importing untrained model
2024-12-29 11:13:30,041:INFO:SVM - Linear Kernel Imported successfully
2024-12-29 11:13:30,046:INFO:Starting cross validation
2024-12-29 11:13:30,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:30,097:INFO:Calculating mean and std
2024-12-29 11:13:30,098:INFO:Creating metrics dataframe
2024-12-29 11:13:30,099:INFO:Uploading results into container
2024-12-29 11:13:30,100:INFO:Uploading model into container now
2024-12-29 11:13:30,100:INFO:_master_model_container: 5
2024-12-29 11:13:30,100:INFO:_display_container: 2
2024-12-29 11:13:30,100:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8464, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-29 11:13:30,100:INFO:create_model() successfully completed......................................
2024-12-29 11:13:30,301:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:30,301:INFO:Creating metrics dataframe
2024-12-29 11:13:30,308:INFO:Initializing Ridge Classifier
2024-12-29 11:13:30,308:INFO:Total runtime is 0.025405768553415933 minutes
2024-12-29 11:13:30,311:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:30,312:INFO:Initializing create_model()
2024-12-29 11:13:30,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:30,312:INFO:Checking exceptions
2024-12-29 11:13:30,312:INFO:Importing libraries
2024-12-29 11:13:30,312:INFO:Copying training dataset
2024-12-29 11:13:30,315:INFO:Defining folds
2024-12-29 11:13:30,315:INFO:Declaring metric variables
2024-12-29 11:13:30,319:INFO:Importing untrained model
2024-12-29 11:13:30,322:INFO:Ridge Classifier Imported successfully
2024-12-29 11:13:30,329:INFO:Starting cross validation
2024-12-29 11:13:30,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:30,399:INFO:Calculating mean and std
2024-12-29 11:13:30,399:INFO:Creating metrics dataframe
2024-12-29 11:13:30,401:INFO:Uploading results into container
2024-12-29 11:13:30,401:INFO:Uploading model into container now
2024-12-29 11:13:30,401:INFO:_master_model_container: 6
2024-12-29 11:13:30,402:INFO:_display_container: 2
2024-12-29 11:13:30,402:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8464, solver='auto',
                tol=0.0001)
2024-12-29 11:13:30,402:INFO:create_model() successfully completed......................................
2024-12-29 11:13:30,605:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:30,605:INFO:Creating metrics dataframe
2024-12-29 11:13:30,612:INFO:Initializing Random Forest Classifier
2024-12-29 11:13:30,612:INFO:Total runtime is 0.030474452177683513 minutes
2024-12-29 11:13:30,615:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:30,615:INFO:Initializing create_model()
2024-12-29 11:13:30,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:30,615:INFO:Checking exceptions
2024-12-29 11:13:30,615:INFO:Importing libraries
2024-12-29 11:13:30,615:INFO:Copying training dataset
2024-12-29 11:13:30,618:INFO:Defining folds
2024-12-29 11:13:30,618:INFO:Declaring metric variables
2024-12-29 11:13:30,622:INFO:Importing untrained model
2024-12-29 11:13:30,625:INFO:Random Forest Classifier Imported successfully
2024-12-29 11:13:30,630:INFO:Starting cross validation
2024-12-29 11:13:30,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:30,903:INFO:Calculating mean and std
2024-12-29 11:13:30,904:INFO:Creating metrics dataframe
2024-12-29 11:13:30,905:INFO:Uploading results into container
2024-12-29 11:13:30,907:INFO:Uploading model into container now
2024-12-29 11:13:30,907:INFO:_master_model_container: 7
2024-12-29 11:13:30,907:INFO:_display_container: 2
2024-12-29 11:13:30,908:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8464, verbose=0,
                       warm_start=False)
2024-12-29 11:13:30,908:INFO:create_model() successfully completed......................................
2024-12-29 11:13:31,112:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:31,112:INFO:Creating metrics dataframe
2024-12-29 11:13:31,119:INFO:Initializing Quadratic Discriminant Analysis
2024-12-29 11:13:31,119:INFO:Total runtime is 0.03891869386037191 minutes
2024-12-29 11:13:31,121:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:31,122:INFO:Initializing create_model()
2024-12-29 11:13:31,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:31,122:INFO:Checking exceptions
2024-12-29 11:13:31,122:INFO:Importing libraries
2024-12-29 11:13:31,122:INFO:Copying training dataset
2024-12-29 11:13:31,125:INFO:Defining folds
2024-12-29 11:13:31,126:INFO:Declaring metric variables
2024-12-29 11:13:31,128:INFO:Importing untrained model
2024-12-29 11:13:31,132:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-29 11:13:31,138:INFO:Starting cross validation
2024-12-29 11:13:31,138:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:31,188:INFO:Calculating mean and std
2024-12-29 11:13:31,189:INFO:Creating metrics dataframe
2024-12-29 11:13:31,190:INFO:Uploading results into container
2024-12-29 11:13:31,190:INFO:Uploading model into container now
2024-12-29 11:13:31,191:INFO:_master_model_container: 8
2024-12-29 11:13:31,191:INFO:_display_container: 2
2024-12-29 11:13:31,191:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-29 11:13:31,191:INFO:create_model() successfully completed......................................
2024-12-29 11:13:31,391:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:31,391:INFO:Creating metrics dataframe
2024-12-29 11:13:31,398:INFO:Initializing Ada Boost Classifier
2024-12-29 11:13:31,398:INFO:Total runtime is 0.04356761773427328 minutes
2024-12-29 11:13:31,402:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:31,402:INFO:Initializing create_model()
2024-12-29 11:13:31,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:31,402:INFO:Checking exceptions
2024-12-29 11:13:31,402:INFO:Importing libraries
2024-12-29 11:13:31,402:INFO:Copying training dataset
2024-12-29 11:13:31,405:INFO:Defining folds
2024-12-29 11:13:31,406:INFO:Declaring metric variables
2024-12-29 11:13:31,408:INFO:Importing untrained model
2024-12-29 11:13:31,411:INFO:Ada Boost Classifier Imported successfully
2024-12-29 11:13:31,417:INFO:Starting cross validation
2024-12-29 11:13:31,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:31,439:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,441:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,441:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,441:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,442:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,444:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,446:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,446:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,448:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,449:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 11:13:31,577:INFO:Calculating mean and std
2024-12-29 11:13:31,578:INFO:Creating metrics dataframe
2024-12-29 11:13:31,579:INFO:Uploading results into container
2024-12-29 11:13:31,580:INFO:Uploading model into container now
2024-12-29 11:13:31,580:INFO:_master_model_container: 9
2024-12-29 11:13:31,580:INFO:_display_container: 2
2024-12-29 11:13:31,580:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8464)
2024-12-29 11:13:31,580:INFO:create_model() successfully completed......................................
2024-12-29 11:13:31,783:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:31,784:INFO:Creating metrics dataframe
2024-12-29 11:13:31,791:INFO:Initializing Gradient Boosting Classifier
2024-12-29 11:13:31,791:INFO:Total runtime is 0.0501234769821167 minutes
2024-12-29 11:13:31,794:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:31,795:INFO:Initializing create_model()
2024-12-29 11:13:31,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:31,795:INFO:Checking exceptions
2024-12-29 11:13:31,795:INFO:Importing libraries
2024-12-29 11:13:31,795:INFO:Copying training dataset
2024-12-29 11:13:31,798:INFO:Defining folds
2024-12-29 11:13:31,798:INFO:Declaring metric variables
2024-12-29 11:13:31,802:INFO:Importing untrained model
2024-12-29 11:13:31,804:INFO:Gradient Boosting Classifier Imported successfully
2024-12-29 11:13:31,810:INFO:Starting cross validation
2024-12-29 11:13:31,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:31,973:INFO:Calculating mean and std
2024-12-29 11:13:31,975:INFO:Creating metrics dataframe
2024-12-29 11:13:31,976:INFO:Uploading results into container
2024-12-29 11:13:31,977:INFO:Uploading model into container now
2024-12-29 11:13:31,977:INFO:_master_model_container: 10
2024-12-29 11:13:31,977:INFO:_display_container: 2
2024-12-29 11:13:31,977:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8464, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-29 11:13:31,977:INFO:create_model() successfully completed......................................
2024-12-29 11:13:32,185:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:32,185:INFO:Creating metrics dataframe
2024-12-29 11:13:32,192:INFO:Initializing Linear Discriminant Analysis
2024-12-29 11:13:32,192:INFO:Total runtime is 0.0567991852760315 minutes
2024-12-29 11:13:32,195:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:32,196:INFO:Initializing create_model()
2024-12-29 11:13:32,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:32,196:INFO:Checking exceptions
2024-12-29 11:13:32,196:INFO:Importing libraries
2024-12-29 11:13:32,196:INFO:Copying training dataset
2024-12-29 11:13:32,199:INFO:Defining folds
2024-12-29 11:13:32,199:INFO:Declaring metric variables
2024-12-29 11:13:32,202:INFO:Importing untrained model
2024-12-29 11:13:32,205:INFO:Linear Discriminant Analysis Imported successfully
2024-12-29 11:13:32,211:INFO:Starting cross validation
2024-12-29 11:13:32,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:32,259:INFO:Calculating mean and std
2024-12-29 11:13:32,260:INFO:Creating metrics dataframe
2024-12-29 11:13:32,261:INFO:Uploading results into container
2024-12-29 11:13:32,262:INFO:Uploading model into container now
2024-12-29 11:13:32,262:INFO:_master_model_container: 11
2024-12-29 11:13:32,262:INFO:_display_container: 2
2024-12-29 11:13:32,262:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-29 11:13:32,262:INFO:create_model() successfully completed......................................
2024-12-29 11:13:32,470:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:32,470:INFO:Creating metrics dataframe
2024-12-29 11:13:32,478:INFO:Initializing Extra Trees Classifier
2024-12-29 11:13:32,478:INFO:Total runtime is 0.06156195004781088 minutes
2024-12-29 11:13:32,481:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:32,481:INFO:Initializing create_model()
2024-12-29 11:13:32,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:32,481:INFO:Checking exceptions
2024-12-29 11:13:32,481:INFO:Importing libraries
2024-12-29 11:13:32,481:INFO:Copying training dataset
2024-12-29 11:13:32,486:INFO:Defining folds
2024-12-29 11:13:32,486:INFO:Declaring metric variables
2024-12-29 11:13:32,489:INFO:Importing untrained model
2024-12-29 11:13:32,491:INFO:Extra Trees Classifier Imported successfully
2024-12-29 11:13:32,497:INFO:Starting cross validation
2024-12-29 11:13:32,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:32,714:INFO:Calculating mean and std
2024-12-29 11:13:32,716:INFO:Creating metrics dataframe
2024-12-29 11:13:32,718:INFO:Uploading results into container
2024-12-29 11:13:32,718:INFO:Uploading model into container now
2024-12-29 11:13:32,719:INFO:_master_model_container: 12
2024-12-29 11:13:32,719:INFO:_display_container: 2
2024-12-29 11:13:32,719:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8464, verbose=0,
                     warm_start=False)
2024-12-29 11:13:32,720:INFO:create_model() successfully completed......................................
2024-12-29 11:13:32,924:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:32,924:INFO:Creating metrics dataframe
2024-12-29 11:13:32,932:INFO:Initializing Extreme Gradient Boosting
2024-12-29 11:13:32,932:INFO:Total runtime is 0.06912947893142701 minutes
2024-12-29 11:13:32,934:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:32,935:INFO:Initializing create_model()
2024-12-29 11:13:32,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:32,935:INFO:Checking exceptions
2024-12-29 11:13:32,935:INFO:Importing libraries
2024-12-29 11:13:32,935:INFO:Copying training dataset
2024-12-29 11:13:32,938:INFO:Defining folds
2024-12-29 11:13:32,938:INFO:Declaring metric variables
2024-12-29 11:13:32,941:INFO:Importing untrained model
2024-12-29 11:13:32,945:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 11:13:32,952:INFO:Starting cross validation
2024-12-29 11:13:32,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:33,044:INFO:Calculating mean and std
2024-12-29 11:13:33,046:INFO:Creating metrics dataframe
2024-12-29 11:13:33,048:INFO:Uploading results into container
2024-12-29 11:13:33,048:INFO:Uploading model into container now
2024-12-29 11:13:33,049:INFO:_master_model_container: 13
2024-12-29 11:13:33,049:INFO:_display_container: 2
2024-12-29 11:13:33,050:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 11:13:33,050:INFO:create_model() successfully completed......................................
2024-12-29 11:13:33,252:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:33,252:INFO:Creating metrics dataframe
2024-12-29 11:13:33,261:INFO:Initializing Light Gradient Boosting Machine
2024-12-29 11:13:33,261:INFO:Total runtime is 0.0746227780977885 minutes
2024-12-29 11:13:33,264:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:33,264:INFO:Initializing create_model()
2024-12-29 11:13:33,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:33,264:INFO:Checking exceptions
2024-12-29 11:13:33,264:INFO:Importing libraries
2024-12-29 11:13:33,264:INFO:Copying training dataset
2024-12-29 11:13:33,267:INFO:Defining folds
2024-12-29 11:13:33,267:INFO:Declaring metric variables
2024-12-29 11:13:33,270:INFO:Importing untrained model
2024-12-29 11:13:33,273:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-29 11:13:33,279:INFO:Starting cross validation
2024-12-29 11:13:33,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:33,564:INFO:Calculating mean and std
2024-12-29 11:13:33,565:INFO:Creating metrics dataframe
2024-12-29 11:13:33,567:INFO:Uploading results into container
2024-12-29 11:13:33,568:INFO:Uploading model into container now
2024-12-29 11:13:33,568:INFO:_master_model_container: 14
2024-12-29 11:13:33,568:INFO:_display_container: 2
2024-12-29 11:13:33,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8464, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-29 11:13:33,569:INFO:create_model() successfully completed......................................
2024-12-29 11:13:33,788:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:33,788:INFO:Creating metrics dataframe
2024-12-29 11:13:33,796:INFO:Initializing CatBoost Classifier
2024-12-29 11:13:33,796:INFO:Total runtime is 0.08353356917699178 minutes
2024-12-29 11:13:33,799:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:33,799:INFO:Initializing create_model()
2024-12-29 11:13:33,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:33,799:INFO:Checking exceptions
2024-12-29 11:13:33,801:INFO:Importing libraries
2024-12-29 11:13:33,801:INFO:Copying training dataset
2024-12-29 11:13:33,803:INFO:Defining folds
2024-12-29 11:13:33,804:INFO:Declaring metric variables
2024-12-29 11:13:33,806:INFO:Importing untrained model
2024-12-29 11:13:33,809:INFO:CatBoost Classifier Imported successfully
2024-12-29 11:13:33,815:INFO:Starting cross validation
2024-12-29 11:13:33,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:36,505:INFO:Calculating mean and std
2024-12-29 11:13:36,506:INFO:Creating metrics dataframe
2024-12-29 11:13:36,508:INFO:Uploading results into container
2024-12-29 11:13:36,508:INFO:Uploading model into container now
2024-12-29 11:13:36,508:INFO:_master_model_container: 15
2024-12-29 11:13:36,509:INFO:_display_container: 2
2024-12-29 11:13:36,509:INFO:<catboost.core.CatBoostClassifier object at 0x000002053CD6A5F0>
2024-12-29 11:13:36,509:INFO:create_model() successfully completed......................................
2024-12-29 11:13:36,743:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:36,743:INFO:Creating metrics dataframe
2024-12-29 11:13:36,753:INFO:Initializing Dummy Classifier
2024-12-29 11:13:36,753:INFO:Total runtime is 0.13280889590581257 minutes
2024-12-29 11:13:36,756:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:36,756:INFO:Initializing create_model()
2024-12-29 11:13:36,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002053AA4A140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:36,756:INFO:Checking exceptions
2024-12-29 11:13:36,756:INFO:Importing libraries
2024-12-29 11:13:36,756:INFO:Copying training dataset
2024-12-29 11:13:36,760:INFO:Defining folds
2024-12-29 11:13:36,761:INFO:Declaring metric variables
2024-12-29 11:13:36,764:INFO:Importing untrained model
2024-12-29 11:13:36,768:INFO:Dummy Classifier Imported successfully
2024-12-29 11:13:36,772:INFO:Starting cross validation
2024-12-29 11:13:36,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:36,807:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,807:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,808:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,810:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,810:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,811:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,812:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,814:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,816:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,817:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 11:13:36,821:INFO:Calculating mean and std
2024-12-29 11:13:36,822:INFO:Creating metrics dataframe
2024-12-29 11:13:36,823:INFO:Uploading results into container
2024-12-29 11:13:36,824:INFO:Uploading model into container now
2024-12-29 11:13:36,824:INFO:_master_model_container: 16
2024-12-29 11:13:36,824:INFO:_display_container: 2
2024-12-29 11:13:36,824:INFO:DummyClassifier(constant=None, random_state=8464, strategy='prior')
2024-12-29 11:13:36,824:INFO:create_model() successfully completed......................................
2024-12-29 11:13:37,030:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:37,030:INFO:Creating metrics dataframe
2024-12-29 11:13:37,039:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-29 11:13:37,047:INFO:Initializing create_model()
2024-12-29 11:13:37,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:37,048:INFO:Checking exceptions
2024-12-29 11:13:37,051:INFO:Importing libraries
2024-12-29 11:13:37,051:INFO:Copying training dataset
2024-12-29 11:13:37,054:INFO:Defining folds
2024-12-29 11:13:37,054:INFO:Declaring metric variables
2024-12-29 11:13:37,055:INFO:Importing untrained model
2024-12-29 11:13:37,055:INFO:Declaring custom model
2024-12-29 11:13:37,055:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:13:37,056:INFO:Cross validation set to False
2024-12-29 11:13:37,056:INFO:Fitting Model
2024-12-29 11:13:37,063:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:37,063:INFO:create_model() successfully completed......................................
2024-12-29 11:13:37,299:INFO:_master_model_container: 16
2024-12-29 11:13:37,299:INFO:_display_container: 2
2024-12-29 11:13:37,299:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:37,299:INFO:compare_models() successfully completed......................................
2024-12-29 11:13:37,300:INFO:Initializing create_model()
2024-12-29 11:13:37,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:37,300:INFO:Checking exceptions
2024-12-29 11:13:37,313:INFO:Importing libraries
2024-12-29 11:13:37,313:INFO:Copying training dataset
2024-12-29 11:13:37,316:INFO:Defining folds
2024-12-29 11:13:37,316:INFO:Declaring metric variables
2024-12-29 11:13:37,319:INFO:Importing untrained model
2024-12-29 11:13:37,320:INFO:Declaring custom model
2024-12-29 11:13:37,324:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:13:37,330:INFO:Starting cross validation
2024-12-29 11:13:37,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:37,501:INFO:Calculating mean and std
2024-12-29 11:13:37,501:INFO:Creating metrics dataframe
2024-12-29 11:13:37,505:INFO:Finalizing model
2024-12-29 11:13:37,513:INFO:Uploading results into container
2024-12-29 11:13:37,515:INFO:Uploading model into container now
2024-12-29 11:13:37,522:INFO:_master_model_container: 17
2024-12-29 11:13:37,523:INFO:_display_container: 3
2024-12-29 11:13:37,523:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:37,524:INFO:create_model() successfully completed......................................
2024-12-29 11:13:37,731:INFO:Initializing tune_model()
2024-12-29 11:13:37,732:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>)
2024-12-29 11:13:37,732:INFO:Checking exceptions
2024-12-29 11:13:37,745:INFO:Copying training dataset
2024-12-29 11:13:37,748:INFO:Checking base model
2024-12-29 11:13:37,748:INFO:Base model : K Neighbors Classifier
2024-12-29 11:13:37,751:INFO:Declaring metric variables
2024-12-29 11:13:37,755:INFO:Defining Hyperparameters
2024-12-29 11:13:37,991:INFO:Tuning with n_jobs=-1
2024-12-29 11:13:37,991:INFO:Initializing RandomizedSearchCV
2024-12-29 11:13:38,429:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 6, 'actual_estimator__metric': 'manhattan'}
2024-12-29 11:13:38,429:INFO:Hyperparameter search completed
2024-12-29 11:13:38,429:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:38,429:INFO:Initializing create_model()
2024-12-29 11:13:38,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000205347BB2B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'weights': 'uniform', 'n_neighbors': 6, 'metric': 'manhattan'})
2024-12-29 11:13:38,429:INFO:Checking exceptions
2024-12-29 11:13:38,429:INFO:Importing libraries
2024-12-29 11:13:38,429:INFO:Copying training dataset
2024-12-29 11:13:38,433:INFO:Defining folds
2024-12-29 11:13:38,433:INFO:Declaring metric variables
2024-12-29 11:13:38,435:INFO:Importing untrained model
2024-12-29 11:13:38,436:INFO:Declaring custom model
2024-12-29 11:13:38,438:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:13:38,444:INFO:Starting cross validation
2024-12-29 11:13:38,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:38,528:INFO:Calculating mean and std
2024-12-29 11:13:38,529:INFO:Creating metrics dataframe
2024-12-29 11:13:38,533:INFO:Finalizing model
2024-12-29 11:13:38,542:INFO:Uploading results into container
2024-12-29 11:13:38,544:INFO:Uploading model into container now
2024-12-29 11:13:38,544:INFO:_master_model_container: 18
2024-12-29 11:13:38,544:INFO:_display_container: 4
2024-12-29 11:13:38,544:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=6, p=2,
                     weights='uniform')
2024-12-29 11:13:38,544:INFO:create_model() successfully completed......................................
2024-12-29 11:13:38,756:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:38,756:INFO:choose_better activated
2024-12-29 11:13:38,759:INFO:SubProcess create_model() called ==================================
2024-12-29 11:13:38,760:INFO:Initializing create_model()
2024-12-29 11:13:38,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:38,760:INFO:Checking exceptions
2024-12-29 11:13:38,762:INFO:Importing libraries
2024-12-29 11:13:38,762:INFO:Copying training dataset
2024-12-29 11:13:38,764:INFO:Defining folds
2024-12-29 11:13:38,764:INFO:Declaring metric variables
2024-12-29 11:13:38,764:INFO:Importing untrained model
2024-12-29 11:13:38,764:INFO:Declaring custom model
2024-12-29 11:13:38,764:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:13:38,764:INFO:Starting cross validation
2024-12-29 11:13:38,765:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 11:13:38,924:INFO:Calculating mean and std
2024-12-29 11:13:38,924:INFO:Creating metrics dataframe
2024-12-29 11:13:38,926:INFO:Finalizing model
2024-12-29 11:13:38,930:INFO:Uploading results into container
2024-12-29 11:13:38,930:INFO:Uploading model into container now
2024-12-29 11:13:38,931:INFO:_master_model_container: 19
2024-12-29 11:13:38,931:INFO:_display_container: 5
2024-12-29 11:13:38,931:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:38,931:INFO:create_model() successfully completed......................................
2024-12-29 11:13:39,157:INFO:SubProcess create_model() end ==================================
2024-12-29 11:13:39,158:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for Accuracy is 0.8153
2024-12-29 11:13:39,158:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=6, p=2,
                     weights='uniform') result for Accuracy is 0.8137
2024-12-29 11:13:39,158:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') is best model
2024-12-29 11:13:39,158:INFO:choose_better completed
2024-12-29 11:13:39,159:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-12-29 11:13:39,167:INFO:_master_model_container: 19
2024-12-29 11:13:39,168:INFO:_display_container: 4
2024-12-29 11:13:39,168:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:39,168:INFO:tune_model() successfully completed......................................
2024-12-29 11:13:39,374:INFO:Initializing finalize_model()
2024-12-29 11:13:39,376:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 11:13:39,376:INFO:Finalizing KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 11:13:39,378:INFO:Initializing create_model()
2024-12-29 11:13:39,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002053CE68760>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 11:13:39,378:INFO:Checking exceptions
2024-12-29 11:13:39,379:INFO:Importing libraries
2024-12-29 11:13:39,379:INFO:Copying training dataset
2024-12-29 11:13:39,379:INFO:Defining folds
2024-12-29 11:13:39,379:INFO:Declaring metric variables
2024-12-29 11:13:39,379:INFO:Importing untrained model
2024-12-29 11:13:39,380:INFO:Declaring custom model
2024-12-29 11:13:39,380:INFO:K Neighbors Classifier Imported successfully
2024-12-29 11:13:39,380:INFO:Cross validation set to False
2024-12-29 11:13:39,382:INFO:Fitting Model
2024-12-29 11:13:39,389:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2024-12-29 11:13:39,389:INFO:create_model() successfully completed......................................
2024-12-29 11:13:39,589:INFO:_master_model_container: 19
2024-12-29 11:13:39,589:INFO:_display_container: 4
2024-12-29 11:13:39,592:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sex', 'Pclass', 'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False)
2024-12-29 11:13:39,592:INFO:finalize_model() successfully completed......................................
2024-12-29 18:04:45,135:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 18:04:45,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 18:04:45,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 18:04:45,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-29 18:04:46,949:INFO:PyCaret ClassificationExperiment
2024-12-29 18:04:46,949:INFO:Logging name: clf-default-name
2024-12-29 18:04:46,949:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-12-29 18:04:46,949:INFO:version 3.3.1
2024-12-29 18:04:46,949:INFO:Initializing setup()
2024-12-29 18:04:46,949:INFO:self.USI: 0bbc
2024-12-29 18:04:46,949:INFO:self._variable_keys: {'pipeline', 'y_train', 'idx', 'html_param', 'X_test', 'y', 'fold_shuffle_param', '_available_plots', 'logging_param', 'y_test', 'target_param', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'X_train', 'is_multiclass', '_ml_usecase', 'n_jobs_param', 'exp_name_log', 'exp_id', 'data', 'X', 'memory', 'USI', 'log_plots_param', 'seed', 'gpu_n_jobs_param', 'fold_generator'}
2024-12-29 18:04:46,949:INFO:Checking environment
2024-12-29 18:04:46,949:INFO:python_version: 3.10.15
2024-12-29 18:04:46,949:INFO:python_build: ('main', 'Oct  3 2024 07:22:19')
2024-12-29 18:04:46,949:INFO:machine: AMD64
2024-12-29 18:04:46,949:INFO:platform: Windows-10-10.0.22631-SP0
2024-12-29 18:04:46,950:INFO:Memory: svmem(total=16312721408, available=5583716352, percent=65.8, used=10729005056, free=5583716352)
2024-12-29 18:04:46,950:INFO:Physical Core: 6
2024-12-29 18:04:46,950:INFO:Logical Core: 12
2024-12-29 18:04:46,950:INFO:Checking libraries
2024-12-29 18:04:46,950:INFO:System:
2024-12-29 18:04:46,950:INFO:    python: 3.10.15 | packaged by Anaconda, Inc. | (main, Oct  3 2024, 07:22:19) [MSC v.1929 64 bit (AMD64)]
2024-12-29 18:04:46,950:INFO:executable: d:\Anaconda\python.exe
2024-12-29 18:04:46,950:INFO:   machine: Windows-10-10.0.22631-SP0
2024-12-29 18:04:46,950:INFO:PyCaret required dependencies:
2024-12-29 18:04:47,051:INFO:                 pip: 24.2
2024-12-29 18:04:47,051:INFO:          setuptools: 75.1.0
2024-12-29 18:04:47,051:INFO:             pycaret: 3.3.1
2024-12-29 18:04:47,053:INFO:             IPython: 8.27.0
2024-12-29 18:04:47,053:INFO:          ipywidgets: 8.1.2
2024-12-29 18:04:47,053:INFO:                tqdm: 4.66.5
2024-12-29 18:04:47,053:INFO:               numpy: 1.26.4
2024-12-29 18:04:47,053:INFO:              pandas: 2.1.4
2024-12-29 18:04:47,053:INFO:              jinja2: 3.1.4
2024-12-29 18:04:47,053:INFO:               scipy: 1.11.4
2024-12-29 18:04:47,053:INFO:              joblib: 1.2.0
2024-12-29 18:04:47,053:INFO:             sklearn: 1.4.2
2024-12-29 18:04:47,053:INFO:                pyod: 2.0.2
2024-12-29 18:04:47,053:INFO:            imblearn: 0.12.3
2024-12-29 18:04:47,053:INFO:   category_encoders: 2.6.3
2024-12-29 18:04:47,053:INFO:            lightgbm: 4.5.0
2024-12-29 18:04:47,053:INFO:               numba: 0.60.0
2024-12-29 18:04:47,053:INFO:            requests: 2.32.3
2024-12-29 18:04:47,053:INFO:          matplotlib: 3.9.2
2024-12-29 18:04:47,053:INFO:          scikitplot: 0.3.7
2024-12-29 18:04:47,054:INFO:         yellowbrick: 1.5
2024-12-29 18:04:47,054:INFO:              plotly: 5.24.1
2024-12-29 18:04:47,054:INFO:    plotly-resampler: Not installed
2024-12-29 18:04:47,054:INFO:             kaleido: 0.2.1
2024-12-29 18:04:47,054:INFO:           schemdraw: 0.15
2024-12-29 18:04:47,054:INFO:         statsmodels: 0.14.2
2024-12-29 18:04:47,054:INFO:              sktime: 0.26.0
2024-12-29 18:04:47,054:INFO:               tbats: 1.1.3
2024-12-29 18:04:47,054:INFO:            pmdarima: 2.0.4
2024-12-29 18:04:47,054:INFO:              psutil: 5.9.0
2024-12-29 18:04:47,054:INFO:          markupsafe: 2.1.3
2024-12-29 18:04:47,054:INFO:             pickle5: Not installed
2024-12-29 18:04:47,054:INFO:         cloudpickle: 3.0.0
2024-12-29 18:04:47,054:INFO:         deprecation: 2.1.0
2024-12-29 18:04:47,054:INFO:              xxhash: 2.0.2
2024-12-29 18:04:47,054:INFO:           wurlitzer: 3.1.1
2024-12-29 18:04:47,054:INFO:PyCaret optional dependencies:
2024-12-29 18:04:47,135:INFO:                shap: Not installed
2024-12-29 18:04:47,135:INFO:           interpret: Not installed
2024-12-29 18:04:47,135:INFO:                umap: 0.5.3
2024-12-29 18:04:47,135:INFO:     ydata_profiling: Not installed
2024-12-29 18:04:47,135:INFO:  explainerdashboard: Not installed
2024-12-29 18:04:47,135:INFO:             autoviz: Not installed
2024-12-29 18:04:47,135:INFO:           fairlearn: Not installed
2024-12-29 18:04:47,135:INFO:          deepchecks: Not installed
2024-12-29 18:04:47,135:INFO:             xgboost: 2.1.2
2024-12-29 18:04:47,135:INFO:            catboost: 1.2.3
2024-12-29 18:04:47,135:INFO:              kmodes: 0.12.2
2024-12-29 18:04:47,135:INFO:             mlxtend: 0.23.1
2024-12-29 18:04:47,135:INFO:       statsforecast: Not installed
2024-12-29 18:04:47,135:INFO:        tune_sklearn: Not installed
2024-12-29 18:04:47,135:INFO:                 ray: Not installed
2024-12-29 18:04:47,135:INFO:            hyperopt: Not installed
2024-12-29 18:04:47,135:INFO:              optuna: Not installed
2024-12-29 18:04:47,135:INFO:               skopt: Not installed
2024-12-29 18:04:47,135:INFO:              mlflow: 2.16.2
2024-12-29 18:04:47,135:INFO:              gradio: Not installed
2024-12-29 18:04:47,136:INFO:             fastapi: Not installed
2024-12-29 18:04:47,136:INFO:             uvicorn: Not installed
2024-12-29 18:04:47,136:INFO:              m2cgen: Not installed
2024-12-29 18:04:47,136:INFO:           evidently: Not installed
2024-12-29 18:04:47,136:INFO:               fugue: Not installed
2024-12-29 18:04:47,136:INFO:           streamlit: Not installed
2024-12-29 18:04:47,136:INFO:             prophet: Not installed
2024-12-29 18:04:47,136:INFO:None
2024-12-29 18:04:47,136:INFO:Set up data.
2024-12-29 18:04:47,144:INFO:Set up folding strategy.
2024-12-29 18:04:47,144:INFO:Set up train/test split.
2024-12-29 18:04:47,152:INFO:Set up index.
2024-12-29 18:04:47,154:INFO:Assigning column types.
2024-12-29 18:04:47,157:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-29 18:04:47,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 18:04:47,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 18:04:47,238:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:47,240:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:47,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-29 18:04:47,409:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 18:04:47,430:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:47,432:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:47,433:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-29 18:04:47,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 18:04:47,491:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:47,494:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:47,529:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-12-29 18:04:47,552:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:47,554:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:47,555:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-12-29 18:04:47,613:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:47,615:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:47,672:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:47,675:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:47,677:INFO:Preparing preprocessing pipeline...
2024-12-29 18:04:47,678:INFO:Set up simple imputation.
2024-12-29 18:04:47,681:INFO:Set up encoding of ordinal features.
2024-12-29 18:04:47,682:INFO:Set up encoding of categorical features.
2024-12-29 18:04:47,799:INFO:Finished creating preprocessing pipeline.
2024-12-29 18:04:47,814:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LENOVO\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-12-29 18:04:47,814:INFO:Creating final display dataframe.
2024-12-29 18:04:48,174:INFO:Setup _display_container:                     Description             Value
0                    Session id              1136
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              0bbc
2024-12-29 18:04:48,249:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:48,253:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:48,317:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-29 18:04:48,319:INFO:Soft dependency imported: catboost: 1.2.3
2024-12-29 18:04:48,320:INFO:setup() successfully completed in 1.37s...............
2024-12-29 18:07:46,200:INFO:Initializing compare_models()
2024-12-29 18:07:46,200:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-12-29 18:07:46,200:INFO:Checking exceptions
2024-12-29 18:07:46,204:INFO:Preparing display monitor
2024-12-29 18:07:46,230:INFO:Initializing Logistic Regression
2024-12-29 18:07:46,230:INFO:Total runtime is 0.0 minutes
2024-12-29 18:07:46,234:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:46,234:INFO:Initializing create_model()
2024-12-29 18:07:46,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:46,235:INFO:Checking exceptions
2024-12-29 18:07:46,235:INFO:Importing libraries
2024-12-29 18:07:46,235:INFO:Copying training dataset
2024-12-29 18:07:46,240:INFO:Defining folds
2024-12-29 18:07:46,241:INFO:Declaring metric variables
2024-12-29 18:07:46,243:INFO:Importing untrained model
2024-12-29 18:07:46,247:INFO:Logistic Regression Imported successfully
2024-12-29 18:07:46,255:INFO:Starting cross validation
2024-12-29 18:07:46,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:49,755:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,768:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,774:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,775:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,776:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,780:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,784:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,807:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,810:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,810:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:07:49,873:INFO:Calculating mean and std
2024-12-29 18:07:49,874:INFO:Creating metrics dataframe
2024-12-29 18:07:49,877:INFO:Uploading results into container
2024-12-29 18:07:49,878:INFO:Uploading model into container now
2024-12-29 18:07:49,879:INFO:_master_model_container: 1
2024-12-29 18:07:49,879:INFO:_display_container: 2
2024-12-29 18:07:49,880:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:07:49,880:INFO:create_model() successfully completed......................................
2024-12-29 18:07:50,008:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:50,008:INFO:Creating metrics dataframe
2024-12-29 18:07:50,013:INFO:Initializing K Neighbors Classifier
2024-12-29 18:07:50,013:INFO:Total runtime is 0.06304358243942261 minutes
2024-12-29 18:07:50,016:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:50,016:INFO:Initializing create_model()
2024-12-29 18:07:50,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:50,016:INFO:Checking exceptions
2024-12-29 18:07:50,017:INFO:Importing libraries
2024-12-29 18:07:50,017:INFO:Copying training dataset
2024-12-29 18:07:50,021:INFO:Defining folds
2024-12-29 18:07:50,021:INFO:Declaring metric variables
2024-12-29 18:07:50,025:INFO:Importing untrained model
2024-12-29 18:07:50,027:INFO:K Neighbors Classifier Imported successfully
2024-12-29 18:07:50,034:INFO:Starting cross validation
2024-12-29 18:07:50,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:50,219:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,219:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,220:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,222:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,229:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,230:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,232:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:50,237:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:51,878:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:51,883:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:51,893:INFO:Calculating mean and std
2024-12-29 18:07:51,894:INFO:Creating metrics dataframe
2024-12-29 18:07:51,896:INFO:Uploading results into container
2024-12-29 18:07:51,896:INFO:Uploading model into container now
2024-12-29 18:07:51,896:INFO:_master_model_container: 2
2024-12-29 18:07:51,896:INFO:_display_container: 2
2024-12-29 18:07:51,897:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-12-29 18:07:51,897:INFO:create_model() successfully completed......................................
2024-12-29 18:07:52,013:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:52,013:INFO:Creating metrics dataframe
2024-12-29 18:07:52,020:INFO:Initializing Naive Bayes
2024-12-29 18:07:52,020:INFO:Total runtime is 0.09648873011271158 minutes
2024-12-29 18:07:52,022:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:52,022:INFO:Initializing create_model()
2024-12-29 18:07:52,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:52,022:INFO:Checking exceptions
2024-12-29 18:07:52,022:INFO:Importing libraries
2024-12-29 18:07:52,022:INFO:Copying training dataset
2024-12-29 18:07:52,027:INFO:Defining folds
2024-12-29 18:07:52,027:INFO:Declaring metric variables
2024-12-29 18:07:52,031:INFO:Importing untrained model
2024-12-29 18:07:52,034:INFO:Naive Bayes Imported successfully
2024-12-29 18:07:52,040:INFO:Starting cross validation
2024-12-29 18:07:52,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:52,204:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,204:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,205:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,206:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,212:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,215:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,215:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,216:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,221:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,229:INFO:Calculating mean and std
2024-12-29 18:07:52,231:INFO:Creating metrics dataframe
2024-12-29 18:07:52,233:INFO:Uploading results into container
2024-12-29 18:07:52,234:INFO:Uploading model into container now
2024-12-29 18:07:52,234:INFO:_master_model_container: 3
2024-12-29 18:07:52,234:INFO:_display_container: 2
2024-12-29 18:07:52,234:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-12-29 18:07:52,234:INFO:create_model() successfully completed......................................
2024-12-29 18:07:52,340:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:52,340:INFO:Creating metrics dataframe
2024-12-29 18:07:52,345:INFO:Initializing Decision Tree Classifier
2024-12-29 18:07:52,346:INFO:Total runtime is 0.10191032886505126 minutes
2024-12-29 18:07:52,349:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:52,349:INFO:Initializing create_model()
2024-12-29 18:07:52,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:52,349:INFO:Checking exceptions
2024-12-29 18:07:52,350:INFO:Importing libraries
2024-12-29 18:07:52,350:INFO:Copying training dataset
2024-12-29 18:07:52,354:INFO:Defining folds
2024-12-29 18:07:52,354:INFO:Declaring metric variables
2024-12-29 18:07:52,357:INFO:Importing untrained model
2024-12-29 18:07:52,360:INFO:Decision Tree Classifier Imported successfully
2024-12-29 18:07:52,367:INFO:Starting cross validation
2024-12-29 18:07:52,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:52,522:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,525:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,527:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,530:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,532:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,532:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,534:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,535:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,535:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,539:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,539:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,540:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,540:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,541:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,541:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,541:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:52,545:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,546:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,547:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,547:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:52,554:INFO:Calculating mean and std
2024-12-29 18:07:52,555:INFO:Creating metrics dataframe
2024-12-29 18:07:52,557:INFO:Uploading results into container
2024-12-29 18:07:52,558:INFO:Uploading model into container now
2024-12-29 18:07:52,558:INFO:_master_model_container: 4
2024-12-29 18:07:52,559:INFO:_display_container: 2
2024-12-29 18:07:52,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1136, splitter='best')
2024-12-29 18:07:52,559:INFO:create_model() successfully completed......................................
2024-12-29 18:07:52,663:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:52,663:INFO:Creating metrics dataframe
2024-12-29 18:07:52,670:INFO:Initializing SVM - Linear Kernel
2024-12-29 18:07:52,670:INFO:Total runtime is 0.10731997489929199 minutes
2024-12-29 18:07:52,673:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:52,673:INFO:Initializing create_model()
2024-12-29 18:07:52,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:52,673:INFO:Checking exceptions
2024-12-29 18:07:52,674:INFO:Importing libraries
2024-12-29 18:07:52,674:INFO:Copying training dataset
2024-12-29 18:07:52,677:INFO:Defining folds
2024-12-29 18:07:52,677:INFO:Declaring metric variables
2024-12-29 18:07:52,681:INFO:Importing untrained model
2024-12-29 18:07:52,685:INFO:SVM - Linear Kernel Imported successfully
2024-12-29 18:07:52,691:INFO:Starting cross validation
2024-12-29 18:07:52,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:52,883:INFO:Calculating mean and std
2024-12-29 18:07:52,884:INFO:Creating metrics dataframe
2024-12-29 18:07:52,887:INFO:Uploading results into container
2024-12-29 18:07:52,888:INFO:Uploading model into container now
2024-12-29 18:07:52,888:INFO:_master_model_container: 5
2024-12-29 18:07:52,888:INFO:_display_container: 2
2024-12-29 18:07:52,889:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1136, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-12-29 18:07:52,889:INFO:create_model() successfully completed......................................
2024-12-29 18:07:52,998:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:52,998:INFO:Creating metrics dataframe
2024-12-29 18:07:53,004:INFO:Initializing Ridge Classifier
2024-12-29 18:07:53,005:INFO:Total runtime is 0.11289403438568114 minutes
2024-12-29 18:07:53,008:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:53,008:INFO:Initializing create_model()
2024-12-29 18:07:53,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:53,008:INFO:Checking exceptions
2024-12-29 18:07:53,009:INFO:Importing libraries
2024-12-29 18:07:53,009:INFO:Copying training dataset
2024-12-29 18:07:53,012:INFO:Defining folds
2024-12-29 18:07:53,012:INFO:Declaring metric variables
2024-12-29 18:07:53,015:INFO:Importing untrained model
2024-12-29 18:07:53,019:INFO:Ridge Classifier Imported successfully
2024-12-29 18:07:53,024:INFO:Starting cross validation
2024-12-29 18:07:53,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:53,259:INFO:Calculating mean and std
2024-12-29 18:07:53,260:INFO:Creating metrics dataframe
2024-12-29 18:07:53,263:INFO:Uploading results into container
2024-12-29 18:07:53,263:INFO:Uploading model into container now
2024-12-29 18:07:53,264:INFO:_master_model_container: 6
2024-12-29 18:07:53,264:INFO:_display_container: 2
2024-12-29 18:07:53,264:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1136, solver='auto',
                tol=0.0001)
2024-12-29 18:07:53,264:INFO:create_model() successfully completed......................................
2024-12-29 18:07:53,364:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:53,364:INFO:Creating metrics dataframe
2024-12-29 18:07:53,371:INFO:Initializing Random Forest Classifier
2024-12-29 18:07:53,371:INFO:Total runtime is 0.11901654402414957 minutes
2024-12-29 18:07:53,374:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:53,374:INFO:Initializing create_model()
2024-12-29 18:07:53,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:53,375:INFO:Checking exceptions
2024-12-29 18:07:53,375:INFO:Importing libraries
2024-12-29 18:07:53,375:INFO:Copying training dataset
2024-12-29 18:07:53,379:INFO:Defining folds
2024-12-29 18:07:53,379:INFO:Declaring metric variables
2024-12-29 18:07:53,381:INFO:Importing untrained model
2024-12-29 18:07:53,386:INFO:Random Forest Classifier Imported successfully
2024-12-29 18:07:53,392:INFO:Starting cross validation
2024-12-29 18:07:53,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:53,774:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,779:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,784:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,785:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,788:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,788:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,794:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,795:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:53,797:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,799:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,801:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:53,809:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:53,813:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:53,817:INFO:Calculating mean and std
2024-12-29 18:07:53,819:INFO:Creating metrics dataframe
2024-12-29 18:07:53,820:INFO:Uploading results into container
2024-12-29 18:07:53,821:INFO:Uploading model into container now
2024-12-29 18:07:53,822:INFO:_master_model_container: 7
2024-12-29 18:07:53,822:INFO:_display_container: 2
2024-12-29 18:07:53,822:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1136, verbose=0,
                       warm_start=False)
2024-12-29 18:07:53,822:INFO:create_model() successfully completed......................................
2024-12-29 18:07:53,922:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:53,923:INFO:Creating metrics dataframe
2024-12-29 18:07:53,930:INFO:Initializing Quadratic Discriminant Analysis
2024-12-29 18:07:53,931:INFO:Total runtime is 0.12832130591074625 minutes
2024-12-29 18:07:53,933:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:53,933:INFO:Initializing create_model()
2024-12-29 18:07:53,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:53,934:INFO:Checking exceptions
2024-12-29 18:07:53,934:INFO:Importing libraries
2024-12-29 18:07:53,934:INFO:Copying training dataset
2024-12-29 18:07:53,938:INFO:Defining folds
2024-12-29 18:07:53,938:INFO:Declaring metric variables
2024-12-29 18:07:53,940:INFO:Importing untrained model
2024-12-29 18:07:53,944:INFO:Quadratic Discriminant Analysis Imported successfully
2024-12-29 18:07:53,950:INFO:Starting cross validation
2024-12-29 18:07:53,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,082:WARNING:d:\Anaconda\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-12-29 18:07:54,124:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,126:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,127:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,128:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,130:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,132:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,137:INFO:Calculating mean and std
2024-12-29 18:07:54,138:INFO:Creating metrics dataframe
2024-12-29 18:07:54,141:INFO:Uploading results into container
2024-12-29 18:07:54,142:INFO:Uploading model into container now
2024-12-29 18:07:54,142:INFO:_master_model_container: 8
2024-12-29 18:07:54,142:INFO:_display_container: 2
2024-12-29 18:07:54,143:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-12-29 18:07:54,143:INFO:create_model() successfully completed......................................
2024-12-29 18:07:54,245:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:54,245:INFO:Creating metrics dataframe
2024-12-29 18:07:54,252:INFO:Initializing Ada Boost Classifier
2024-12-29 18:07:54,252:INFO:Total runtime is 0.1336982766787211 minutes
2024-12-29 18:07:54,255:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:54,256:INFO:Initializing create_model()
2024-12-29 18:07:54,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:54,256:INFO:Checking exceptions
2024-12-29 18:07:54,256:INFO:Importing libraries
2024-12-29 18:07:54,256:INFO:Copying training dataset
2024-12-29 18:07:54,260:INFO:Defining folds
2024-12-29 18:07:54,261:INFO:Declaring metric variables
2024-12-29 18:07:54,264:INFO:Importing untrained model
2024-12-29 18:07:54,268:INFO:Ada Boost Classifier Imported successfully
2024-12-29 18:07:54,277:INFO:Starting cross validation
2024-12-29 18:07:54,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:54,395:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,396:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,396:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,396:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,397:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,399:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,401:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,408:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,412:WARNING:d:\Anaconda\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-12-29 18:07:54,450:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,456:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,458:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,459:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,459:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,461:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,464:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,466:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,467:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,473:INFO:Calculating mean and std
2024-12-29 18:07:54,474:INFO:Creating metrics dataframe
2024-12-29 18:07:54,477:INFO:Uploading results into container
2024-12-29 18:07:54,477:INFO:Uploading model into container now
2024-12-29 18:07:54,478:INFO:_master_model_container: 9
2024-12-29 18:07:54,478:INFO:_display_container: 2
2024-12-29 18:07:54,478:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1136)
2024-12-29 18:07:54,479:INFO:create_model() successfully completed......................................
2024-12-29 18:07:54,587:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:54,587:INFO:Creating metrics dataframe
2024-12-29 18:07:54,595:INFO:Initializing Gradient Boosting Classifier
2024-12-29 18:07:54,596:INFO:Total runtime is 0.13941990534464518 minutes
2024-12-29 18:07:54,598:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:54,599:INFO:Initializing create_model()
2024-12-29 18:07:54,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:54,599:INFO:Checking exceptions
2024-12-29 18:07:54,599:INFO:Importing libraries
2024-12-29 18:07:54,599:INFO:Copying training dataset
2024-12-29 18:07:54,603:INFO:Defining folds
2024-12-29 18:07:54,603:INFO:Declaring metric variables
2024-12-29 18:07:54,608:INFO:Importing untrained model
2024-12-29 18:07:54,610:INFO:Gradient Boosting Classifier Imported successfully
2024-12-29 18:07:54,617:INFO:Starting cross validation
2024-12-29 18:07:54,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:54,868:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,869:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,869:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,870:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,870:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,870:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,872:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,879:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,881:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,883:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:54,889:INFO:Calculating mean and std
2024-12-29 18:07:54,890:INFO:Creating metrics dataframe
2024-12-29 18:07:54,892:INFO:Uploading results into container
2024-12-29 18:07:54,892:INFO:Uploading model into container now
2024-12-29 18:07:54,892:INFO:_master_model_container: 10
2024-12-29 18:07:54,892:INFO:_display_container: 2
2024-12-29 18:07:54,893:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1136, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-12-29 18:07:54,893:INFO:create_model() successfully completed......................................
2024-12-29 18:07:54,994:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:54,994:INFO:Creating metrics dataframe
2024-12-29 18:07:55,002:INFO:Initializing Linear Discriminant Analysis
2024-12-29 18:07:55,002:INFO:Total runtime is 0.14619641701380412 minutes
2024-12-29 18:07:55,005:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:55,006:INFO:Initializing create_model()
2024-12-29 18:07:55,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:55,006:INFO:Checking exceptions
2024-12-29 18:07:55,006:INFO:Importing libraries
2024-12-29 18:07:55,006:INFO:Copying training dataset
2024-12-29 18:07:55,010:INFO:Defining folds
2024-12-29 18:07:55,010:INFO:Declaring metric variables
2024-12-29 18:07:55,014:INFO:Importing untrained model
2024-12-29 18:07:55,017:INFO:Linear Discriminant Analysis Imported successfully
2024-12-29 18:07:55,022:INFO:Starting cross validation
2024-12-29 18:07:55,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:55,174:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,174:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,175:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,182:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,185:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,185:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,188:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,191:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,194:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:55,200:INFO:Calculating mean and std
2024-12-29 18:07:55,201:INFO:Creating metrics dataframe
2024-12-29 18:07:55,203:INFO:Uploading results into container
2024-12-29 18:07:55,203:INFO:Uploading model into container now
2024-12-29 18:07:55,204:INFO:_master_model_container: 11
2024-12-29 18:07:55,204:INFO:_display_container: 2
2024-12-29 18:07:55,204:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-12-29 18:07:55,204:INFO:create_model() successfully completed......................................
2024-12-29 18:07:55,308:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:55,308:INFO:Creating metrics dataframe
2024-12-29 18:07:55,315:INFO:Initializing Extra Trees Classifier
2024-12-29 18:07:55,317:INFO:Total runtime is 0.15143440961837767 minutes
2024-12-29 18:07:55,319:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:55,320:INFO:Initializing create_model()
2024-12-29 18:07:55,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:55,320:INFO:Checking exceptions
2024-12-29 18:07:55,320:INFO:Importing libraries
2024-12-29 18:07:55,320:INFO:Copying training dataset
2024-12-29 18:07:55,324:INFO:Defining folds
2024-12-29 18:07:55,324:INFO:Declaring metric variables
2024-12-29 18:07:55,327:INFO:Importing untrained model
2024-12-29 18:07:55,330:INFO:Extra Trees Classifier Imported successfully
2024-12-29 18:07:55,336:INFO:Starting cross validation
2024-12-29 18:07:55,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:55,641:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,642:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,643:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,647:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,649:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,652:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,658:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,663:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,666:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,670:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:55,679:INFO:Calculating mean and std
2024-12-29 18:07:55,680:INFO:Creating metrics dataframe
2024-12-29 18:07:55,682:INFO:Uploading results into container
2024-12-29 18:07:55,682:INFO:Uploading model into container now
2024-12-29 18:07:55,682:INFO:_master_model_container: 12
2024-12-29 18:07:55,684:INFO:_display_container: 2
2024-12-29 18:07:55,684:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1136, verbose=0,
                     warm_start=False)
2024-12-29 18:07:55,684:INFO:create_model() successfully completed......................................
2024-12-29 18:07:55,787:INFO:SubProcess create_model() end ==================================
2024-12-29 18:07:55,787:INFO:Creating metrics dataframe
2024-12-29 18:07:55,795:INFO:Initializing Extreme Gradient Boosting
2024-12-29 18:07:55,795:INFO:Total runtime is 0.1594126303990682 minutes
2024-12-29 18:07:55,797:INFO:SubProcess create_model() called ==================================
2024-12-29 18:07:55,797:INFO:Initializing create_model()
2024-12-29 18:07:55,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:07:55,798:INFO:Checking exceptions
2024-12-29 18:07:55,798:INFO:Importing libraries
2024-12-29 18:07:55,798:INFO:Copying training dataset
2024-12-29 18:07:55,803:INFO:Defining folds
2024-12-29 18:07:55,803:INFO:Declaring metric variables
2024-12-29 18:07:55,806:INFO:Importing untrained model
2024-12-29 18:07:55,810:INFO:Extreme Gradient Boosting Imported successfully
2024-12-29 18:07:55,816:INFO:Starting cross validation
2024-12-29 18:07:55,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:07:58,713:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,721:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,723:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,727:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,741:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,747:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,750:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,753:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,757:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,759:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,762:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,768:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,816:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,823:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,832:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,839:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,875:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,884:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:07:58,923:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:07:58,929:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:01,025:INFO:Calculating mean and std
2024-12-29 18:08:01,026:INFO:Creating metrics dataframe
2024-12-29 18:08:01,027:INFO:Uploading results into container
2024-12-29 18:08:01,028:INFO:Uploading model into container now
2024-12-29 18:08:01,028:INFO:_master_model_container: 13
2024-12-29 18:08:01,028:INFO:_display_container: 2
2024-12-29 18:08:01,029:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-12-29 18:08:01,029:INFO:create_model() successfully completed......................................
2024-12-29 18:08:01,147:INFO:SubProcess create_model() end ==================================
2024-12-29 18:08:01,147:INFO:Creating metrics dataframe
2024-12-29 18:08:01,156:INFO:Initializing Light Gradient Boosting Machine
2024-12-29 18:08:01,156:INFO:Total runtime is 0.2487621863683065 minutes
2024-12-29 18:08:01,160:INFO:SubProcess create_model() called ==================================
2024-12-29 18:08:01,160:INFO:Initializing create_model()
2024-12-29 18:08:01,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:08:01,160:INFO:Checking exceptions
2024-12-29 18:08:01,161:INFO:Importing libraries
2024-12-29 18:08:01,161:INFO:Copying training dataset
2024-12-29 18:08:01,166:INFO:Defining folds
2024-12-29 18:08:01,166:INFO:Declaring metric variables
2024-12-29 18:08:01,170:INFO:Importing untrained model
2024-12-29 18:08:01,174:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-29 18:08:01,182:INFO:Starting cross validation
2024-12-29 18:08:01,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:08:07,006:WARNING:d:\Anaconda\lib\site-packages\joblib\externals\loky\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-12-29 18:08:07,266:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,283:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,312:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,317:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,523:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,532:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,540:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,541:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,547:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,547:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,570:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,576:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,680:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,686:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,686:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,693:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,706:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,713:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,777:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:07,782:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:07,788:INFO:Calculating mean and std
2024-12-29 18:08:07,789:INFO:Creating metrics dataframe
2024-12-29 18:08:07,792:INFO:Uploading results into container
2024-12-29 18:08:07,793:INFO:Uploading model into container now
2024-12-29 18:08:07,794:INFO:_master_model_container: 14
2024-12-29 18:08:07,794:INFO:_display_container: 2
2024-12-29 18:08:07,795:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1136, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-12-29 18:08:07,795:INFO:create_model() successfully completed......................................
2024-12-29 18:08:07,917:INFO:SubProcess create_model() end ==================================
2024-12-29 18:08:07,917:INFO:Creating metrics dataframe
2024-12-29 18:08:07,927:INFO:Initializing CatBoost Classifier
2024-12-29 18:08:07,927:INFO:Total runtime is 0.3616088509559632 minutes
2024-12-29 18:08:07,930:INFO:SubProcess create_model() called ==================================
2024-12-29 18:08:07,930:INFO:Initializing create_model()
2024-12-29 18:08:07,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:08:07,930:INFO:Checking exceptions
2024-12-29 18:08:07,931:INFO:Importing libraries
2024-12-29 18:08:07,931:INFO:Copying training dataset
2024-12-29 18:08:07,934:INFO:Defining folds
2024-12-29 18:08:07,935:INFO:Declaring metric variables
2024-12-29 18:08:07,938:INFO:Importing untrained model
2024-12-29 18:08:07,941:INFO:CatBoost Classifier Imported successfully
2024-12-29 18:08:07,953:INFO:Starting cross validation
2024-12-29 18:08:07,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:08:11,326:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:11,333:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:11,622:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:11,629:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:11,832:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:11,839:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:11,942:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:11,948:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:12,002:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:12,008:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:12,152:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:12,160:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:12,340:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:12,346:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,305:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,310:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,311:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,312:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,316:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,318:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,323:INFO:Calculating mean and std
2024-12-29 18:08:13,324:INFO:Creating metrics dataframe
2024-12-29 18:08:13,328:INFO:Uploading results into container
2024-12-29 18:08:13,328:INFO:Uploading model into container now
2024-12-29 18:08:13,329:INFO:_master_model_container: 15
2024-12-29 18:08:13,329:INFO:_display_container: 2
2024-12-29 18:08:13,329:INFO:<catboost.core.CatBoostClassifier object at 0x000001C5893B3370>
2024-12-29 18:08:13,329:INFO:create_model() successfully completed......................................
2024-12-29 18:08:13,448:INFO:SubProcess create_model() end ==================================
2024-12-29 18:08:13,448:INFO:Creating metrics dataframe
2024-12-29 18:08:13,457:INFO:Initializing Dummy Classifier
2024-12-29 18:08:13,457:INFO:Total runtime is 0.4537785212198894 minutes
2024-12-29 18:08:13,460:INFO:SubProcess create_model() called ==================================
2024-12-29 18:08:13,460:INFO:Initializing create_model()
2024-12-29 18:08:13,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C5830497E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:08:13,460:INFO:Checking exceptions
2024-12-29 18:08:13,460:INFO:Importing libraries
2024-12-29 18:08:13,460:INFO:Copying training dataset
2024-12-29 18:08:13,465:INFO:Defining folds
2024-12-29 18:08:13,465:INFO:Declaring metric variables
2024-12-29 18:08:13,468:INFO:Importing untrained model
2024-12-29 18:08:13,474:INFO:Dummy Classifier Imported successfully
2024-12-29 18:08:13,484:INFO:Starting cross validation
2024-12-29 18:08:13,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:08:13,640:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,641:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,645:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,647:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,647:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,647:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,649:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,651:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,654:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,655:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,655:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,655:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,659:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,660:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,662:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,665:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,666:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,667:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\Anaconda\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "d:\Anaconda\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "d:\Anaconda\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "d:\Anaconda\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "d:\Anaconda\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "d:\Anaconda\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-12-29 18:08:13,669:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,670:WARNING:d:\Anaconda\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-12-29 18:08:13,675:INFO:Calculating mean and std
2024-12-29 18:08:13,676:INFO:Creating metrics dataframe
2024-12-29 18:08:13,678:INFO:Uploading results into container
2024-12-29 18:08:13,679:INFO:Uploading model into container now
2024-12-29 18:08:13,679:INFO:_master_model_container: 16
2024-12-29 18:08:13,679:INFO:_display_container: 2
2024-12-29 18:08:13,679:INFO:DummyClassifier(constant=None, random_state=1136, strategy='prior')
2024-12-29 18:08:13,680:INFO:create_model() successfully completed......................................
2024-12-29 18:08:13,788:INFO:SubProcess create_model() end ==================================
2024-12-29 18:08:13,788:INFO:Creating metrics dataframe
2024-12-29 18:08:13,803:WARNING:d:\Anaconda\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-12-29 18:08:13,810:INFO:Initializing create_model()
2024-12-29 18:08:13,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:08:13,810:INFO:Checking exceptions
2024-12-29 18:08:13,811:INFO:Importing libraries
2024-12-29 18:08:13,811:INFO:Copying training dataset
2024-12-29 18:08:13,815:INFO:Defining folds
2024-12-29 18:08:13,815:INFO:Declaring metric variables
2024-12-29 18:08:13,816:INFO:Importing untrained model
2024-12-29 18:08:13,816:INFO:Declaring custom model
2024-12-29 18:08:13,816:INFO:Logistic Regression Imported successfully
2024-12-29 18:08:13,817:INFO:Cross validation set to False
2024-12-29 18:08:13,817:INFO:Fitting Model
2024-12-29 18:08:13,962:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:08:13,963:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:08:13,963:INFO:create_model() successfully completed......................................
2024-12-29 18:08:14,085:INFO:_master_model_container: 16
2024-12-29 18:08:14,085:INFO:_display_container: 2
2024-12-29 18:08:14,086:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:08:14,086:INFO:compare_models() successfully completed......................................
2024-12-29 18:10:37,001:INFO:Initializing finalize_model()
2024-12-29 18:10:37,001:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 18:10:37,002:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:10:37,006:INFO:Initializing create_model()
2024-12-29 18:10:37,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:10:37,006:INFO:Checking exceptions
2024-12-29 18:10:37,007:INFO:Importing libraries
2024-12-29 18:10:37,007:INFO:Copying training dataset
2024-12-29 18:10:37,008:INFO:Defining folds
2024-12-29 18:10:37,008:INFO:Declaring metric variables
2024-12-29 18:10:37,008:INFO:Importing untrained model
2024-12-29 18:10:37,008:INFO:Declaring custom model
2024-12-29 18:10:37,009:INFO:Logistic Regression Imported successfully
2024-12-29 18:10:37,010:INFO:Cross validation set to False
2024-12-29 18:10:37,010:INFO:Fitting Model
2024-12-29 18:10:37,181:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:10:37,198:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-12-29 18:10:37,199:INFO:create_model() successfully completed......................................
2024-12-29 18:10:37,302:INFO:_master_model_container: 16
2024-12-29 18:10:37,302:INFO:_display_container: 2
2024-12-29 18:10:37,318:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-12-29 18:10:37,318:INFO:finalize_model() successfully completed......................................
2024-12-29 18:11:05,051:INFO:Initializing evaluate_model()
2024-12-29 18:11:05,051:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-12-29 18:11:05,063:INFO:Initializing plot_model()
2024-12-29 18:11:05,063:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:11:05,063:INFO:Checking exceptions
2024-12-29 18:11:05,066:INFO:Preloading libraries
2024-12-29 18:11:05,066:INFO:Copying training dataset
2024-12-29 18:11:05,066:INFO:Plot type: pipeline
2024-12-29 18:11:05,275:INFO:Visual Rendered Successfully
2024-12-29 18:11:05,391:INFO:plot_model() successfully completed......................................
2024-12-29 18:12:23,383:INFO:Initializing plot_model()
2024-12-29 18:12:23,383:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:12:23,383:INFO:Checking exceptions
2024-12-29 18:12:23,384:INFO:Preloading libraries
2024-12-29 18:12:23,386:INFO:Copying training dataset
2024-12-29 18:12:23,386:INFO:Plot type: auc
2024-12-29 18:12:23,869:INFO:Fitting Model
2024-12-29 18:12:23,870:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:12:23,870:INFO:Scoring test/hold-out set
2024-12-29 18:12:24,001:INFO:Visual Rendered Successfully
2024-12-29 18:12:24,102:INFO:plot_model() successfully completed......................................
2024-12-29 18:12:24,145:INFO:Initializing plot_model()
2024-12-29 18:12:24,145:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:12:24,145:INFO:Checking exceptions
2024-12-29 18:12:24,147:INFO:Preloading libraries
2024-12-29 18:12:24,147:INFO:Copying training dataset
2024-12-29 18:12:24,147:INFO:Plot type: confusion_matrix
2024-12-29 18:12:24,392:INFO:Fitting Model
2024-12-29 18:12:24,392:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:12:24,392:INFO:Scoring test/hold-out set
2024-12-29 18:12:24,467:INFO:Visual Rendered Successfully
2024-12-29 18:12:24,576:INFO:plot_model() successfully completed......................................
2024-12-29 18:12:26,791:INFO:Initializing plot_model()
2024-12-29 18:12:26,791:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:12:26,792:INFO:Checking exceptions
2024-12-29 18:12:26,794:INFO:Preloading libraries
2024-12-29 18:12:26,794:INFO:Copying training dataset
2024-12-29 18:12:26,794:INFO:Plot type: learning
2024-12-29 18:12:27,057:INFO:Fitting Model
2024-12-29 18:12:27,145:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,238:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,399:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,493:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,619:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,717:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,807:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,899:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:27,992:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,131:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,221:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,326:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,436:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,556:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,668:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,769:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,873:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:28,987:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,074:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,165:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,258:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,339:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,424:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,529:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,624:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,710:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,803:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,906:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:29,984:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,063:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,142:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,224:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,306:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,402:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,519:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,608:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,700:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,795:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:30,872:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,031:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,112:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,197:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,297:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,382:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,469:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,561:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,656:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,737:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,895:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:31,980:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,064:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,154:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,259:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,351:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,456:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,551:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,640:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,810:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,903:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:32,988:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,092:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,184:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,285:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,387:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,493:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,573:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,732:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,825:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:33,910:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,021:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,110:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,205:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,296:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,387:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,484:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,649:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,734:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,818:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:34,915:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,007:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,105:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,203:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,297:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,386:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,546:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,651:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,744:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,833:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:35,934:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:36,041:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:36,171:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:36,287:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:12:36,444:INFO:Visual Rendered Successfully
2024-12-29 18:12:36,550:INFO:plot_model() successfully completed......................................
2024-12-29 18:12:36,608:INFO:Initializing plot_model()
2024-12-29 18:12:36,608:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:12:36,608:INFO:Checking exceptions
2024-12-29 18:12:36,610:INFO:Preloading libraries
2024-12-29 18:12:36,611:INFO:Copying training dataset
2024-12-29 18:12:36,611:INFO:Plot type: feature
2024-12-29 18:12:36,776:INFO:Visual Rendered Successfully
2024-12-29 18:12:36,879:INFO:plot_model() successfully completed......................................
2024-12-29 18:13:27,446:INFO:Initializing plot_model()
2024-12-29 18:13:27,446:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:13:27,446:INFO:Checking exceptions
2024-12-29 18:13:27,449:INFO:Preloading libraries
2024-12-29 18:13:27,449:INFO:Copying training dataset
2024-12-29 18:13:27,449:INFO:Plot type: boundary
2024-12-29 18:13:27,584:INFO:Fitting StandardScaler()
2024-12-29 18:13:27,587:INFO:Fitting PCA()
2024-12-29 18:13:27,733:INFO:Fitting Model
2024-12-29 18:13:28,520:INFO:Visual Rendered Successfully
2024-12-29 18:13:28,651:INFO:plot_model() successfully completed......................................
2024-12-29 18:14:34,753:INFO:Initializing plot_model()
2024-12-29 18:14:34,754:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:14:34,754:INFO:Checking exceptions
2024-12-29 18:14:34,758:INFO:Preloading libraries
2024-12-29 18:14:34,759:INFO:Copying training dataset
2024-12-29 18:14:34,759:INFO:Plot type: feature_all
2024-12-29 18:14:35,079:INFO:Visual Rendered Successfully
2024-12-29 18:14:35,192:INFO:plot_model() successfully completed......................................
2024-12-29 18:14:38,252:INFO:Initializing plot_model()
2024-12-29 18:14:38,252:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:14:38,252:INFO:Checking exceptions
2024-12-29 18:14:42,286:INFO:Initializing plot_model()
2024-12-29 18:14:42,286:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:14:42,286:INFO:Checking exceptions
2024-12-29 18:14:42,289:INFO:Preloading libraries
2024-12-29 18:14:42,289:INFO:Copying training dataset
2024-12-29 18:14:42,289:INFO:Plot type: parameter
2024-12-29 18:14:42,292:INFO:Visual Rendered Successfully
2024-12-29 18:14:42,404:INFO:plot_model() successfully completed......................................
2024-12-29 18:14:43,611:INFO:Initializing plot_model()
2024-12-29 18:14:43,612:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:14:43,612:INFO:Checking exceptions
2024-12-29 18:14:43,614:INFO:Preloading libraries
2024-12-29 18:14:43,614:INFO:Copying training dataset
2024-12-29 18:14:43,614:INFO:Plot type: auc
2024-12-29 18:14:43,850:INFO:Fitting Model
2024-12-29 18:14:43,850:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:14:43,850:INFO:Scoring test/hold-out set
2024-12-29 18:14:43,964:INFO:Visual Rendered Successfully
2024-12-29 18:14:44,068:INFO:plot_model() successfully completed......................................
2024-12-29 18:15:14,896:INFO:Initializing plot_model()
2024-12-29 18:15:14,896:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:15:14,896:INFO:Checking exceptions
2024-12-29 18:15:14,899:INFO:Preloading libraries
2024-12-29 18:15:14,900:INFO:Copying training dataset
2024-12-29 18:15:14,900:INFO:Plot type: pipeline
2024-12-29 18:15:15,069:INFO:Visual Rendered Successfully
2024-12-29 18:15:15,196:INFO:plot_model() successfully completed......................................
2024-12-29 18:15:24,293:INFO:Initializing plot_model()
2024-12-29 18:15:24,293:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:15:24,293:INFO:Checking exceptions
2024-12-29 18:15:24,295:INFO:Preloading libraries
2024-12-29 18:15:24,296:INFO:Copying training dataset
2024-12-29 18:15:24,296:INFO:Plot type: gain
2024-12-29 18:15:24,296:INFO:Generating predictions / predict_proba on X_test
2024-12-29 18:15:24,604:INFO:Visual Rendered Successfully
2024-12-29 18:15:24,711:INFO:plot_model() successfully completed......................................
2024-12-29 18:15:27,220:INFO:Initializing plot_model()
2024-12-29 18:15:27,220:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:15:27,220:INFO:Checking exceptions
2024-12-29 18:15:27,223:INFO:Preloading libraries
2024-12-29 18:15:27,223:INFO:Copying training dataset
2024-12-29 18:15:27,223:INFO:Plot type: dimension
2024-12-29 18:15:27,292:INFO:Fitting StandardScaler()
2024-12-29 18:15:27,325:INFO:Fitting PCA()
2024-12-29 18:15:27,605:INFO:Fitting & Transforming Model
2024-12-29 18:15:27,698:INFO:Visual Rendered Successfully
2024-12-29 18:15:27,811:INFO:plot_model() successfully completed......................................
2024-12-29 18:15:32,483:INFO:Initializing plot_model()
2024-12-29 18:15:32,484:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:15:32,484:INFO:Checking exceptions
2024-12-29 18:15:32,486:INFO:Preloading libraries
2024-12-29 18:15:32,486:INFO:Copying training dataset
2024-12-29 18:15:32,486:INFO:Plot type: learning
2024-12-29 18:15:32,723:INFO:Fitting Model
2024-12-29 18:15:32,822:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:32,900:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,054:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,137:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,239:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,324:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,411:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,500:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,589:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,720:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,798:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,879:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:33,961:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,045:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,129:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,213:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,301:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,390:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,466:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,542:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,622:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,703:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,784:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,868:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:34,952:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,037:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,146:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,245:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,321:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,397:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,476:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,557:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,638:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,723:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,806:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,891:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:35,979:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,068:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,143:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,294:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,375:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,457:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,541:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,626:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,710:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,803:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,892:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:36,968:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,120:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,200:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,281:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,364:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,449:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,533:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,621:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,710:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,786:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:37,938:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,017:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,099:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,182:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,266:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,351:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,439:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,527:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,601:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,752:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,832:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,912:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:38,994:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,077:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,163:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,252:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,340:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,415:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,568:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,649:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,732:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,835:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:39,920:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,007:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,094:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,184:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,258:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,409:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,489:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,569:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,659:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,743:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,834:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:40,921:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:41,009:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:15:41,121:INFO:Visual Rendered Successfully
2024-12-29 18:15:41,227:INFO:plot_model() successfully completed......................................
2024-12-29 18:18:05,324:INFO:Initializing predict_model()
2024-12-29 18:18:05,324:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C5830571C0>)
2024-12-29 18:18:05,324:INFO:Checking exceptions
2024-12-29 18:18:05,324:INFO:Preloading libraries
2024-12-29 18:18:05,327:INFO:Set up data.
2024-12-29 18:18:05,335:INFO:Set up index.
2024-12-29 18:19:55,588:INFO:Initializing predict_model()
2024-12-29 18:19:55,588:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C5892CA710>)
2024-12-29 18:19:55,589:INFO:Checking exceptions
2024-12-29 18:19:55,589:INFO:Preloading libraries
2024-12-29 18:19:55,590:INFO:Set up data.
2024-12-29 18:19:55,596:INFO:Set up index.
2024-12-29 18:27:49,256:INFO:Initializing tune_model()
2024-12-29 18:27:49,256:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>)
2024-12-29 18:27:49,256:INFO:Checking exceptions
2024-12-29 18:27:49,276:INFO:Copying training dataset
2024-12-29 18:27:49,283:INFO:Checking base model
2024-12-29 18:27:49,283:INFO:Base model : Logistic Regression
2024-12-29 18:27:49,288:INFO:Declaring metric variables
2024-12-29 18:27:49,293:INFO:Defining Hyperparameters
2024-12-29 18:27:49,471:INFO:Tuning with n_jobs=-1
2024-12-29 18:27:49,471:INFO:Initializing RandomizedSearchCV
2024-12-29 18:27:53,588:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,602:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,607:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,613:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,623:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,698:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,727:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,761:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,776:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,776:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,784:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,784:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:53,950:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,022:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,025:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,047:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,049:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,131:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,149:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,181:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,198:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,214:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,232:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,235:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,274:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,345:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,355:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,388:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,389:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,472:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,504:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,524:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,532:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,562:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,574:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,582:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,589:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,646:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,680:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,735:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,746:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,813:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,819:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,833:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,844:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,889:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,902:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,911:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,931:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:54,946:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,046:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,081:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,086:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,133:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,134:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,145:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,153:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,212:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,213:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,236:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,304:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,311:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,394:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,420:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,431:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,446:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,454:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,465:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,470:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,518:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,537:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,545:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,647:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,680:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,700:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,744:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,750:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,752:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,790:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,791:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,802:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,844:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,860:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,899:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:55,949:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,009:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,030:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,061:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,070:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,073:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,114:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,117:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,143:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,151:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,166:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,203:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,243:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,285:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,304:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,308:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,333:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.436}
2024-12-29 18:27:56,334:INFO:Hyperparameter search completed
2024-12-29 18:27:56,334:INFO:SubProcess create_model() called ==================================
2024-12-29 18:27:56,334:INFO:Initializing create_model()
2024-12-29 18:27:56,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C58914B100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.436})
2024-12-29 18:27:56,336:INFO:Checking exceptions
2024-12-29 18:27:56,336:INFO:Importing libraries
2024-12-29 18:27:56,336:INFO:Copying training dataset
2024-12-29 18:27:56,340:INFO:Defining folds
2024-12-29 18:27:56,340:INFO:Declaring metric variables
2024-12-29 18:27:56,343:INFO:Importing untrained model
2024-12-29 18:27:56,343:INFO:Declaring custom model
2024-12-29 18:27:56,347:INFO:Logistic Regression Imported successfully
2024-12-29 18:27:56,353:INFO:Starting cross validation
2024-12-29 18:27:56,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:27:56,625:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,627:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,632:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,635:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,636:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,636:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,638:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,639:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,643:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,643:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,694:INFO:Calculating mean and std
2024-12-29 18:27:56,696:INFO:Creating metrics dataframe
2024-12-29 18:27:56,700:INFO:Finalizing model
2024-12-29 18:27:56,845:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:56,850:INFO:Uploading results into container
2024-12-29 18:27:56,851:INFO:Uploading model into container now
2024-12-29 18:27:56,851:INFO:_master_model_container: 17
2024-12-29 18:27:56,851:INFO:_display_container: 3
2024-12-29 18:27:56,852:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:27:56,852:INFO:create_model() successfully completed......................................
2024-12-29 18:27:57,013:INFO:SubProcess create_model() end ==================================
2024-12-29 18:27:57,013:INFO:choose_better activated
2024-12-29 18:27:57,016:INFO:SubProcess create_model() called ==================================
2024-12-29 18:27:57,018:INFO:Initializing create_model()
2024-12-29 18:27:57,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:27:57,018:INFO:Checking exceptions
2024-12-29 18:27:57,020:INFO:Importing libraries
2024-12-29 18:27:57,020:INFO:Copying training dataset
2024-12-29 18:27:57,024:INFO:Defining folds
2024-12-29 18:27:57,024:INFO:Declaring metric variables
2024-12-29 18:27:57,024:INFO:Importing untrained model
2024-12-29 18:27:57,024:INFO:Declaring custom model
2024-12-29 18:27:57,024:INFO:Logistic Regression Imported successfully
2024-12-29 18:27:57,024:INFO:Starting cross validation
2024-12-29 18:27:57,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:27:57,272:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,273:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,276:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,278:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,278:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,286:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,290:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,292:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,293:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,299:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,346:INFO:Calculating mean and std
2024-12-29 18:27:57,346:INFO:Creating metrics dataframe
2024-12-29 18:27:57,348:INFO:Finalizing model
2024-12-29 18:27:57,488:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:27:57,488:INFO:Uploading results into container
2024-12-29 18:27:57,489:INFO:Uploading model into container now
2024-12-29 18:27:57,489:INFO:_master_model_container: 18
2024-12-29 18:27:57,489:INFO:_display_container: 4
2024-12-29 18:27:57,490:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:27:57,490:INFO:create_model() successfully completed......................................
2024-12-29 18:27:57,644:INFO:SubProcess create_model() end ==================================
2024-12-29 18:27:57,645:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8267
2024-12-29 18:27:57,645:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8332
2024-12-29 18:27:57,646:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-12-29 18:27:57,646:INFO:choose_better completed
2024-12-29 18:27:57,654:INFO:_master_model_container: 18
2024-12-29 18:27:57,654:INFO:_display_container: 3
2024-12-29 18:27:57,654:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:27:57,654:INFO:tune_model() successfully completed......................................
2024-12-29 18:29:56,773:INFO:Initializing tune_model()
2024-12-29 18:29:56,773:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>)
2024-12-29 18:29:56,773:INFO:Checking exceptions
2024-12-29 18:29:56,791:INFO:Copying training dataset
2024-12-29 18:29:56,796:INFO:Checking base model
2024-12-29 18:29:56,796:INFO:Base model : Logistic Regression
2024-12-29 18:29:56,800:INFO:Declaring metric variables
2024-12-29 18:29:56,803:INFO:Defining Hyperparameters
2024-12-29 18:29:56,963:INFO:Tuning with n_jobs=-1
2024-12-29 18:29:56,963:INFO:Initializing RandomizedSearchCV
2024-12-29 18:29:57,255:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,259:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,262:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,272:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,274:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,276:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,282:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,282:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,285:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,288:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,298:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,311:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,640:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,671:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,676:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,685:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,685:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,701:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,726:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,730:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,734:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,744:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,817:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,876:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:57,978:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,000:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,023:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,026:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,028:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,052:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,114:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,117:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,121:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,184:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,306:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,320:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,349:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,351:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,352:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,386:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,408:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,433:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,468:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,509:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,585:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,589:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,670:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,682:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,741:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,750:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,778:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,781:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,799:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,832:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,855:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,939:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,940:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,985:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:58,994:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,016:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,080:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,092:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,104:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,121:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,122:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,172:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,191:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,254:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,269:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,296:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,308:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,311:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,419:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,425:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,438:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,451:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,461:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,494:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,511:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,584:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,598:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,605:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,615:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,634:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,742:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,754:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,760:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,780:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,804:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,826:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,838:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,893:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,915:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,921:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,929:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,939:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:29:59,999:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,014:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,025:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,026:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,052:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.436}
2024-12-29 18:30:00,052:INFO:Hyperparameter search completed
2024-12-29 18:30:00,052:INFO:SubProcess create_model() called ==================================
2024-12-29 18:30:00,054:INFO:Initializing create_model()
2024-12-29 18:30:00,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C58A8C3820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.436})
2024-12-29 18:30:00,054:INFO:Checking exceptions
2024-12-29 18:30:00,054:INFO:Importing libraries
2024-12-29 18:30:00,054:INFO:Copying training dataset
2024-12-29 18:30:00,059:INFO:Defining folds
2024-12-29 18:30:00,059:INFO:Declaring metric variables
2024-12-29 18:30:00,062:INFO:Importing untrained model
2024-12-29 18:30:00,062:INFO:Declaring custom model
2024-12-29 18:30:00,065:INFO:Logistic Regression Imported successfully
2024-12-29 18:30:00,071:INFO:Starting cross validation
2024-12-29 18:30:00,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:30:00,329:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,330:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,332:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,334:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,334:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,336:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,341:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,343:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,348:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,351:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,399:INFO:Calculating mean and std
2024-12-29 18:30:00,401:INFO:Creating metrics dataframe
2024-12-29 18:30:00,405:INFO:Finalizing model
2024-12-29 18:30:00,551:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,554:INFO:Uploading results into container
2024-12-29 18:30:00,555:INFO:Uploading model into container now
2024-12-29 18:30:00,555:INFO:_master_model_container: 19
2024-12-29 18:30:00,555:INFO:_display_container: 4
2024-12-29 18:30:00,556:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:30:00,556:INFO:create_model() successfully completed......................................
2024-12-29 18:30:00,718:INFO:SubProcess create_model() end ==================================
2024-12-29 18:30:00,718:INFO:choose_better activated
2024-12-29 18:30:00,721:INFO:SubProcess create_model() called ==================================
2024-12-29 18:30:00,722:INFO:Initializing create_model()
2024-12-29 18:30:00,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:30:00,722:INFO:Checking exceptions
2024-12-29 18:30:00,724:INFO:Importing libraries
2024-12-29 18:30:00,724:INFO:Copying training dataset
2024-12-29 18:30:00,727:INFO:Defining folds
2024-12-29 18:30:00,727:INFO:Declaring metric variables
2024-12-29 18:30:00,727:INFO:Importing untrained model
2024-12-29 18:30:00,728:INFO:Declaring custom model
2024-12-29 18:30:00,728:INFO:Logistic Regression Imported successfully
2024-12-29 18:30:00,728:INFO:Starting cross validation
2024-12-29 18:30:00,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-29 18:30:00,977:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,977:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,980:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,982:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,983:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,984:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,984:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,985:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,992:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:00,997:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:01,048:INFO:Calculating mean and std
2024-12-29 18:30:01,048:INFO:Creating metrics dataframe
2024-12-29 18:30:01,050:INFO:Finalizing model
2024-12-29 18:30:01,189:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:01,190:INFO:Uploading results into container
2024-12-29 18:30:01,190:INFO:Uploading model into container now
2024-12-29 18:30:01,191:INFO:_master_model_container: 20
2024-12-29 18:30:01,191:INFO:_display_container: 5
2024-12-29 18:30:01,191:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:30:01,191:INFO:create_model() successfully completed......................................
2024-12-29 18:30:01,346:INFO:SubProcess create_model() end ==================================
2024-12-29 18:30:01,347:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8267
2024-12-29 18:30:01,347:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8332
2024-12-29 18:30:01,347:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-12-29 18:30:01,347:INFO:choose_better completed
2024-12-29 18:30:01,355:INFO:_master_model_container: 20
2024-12-29 18:30:01,355:INFO:_display_container: 4
2024-12-29 18:30:01,355:INFO:LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:30:01,355:INFO:tune_model() successfully completed......................................
2024-12-29 18:30:55,608:INFO:Initializing finalize_model()
2024-12-29 18:30:55,608:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 18:30:55,609:INFO:Finalizing LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:30:55,613:INFO:Initializing create_model()
2024-12-29 18:30:55,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:30:55,614:INFO:Checking exceptions
2024-12-29 18:30:55,616:INFO:Importing libraries
2024-12-29 18:30:55,616:INFO:Copying training dataset
2024-12-29 18:30:55,617:INFO:Defining folds
2024-12-29 18:30:55,617:INFO:Declaring metric variables
2024-12-29 18:30:55,617:INFO:Importing untrained model
2024-12-29 18:30:55,617:INFO:Declaring custom model
2024-12-29 18:30:55,617:INFO:Logistic Regression Imported successfully
2024-12-29 18:30:55,619:INFO:Cross validation set to False
2024-12-29 18:30:55,619:INFO:Fitting Model
2024-12-29 18:30:55,797:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:30:55,815:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-12-29 18:30:55,815:INFO:create_model() successfully completed......................................
2024-12-29 18:30:55,973:INFO:_master_model_container: 20
2024-12-29 18:30:55,973:INFO:_display_container: 4
2024-12-29 18:30:55,989:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-12-29 18:30:55,989:INFO:finalize_model() successfully completed......................................
2024-12-29 18:31:19,716:INFO:Initializing finalize_model()
2024-12-29 18:31:19,717:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-12-29 18:31:19,717:INFO:Finalizing LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-12-29 18:31:19,721:INFO:Initializing create_model()
2024-12-29 18:31:19,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=LogisticRegression(C=2.436, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1136, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-12-29 18:31:19,722:INFO:Checking exceptions
2024-12-29 18:31:19,724:INFO:Importing libraries
2024-12-29 18:31:19,724:INFO:Copying training dataset
2024-12-29 18:31:19,724:INFO:Defining folds
2024-12-29 18:31:19,724:INFO:Declaring metric variables
2024-12-29 18:31:19,725:INFO:Importing untrained model
2024-12-29 18:31:19,725:INFO:Declaring custom model
2024-12-29 18:31:19,726:INFO:Logistic Regression Imported successfully
2024-12-29 18:31:19,727:INFO:Cross validation set to False
2024-12-29 18:31:19,729:INFO:Fitting Model
2024-12-29 18:31:19,922:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:19,940:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-12-29 18:31:19,940:INFO:create_model() successfully completed......................................
2024-12-29 18:31:20,096:INFO:_master_model_container: 20
2024-12-29 18:31:20,096:INFO:_display_container: 4
2024-12-29 18:31:20,111:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-12-29 18:31:20,111:INFO:finalize_model() successfully completed......................................
2024-12-29 18:31:30,938:INFO:Initializing evaluate_model()
2024-12-29 18:31:30,939:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-12-29 18:31:30,965:INFO:Initializing plot_model()
2024-12-29 18:31:30,965:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:31:30,967:INFO:Checking exceptions
2024-12-29 18:31:30,969:INFO:Preloading libraries
2024-12-29 18:31:30,969:INFO:Copying training dataset
2024-12-29 18:31:30,970:INFO:Plot type: pipeline
2024-12-29 18:31:31,108:INFO:Visual Rendered Successfully
2024-12-29 18:31:31,262:INFO:plot_model() successfully completed......................................
2024-12-29 18:31:40,016:INFO:Initializing plot_model()
2024-12-29 18:31:40,016:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:31:40,016:INFO:Checking exceptions
2024-12-29 18:31:40,018:INFO:Preloading libraries
2024-12-29 18:31:40,020:INFO:Copying training dataset
2024-12-29 18:31:40,020:INFO:Plot type: rfe
2024-12-29 18:31:40,253:INFO:Fitting Model
2024-12-29 18:31:40,352:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:40,535:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:40,732:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:40,822:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:40,977:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:41,159:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:41,337:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:41,520:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:41,740:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:41,831:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:41,977:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:42,164:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:42,256:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:42,417:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:42,595:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:42,791:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:42,881:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:43,033:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:43,213:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:43,390:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:43,570:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:43,790:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:43,880:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,022:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,205:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,297:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,449:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,621:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,811:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:44,902:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:45,055:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:45,233:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:45,406:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:45,596:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:45,819:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:45,910:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,056:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,241:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,332:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,482:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,648:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,835:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:46,933:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:47,088:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:47,264:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:47,438:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:47,617:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:47,833:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:47,924:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,062:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,239:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,328:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,475:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,638:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,822:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:48,912:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:49,057:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:49,225:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:49,391:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:49,565:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:49,777:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:49,866:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,003:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,177:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,266:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,407:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,569:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,754:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,847:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:50,991:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:51,158:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:51,320:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:51,491:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:51,704:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:51,795:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:51,935:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,111:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,202:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,344:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,507:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,703:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,795:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:52,938:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:53,109:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:53,274:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:53,446:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:53,660:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:53,751:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:53,883:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,056:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,147:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,284:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,439:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,617:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,708:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:54,854:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,037:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,198:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,376:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,608:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,698:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,828:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:55,999:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,091:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,227:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,381:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,555:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,646:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,778:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:56,937:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,092:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,257:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,462:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,552:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,676:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,843:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:57,934:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,069:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,220:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,388:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,481:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,610:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,767:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:58,921:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,081:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,264:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,353:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,472:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,633:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,723:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,850:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:31:59,997:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,163:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,255:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,369:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,523:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,669:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,816:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:00,982:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,072:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,185:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,339:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,428:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,537:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,665:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,814:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,904:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:01,995:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,124:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,250:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,378:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,517:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,607:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,698:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,833:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:02,924:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,015:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,106:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,196:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,287:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,377:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,468:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,561:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,651:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,741:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,833:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:03,927:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:04,133:INFO:Visual Rendered Successfully
2024-12-29 18:32:04,285:INFO:plot_model() successfully completed......................................
2024-12-29 18:32:04,359:INFO:Initializing plot_model()
2024-12-29 18:32:04,359:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:32:04,360:INFO:Checking exceptions
2024-12-29 18:32:04,363:INFO:Preloading libraries
2024-12-29 18:32:04,363:INFO:Copying training dataset
2024-12-29 18:32:04,363:INFO:Plot type: feature
2024-12-29 18:32:04,520:INFO:Visual Rendered Successfully
2024-12-29 18:32:04,675:INFO:plot_model() successfully completed......................................
2024-12-29 18:32:06,095:INFO:Initializing plot_model()
2024-12-29 18:32:06,095:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:32:06,095:INFO:Checking exceptions
2024-12-29 18:32:06,098:INFO:Preloading libraries
2024-12-29 18:32:06,098:INFO:Copying training dataset
2024-12-29 18:32:06,098:INFO:Plot type: rfe
2024-12-29 18:32:06,325:INFO:Fitting Model
2024-12-29 18:32:06,423:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:06,604:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:06,797:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:06,888:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:07,043:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:07,222:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:07,397:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:07,580:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:07,801:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:07,888:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,032:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,216:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,306:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,458:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,634:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,827:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:08,917:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:09,069:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:09,247:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:09,424:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:09,609:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:09,833:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:09,922:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,064:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,248:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,338:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,492:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,662:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,853:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:10,943:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:11,093:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:11,265:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:11,432:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:11,609:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:11,824:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:11,911:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,052:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,237:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,326:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,475:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,643:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,832:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:12,923:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:13,068:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:13,238:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:13,404:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:13,576:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:13,790:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:13,878:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,013:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,188:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,275:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,418:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,583:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,767:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:14,857:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,000:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,168:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,333:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,505:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,717:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,819:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:15,956:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,129:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,217:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,361:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,520:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,704:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,795:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:16,937:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:17,103:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:17,266:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:17,436:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:17,647:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:17,738:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:17,870:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,044:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,132:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,271:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,429:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,606:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,696:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,835:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:18,997:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:19,159:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:19,330:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:19,541:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:19,630:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:19,762:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:19,931:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,022:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,159:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,313:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,487:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,577:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,711:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:20,872:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,028:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,192:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,395:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,484:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,610:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,775:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:21,865:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,000:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,151:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,322:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,412:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,542:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,698:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:22,853:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,015:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,219:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,310:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,433:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,594:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,683:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,815:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:23,967:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,134:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,225:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,351:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,505:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,659:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,817:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:24,997:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,086:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,205:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,365:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,454:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,579:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,722:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,886:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:25,976:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,088:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,238:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,383:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,527:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,691:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,782:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:26,899:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,059:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,154:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,265:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,394:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,546:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,638:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,731:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,860:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:27,989:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,121:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,264:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,353:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,445:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,583:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,674:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,766:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,857:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:28,948:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,040:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,132:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,222:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,315:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,404:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,495:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,587:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,679:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:32:29,892:INFO:Visual Rendered Successfully
2024-12-29 18:32:30,065:INFO:plot_model() successfully completed......................................
2024-12-29 18:33:49,607:INFO:Initializing plot_model()
2024-12-29 18:33:49,608:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:33:49,608:INFO:Checking exceptions
2024-12-29 18:33:49,610:INFO:Preloading libraries
2024-12-29 18:33:49,610:INFO:Copying training dataset
2024-12-29 18:33:49,610:INFO:Plot type: boundary
2024-12-29 18:33:49,732:INFO:Fitting StandardScaler()
2024-12-29 18:33:49,736:INFO:Fitting PCA()
2024-12-29 18:33:49,857:INFO:Fitting Model
2024-12-29 18:33:50,757:INFO:Visual Rendered Successfully
2024-12-29 18:33:50,974:INFO:plot_model() successfully completed......................................
2024-12-29 18:33:58,238:INFO:Initializing plot_model()
2024-12-29 18:33:58,238:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:33:58,238:INFO:Checking exceptions
2024-12-29 18:33:58,241:INFO:Preloading libraries
2024-12-29 18:33:58,241:INFO:Copying training dataset
2024-12-29 18:33:58,241:INFO:Plot type: dimension
2024-12-29 18:33:58,273:INFO:Fitting StandardScaler()
2024-12-29 18:33:58,303:INFO:Fitting PCA()
2024-12-29 18:33:58,547:INFO:Fitting & Transforming Model
2024-12-29 18:33:58,635:INFO:Visual Rendered Successfully
2024-12-29 18:33:58,787:INFO:plot_model() successfully completed......................................
2024-12-29 18:34:03,381:INFO:Initializing plot_model()
2024-12-29 18:34:03,381:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:34:03,381:INFO:Checking exceptions
2024-12-29 18:34:03,383:INFO:Preloading libraries
2024-12-29 18:34:03,383:INFO:Copying training dataset
2024-12-29 18:34:03,384:INFO:Plot type: feature
2024-12-29 18:34:03,548:INFO:Visual Rendered Successfully
2024-12-29 18:34:03,702:INFO:plot_model() successfully completed......................................
2024-12-29 18:35:47,912:INFO:Initializing get_config()
2024-12-29 18:35:47,912:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, variable=X)
2024-12-29 18:35:47,922:INFO:Variable:  returned as      PassengerId  Pclass                                              Name  \
239          240       2                            Hunt, Mr. George Henry   
4              5       3                          Allen, Mr. William Henry   
158          159       3                               Smiljanic, Mr. Mile   
206          207       3                        Backstrom, Mr. Karl Alfred   
289          290       3                              Connolly, Miss. Kate   
..           ...     ...                                               ...   
366          367       1  Warren, Mrs. Frank Manley (Anna Sophia Atkinson)   
879          880       1     Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   
570          571       2                                Harris, Mr. George   
320          321       3                                Dennis, Mr. Samuel   
165          166       3   Goldsmith, Master. Frank John William "Frankie"   

        Sex   Age  SibSp  Parch       Ticket       Fare Cabin Embarked  
239    male  33.0      0      0   SCO/W 1585  12.275000   NaN        S  
4      male  35.0      0      0       373450   8.050000   NaN        S  
158    male   NaN      0      0       315037   8.662500   NaN        S  
206    male  32.0      1      0      3101278  15.850000   NaN        S  
289  female  22.0      0      0       370373   7.750000   NaN        Q  
..      ...   ...    ...    ...          ...        ...   ...      ...  
366  female  60.0      1      0       110813  75.250000   D37        C  
879  female  56.0      0      1        11767  83.158302   C50        C  
570    male  62.0      0      0  S.W./PP 752  10.500000   NaN        S  
320    male  22.0      0      0    A/5 21172   7.250000   NaN        S  
165    male   9.0      0      2       363291  20.525000   NaN        S  

[891 rows x 11 columns]
2024-12-29 18:35:47,922:INFO:get_config() successfully completed......................................
2024-12-29 18:36:03,493:INFO:Initializing plot_model()
2024-12-29 18:36:03,493:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:36:03,493:INFO:Checking exceptions
2024-12-29 18:36:03,495:INFO:Preloading libraries
2024-12-29 18:36:03,495:INFO:Copying training dataset
2024-12-29 18:36:03,496:INFO:Plot type: rfe
2024-12-29 18:36:03,737:INFO:Fitting Model
2024-12-29 18:36:03,835:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:04,024:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:04,220:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:04,315:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:04,470:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:04,658:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:04,835:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,026:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,253:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,342:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,509:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,697:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,786:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:05,942:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:06,117:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:06,310:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:06,400:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:06,560:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:06,748:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:06,926:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:07,115:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:07,339:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:07,428:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:07,570:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:07,752:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:07,844:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,000:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,174:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,366:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,456:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,606:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,789:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:08,963:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:09,141:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:09,360:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:09,448:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:09,589:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:09,769:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:09,860:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,010:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,187:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,375:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,466:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,614:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,789:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:10,957:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,132:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,348:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,436:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,575:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,753:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,844:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:11,993:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:12,160:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:12,346:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:12,436:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:12,579:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:12,749:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:12,917:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,092:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,306:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,396:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,532:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,708:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,799:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:13,945:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:14,110:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:14,293:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:14,384:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:14,527:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:14,694:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:14,857:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,029:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,241:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,331:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,464:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,637:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,730:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:15,873:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,035:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,214:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,304:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,443:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,607:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,765:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:16,936:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,147:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,238:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,366:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,536:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,625:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,765:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:17,921:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:18,100:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:18,189:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:18,324:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:18,482:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:18,638:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:18,804:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,009:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,099:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,227:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,392:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,482:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,616:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,766:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:19,937:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,027:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,160:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,316:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,468:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,628:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,829:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:20,918:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,046:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,214:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,307:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,441:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,590:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,762:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,855:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:21,982:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:22,136:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:22,287:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:22,447:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:22,629:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:22,719:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:22,839:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,002:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,092:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,223:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,370:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,538:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,629:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,743:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:23,897:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,044:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,189:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,353:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,443:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,556:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,713:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,804:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:24,913:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,040:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,187:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,277:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,368:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,498:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,632:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,764:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:25,911:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,005:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,100:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,243:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,333:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,425:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,520:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,625:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,717:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,808:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,898:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:26,988:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:27,078:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:27,168:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:27,258:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:27,351:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:36:27,560:INFO:Visual Rendered Successfully
2024-12-29 18:36:27,711:INFO:plot_model() successfully completed......................................
2024-12-29 18:37:11,952:INFO:Initializing predict_model()
2024-12-29 18:37:11,952:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C58CC149D0>)
2024-12-29 18:37:11,952:INFO:Checking exceptions
2024-12-29 18:37:11,952:INFO:Preloading libraries
2024-12-29 18:37:11,954:INFO:Set up data.
2024-12-29 18:37:11,963:INFO:Set up index.
2024-12-29 18:39:33,596:INFO:Initializing plot_model()
2024-12-29 18:39:33,597:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:39:33,597:INFO:Checking exceptions
2024-12-29 18:39:33,601:INFO:Preloading libraries
2024-12-29 18:39:33,602:INFO:Copying training dataset
2024-12-29 18:39:33,602:INFO:Plot type: error
2024-12-29 18:39:33,877:INFO:Fitting Model
2024-12-29 18:39:33,877:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:39:33,877:INFO:Scoring test/hold-out set
2024-12-29 18:39:33,990:INFO:Visual Rendered Successfully
2024-12-29 18:39:34,143:INFO:plot_model() successfully completed......................................
2024-12-29 18:39:56,836:INFO:Initializing plot_model()
2024-12-29 18:39:56,836:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:39:56,837:INFO:Checking exceptions
2024-12-29 18:39:56,839:INFO:Preloading libraries
2024-12-29 18:39:56,839:INFO:Copying training dataset
2024-12-29 18:39:56,839:INFO:Plot type: pr
2024-12-29 18:39:57,074:INFO:Fitting Model
2024-12-29 18:39:57,074:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:39:57,074:INFO:Scoring test/hold-out set
2024-12-29 18:39:57,173:INFO:Visual Rendered Successfully
2024-12-29 18:39:57,346:INFO:plot_model() successfully completed......................................
2024-12-29 18:40:03,384:INFO:Initializing plot_model()
2024-12-29 18:40:03,384:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:40:03,384:INFO:Checking exceptions
2024-12-29 18:40:03,387:INFO:Preloading libraries
2024-12-29 18:40:03,388:INFO:Copying training dataset
2024-12-29 18:40:03,388:INFO:Plot type: threshold
2024-12-29 18:40:03,617:INFO:Fitting Model
2024-12-29 18:40:03,707:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:03,811:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:03,922:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,016:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,108:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,201:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,294:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,389:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,482:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,573:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,663:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,755:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,849:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:04,943:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,040:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,130:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,221:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,313:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,406:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,504:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,596:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,689:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,780:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,873:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:05,964:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,058:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,151:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,244:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,335:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,427:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,518:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,612:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,705:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,794:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,887:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:06,979:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,068:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,162:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,254:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,346:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,437:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,529:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,622:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,716:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,812:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:07,905:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:08,000:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:08,095:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:08,190:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:08,283:WARNING:d:\Anaconda\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-12-29 18:40:08,303:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:40:08,315:INFO:Scoring test/hold-out set
2024-12-29 18:40:08,566:INFO:Visual Rendered Successfully
2024-12-29 18:40:08,739:INFO:plot_model() successfully completed......................................
2024-12-29 18:43:06,578:INFO:Initializing plot_model()
2024-12-29 18:43:06,579:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:43:06,579:INFO:Checking exceptions
2024-12-29 18:43:06,582:INFO:Preloading libraries
2024-12-29 18:43:06,582:INFO:Copying training dataset
2024-12-29 18:43:06,582:INFO:Plot type: confusion_matrix
2024-12-29 18:43:06,813:INFO:Fitting Model
2024-12-29 18:43:06,813:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:43:06,814:INFO:Scoring test/hold-out set
2024-12-29 18:43:06,878:INFO:Visual Rendered Successfully
2024-12-29 18:43:07,032:INFO:plot_model() successfully completed......................................
2024-12-29 18:43:12,698:INFO:Initializing plot_model()
2024-12-29 18:43:12,698:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 LogisticRegression(C=2.436, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1136,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C5FEC0BCD0>, system=True)
2024-12-29 18:43:12,698:INFO:Checking exceptions
2024-12-29 18:43:12,700:INFO:Preloading libraries
2024-12-29 18:43:12,701:INFO:Copying training dataset
2024-12-29 18:43:12,701:INFO:Plot type: auc
2024-12-29 18:43:12,934:INFO:Fitting Model
2024-12-29 18:43:12,934:WARNING:d:\Anaconda\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-12-29 18:43:12,934:INFO:Scoring test/hold-out set
2024-12-29 18:43:13,049:INFO:Visual Rendered Successfully
2024-12-29 18:43:13,197:INFO:plot_model() successfully completed......................................
